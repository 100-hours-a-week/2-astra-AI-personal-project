{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install easyfsl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1siZbCvzrQCV",
        "outputId": "17e0819c-9c2c-4a61-959f-692b2d0dc808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyfsl in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from easyfsl) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from easyfsl) (2.2.2)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from easyfsl) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from easyfsl) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from easyfsl) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->easyfsl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->easyfsl) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->easyfsl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->easyfsl) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->easyfsl) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-txgEmtu75T",
        "outputId": "3d0884cb-b1ef-4b8e-a2a3-0c7d40f5ed69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from easyfsl.samplers import TaskSampler\n",
        "from easyfsl.utils import sliding_average\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "4BroOU1Yqunh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFZ1c1y6TiYb",
        "outputId": "5a1fda87-1c1f-4839-d18c-2309761aa7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FilteredCIFAR100(datasets.CIFAR100):\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "        image = Image.fromarray(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, int(label)"
      ],
      "metadata": {
        "id": "VPkroghmqxkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrototypicalNetworks(nn.Module):\n",
        "        def __init__(self, backbone: nn.Module):\n",
        "            super().__init__()\n",
        "            self.backbone = backbone\n",
        "\n",
        "        def forward(self, support_images, support_labels, query_images):\n",
        "            z_support = self.backbone(support_images)\n",
        "            z_query = self.backbone(query_images)\n",
        "            n_way = len(torch.unique(support_labels))\n",
        "            z_proto = torch.stack([\n",
        "                z_support[support_labels == label].mean(0)\n",
        "                for label in torch.unique(support_labels)\n",
        "            ])\n",
        "            dists = torch.cdist(z_query, z_proto)\n",
        "            return -dists"
      ],
      "metadata": {
        "id": "Lmb34kXntfFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbKdbWApqIew"
      },
      "outputs": [],
      "source": [
        "def run_single_experiment(experiment_id, shot, meta_batch_size, do_training, results_dir):\n",
        "    exp_dir = os.path.join(results_dir, experiment_id)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "\n",
        "    # 하이퍼파리터 설정\n",
        "    N_WAY = 4\n",
        "    N_SHOT = shot\n",
        "    N_QUERY = 10\n",
        "    N_TRAINING_EPISODES = 40000\n",
        "    N_VALIDATION_TASKS = 100\n",
        "    N_EVALUATION_TASKS = 1000\n",
        "    LOG_FREQ = 50\n",
        "    VAL_FREQ = 500\n",
        "    PATIENCE = 10\n",
        "\n",
        "    # 데이터세트\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    cifar100 = FilteredCIFAR100(root=\".\", train=True, download=True, transform=transform)\n",
        "\n",
        "    # 클래스 설정\n",
        "    all_classes = list(range(100))\n",
        "    random.seed(42)\n",
        "    random.shuffle(all_classes)\n",
        "    train_classes = all_classes[:80]\n",
        "    val_classes = all_classes[80:]\n",
        "\n",
        "    train_idx = [i for i, label in enumerate(cifar100.targets) if label in train_classes]\n",
        "    val_idx = [i for i, label in enumerate(cifar100.targets) if label in val_classes]\n",
        "\n",
        "    train_dataset = Subset(cifar100, train_idx)\n",
        "    val_dataset = Subset(cifar100, val_idx)\n",
        "    train_dataset.get_labels = lambda: [int(cifar100.targets[i]) for i in train_idx]\n",
        "    val_dataset.get_labels = lambda: [int(cifar100.targets[i]) for i in val_idx]\n",
        "\n",
        "    train_sampler = TaskSampler(train_dataset, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_TRAINING_EPISODES)\n",
        "    val_sampler = TaskSampler(val_dataset, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_VALIDATION_TASKS)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_sampler=train_sampler, num_workers=2, collate_fn=train_sampler.episodic_collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_sampler=val_sampler, num_workers=2, collate_fn=val_sampler.episodic_collate_fn)\n",
        "\n",
        "    # 모델 정의\n",
        "    backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "    backbone.fc = nn.Flatten()\n",
        "    model = PrototypicalNetworks(backbone).cuda()\n",
        "\n",
        "    # 학습 설정\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    all_loss = []\n",
        "    val_acc_list = []\n",
        "    episode_list = []\n",
        "\n",
        "    # 학습 없이 검사만 진행하는 경우\n",
        "    if not do_training:\n",
        "        print(f\"[{experiment_id}] No training: evaluating pretrained model\")\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for s_img, s_lbl, q_img, q_lbl, _ in val_loader:\n",
        "                s_img, s_lbl = s_img.cuda(), s_lbl.cuda()\n",
        "                q_img, q_lbl = q_img.cuda(), q_lbl.cuda()\n",
        "                scores = model(s_img, s_lbl, q_img)\n",
        "                preds = scores.argmax(dim=1)\n",
        "                correct += (preds == q_lbl).sum().item()\n",
        "                total += len(q_lbl)\n",
        "        val_acc = correct / total * 100\n",
        "        print(f\"[{experiment_id}] Validation Accuracy: {val_acc:.2f}%\")\n",
        "        return {\n",
        "            \"experiment_id\": experiment_id,\n",
        "            \"shot\": shot,\n",
        "            \"meta_batch_size\": meta_batch_size,\n",
        "            \"best_val_acc\": val_acc,\n",
        "            \"status\": \"Evaluated\"\n",
        "        }\n",
        "\n",
        "    # 학습 루프\n",
        "    model.train()\n",
        "    for episode_index, (support_images, support_labels, query_images, query_labels, _) in enumerate(train_loader):\n",
        "        support_images, support_labels = support_images.cuda(), support_labels.cuda()\n",
        "        query_images, query_labels = query_images.cuda(), query_labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(support_images, support_labels, query_images)\n",
        "        loss = criterion(scores, query_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        all_loss.append(loss.item())\n",
        "\n",
        "        # 로그 출력\n",
        "        if episode_index % LOG_FREQ == 0:\n",
        "            print(f\"[{experiment_id}] Episode {episode_index} | Loss: {sliding_average(all_loss, LOG_FREQ):.4f}\")\n",
        "\n",
        "        # Validation 평가\n",
        "        if episode_index % VAL_FREQ == 0 and episode_index > 0:\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for s_img, s_lbl, q_img, q_lbl, _ in val_loader:\n",
        "                    s_img, s_lbl = s_img.cuda(), s_lbl.cuda()\n",
        "                    q_img, q_lbl = q_img.cuda(), q_lbl.cuda()\n",
        "                    scores = model(s_img, s_lbl, q_img)\n",
        "                    preds = scores.argmax(dim=1)\n",
        "                    correct += (preds == q_lbl).sum().item()\n",
        "                    total += len(q_lbl)\n",
        "            val_acc = correct / total * 100\n",
        "            val_acc_list.append(val_acc)\n",
        "            episode_list.append(episode_index)\n",
        "            print(f\"[{experiment_id}] Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "            # Early Stopping 체크\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), os.path.join(exp_dir, \"best_model.pt\"))\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= PATIENCE:\n",
        "                    print(f\"[{experiment_id}] Early stopping triggered at episode {episode_index}\")\n",
        "                    break\n",
        "            model.train()\n",
        "\n",
        "    # 시각화 저장\n",
        "    smoothed_loss = [np.mean(all_loss[max(0, i - 49):i + 1]) for i in range(len(all_loss))]\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(smoothed_loss)\n",
        "    plt.title(\"Train Loss\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(episode_list, val_acc_list, marker='o')\n",
        "    plt.title(\"Validation Accuracy\")\n",
        "    plt.savefig(os.path.join(exp_dir, \"training_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    return {\n",
        "        \"experiment_id\": experiment_id,\n",
        "        \"shot\": shot,\n",
        "        \"meta_batch_size\": meta_batch_size,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"status\": \"Finished\"\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# MongoDB Atlas 연결\n",
        "conn_str = \"mongodb+srv://kaeul991020:IlopdXaLdPPAQyWX@cluster0.c74kr.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "\n",
        "client = MongoClient(conn_str)\n",
        "db = client[\"mydatabase\"]\n",
        "collection = db[\"experiment_results\"]\n"
      ],
      "metadata": {
        "id": "tcgdUFx9u35f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "# 학습 없이 평가만 하는 실험 2개 (pretrained만 사용)\n",
        "no_training_experiments = [\n",
        "    {\"shot\": 1, \"meta_batch_size\": None, \"do_training\": False},\n",
        "    {\"shot\": 5, \"meta_batch_size\": None, \"do_training\": False},\n",
        "]\n",
        "\n",
        "# meta-training을 수행하는 실험 6개 (학습 + 평가)\n",
        "training_experiments = [\n",
        "    {\"shot\": s, \"meta_batch_size\": mb, \"do_training\": True}\n",
        "    for s in [1, 5]  # shot\n",
        "    for mb in [1, 4, 8]  # meta_batch_size\n",
        "]\n",
        "\n",
        "# 전체 실험 조합 결합 (총 8개)\n",
        "experiments = no_training_experiments + training_experiments\n",
        "\n",
        "# 각 실험에 experiment_id 부여\n",
        "experiment_configs = []\n",
        "for i, exp in enumerate(experiments):\n",
        "    exp_id = f\"exp_{i+1}\"\n",
        "    exp[\"experiment_id\"] = exp_id\n",
        "    experiment_configs.append(exp)\n",
        "\n",
        "# DataFrame으로 보기 쉽게 정리\n",
        "experiment_df = pd.DataFrame(experiment_configs)\n",
        "print(\"실험 구성표:\")\n",
        "print(experiment_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9hEE7TDCmvq",
        "outputId": "95a92eea-d3ad-4080-f9f4-18a749be5bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실험 구성표:\n",
            "   shot  meta_batch_size  do_training experiment_id\n",
            "0     1              NaN        False         exp_1\n",
            "1     5              NaN        False         exp_2\n",
            "2     1              1.0         True         exp_3\n",
            "3     1              4.0         True         exp_4\n",
            "4     1              8.0         True         exp_5\n",
            "5     5              1.0         True         exp_6\n",
            "6     5              4.0         True         exp_7\n",
            "7     5              8.0         True         exp_8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 저장 폴더\n",
        "results_dir = \"/content/drive/MyDrive/experiment_results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# 전체 실험 실행\n",
        "results_list = []\n",
        "\n",
        "# 전체 실험 실행\n",
        "for exp in experiment_configs:\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"실험 시작: {exp['experiment_id']} (shot: {exp['shot']}, \"\n",
        "          f\"meta_batch_size: {exp['meta_batch_size']}, do_training: {exp['do_training']})\")\n",
        "\n",
        "    result = run_single_experiment(\n",
        "        experiment_id=exp[\"experiment_id\"],\n",
        "        shot=exp[\"shot\"],\n",
        "        meta_batch_size=exp[\"meta_batch_size\"],\n",
        "        do_training=exp[\"do_training\"],\n",
        "        results_dir=results_dir\n",
        "    )\n",
        "\n",
        "    # MongoDB 저장\n",
        "    collection.insert_one(result)\n",
        "\n",
        "    results_list.append(result)\n",
        "\n",
        "    # 중간 결과 저장\n",
        "    result_df = pd.DataFrame(results_list)\n",
        "    result_csv_path = os.path.join(results_dir, \"experiment_summary.csv\")\n",
        "    result_df.to_csv(result_csv_path, index=False)\n",
        "    print(f\"결과가 저장되었습니다: {result_csv_path}\")\n",
        "\n",
        "# 최종 결과 출력\n",
        "final_results = pd.DataFrame(results_list)\n",
        "print(\"\\n최종 실험 결과:\")\n",
        "print(final_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5no3SRR1qPqr",
        "outputId": "c443377f-f5ed-4f2f-8e5a-9391be49ec2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "실험 시작: exp_1 (shot: 1, meta_batch_size: None, do_training: False)\n",
            "[exp_1] No training: evaluating pretrained model\n",
            "[exp_1] Validation Accuracy: 52.48%\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_2 (shot: 5, meta_batch_size: None, do_training: False)\n",
            "[exp_2] No training: evaluating pretrained model\n",
            "[exp_2] Validation Accuracy: 71.38%\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_3 (shot: 1, meta_batch_size: 1, do_training: True)\n",
            "[exp_3] Episode 0 | Loss: 0.9434\n",
            "[exp_3] Episode 50 | Loss: 2.0671\n",
            "[exp_3] Episode 100 | Loss: 1.4189\n",
            "[exp_3] Episode 150 | Loss: 1.2949\n",
            "[exp_3] Episode 200 | Loss: 1.2000\n",
            "[exp_3] Episode 250 | Loss: 1.2143\n",
            "[exp_3] Episode 300 | Loss: 1.1662\n",
            "[exp_3] Episode 350 | Loss: 1.1912\n",
            "[exp_3] Episode 400 | Loss: 1.1753\n",
            "[exp_3] Episode 450 | Loss: 1.2500\n",
            "[exp_3] Episode 500 | Loss: 1.1800\n",
            "[exp_3] Validation Accuracy: 41.02%\n",
            "[exp_3] Episode 550 | Loss: 1.1476\n",
            "[exp_3] Episode 600 | Loss: 1.1991\n",
            "[exp_3] Episode 650 | Loss: 1.1348\n",
            "[exp_3] Episode 700 | Loss: 1.1237\n",
            "[exp_3] Episode 750 | Loss: 1.1451\n",
            "[exp_3] Episode 800 | Loss: 1.0613\n",
            "[exp_3] Episode 850 | Loss: 1.1203\n",
            "[exp_3] Episode 900 | Loss: 1.1009\n",
            "[exp_3] Episode 950 | Loss: 1.1098\n",
            "[exp_3] Episode 1000 | Loss: 1.0817\n",
            "[exp_3] Validation Accuracy: 45.70%\n",
            "[exp_3] Episode 1050 | Loss: 1.1067\n",
            "[exp_3] Episode 1100 | Loss: 1.0716\n",
            "[exp_3] Episode 1150 | Loss: 1.0836\n",
            "[exp_3] Episode 1200 | Loss: 1.0992\n",
            "[exp_3] Episode 1250 | Loss: 1.0481\n",
            "[exp_3] Episode 1300 | Loss: 1.0130\n",
            "[exp_3] Episode 1350 | Loss: 0.9831\n",
            "[exp_3] Episode 1400 | Loss: 1.0407\n",
            "[exp_3] Episode 1450 | Loss: 1.0275\n",
            "[exp_3] Episode 1500 | Loss: 1.0337\n",
            "[exp_3] Validation Accuracy: 52.58%\n",
            "[exp_3] Episode 1550 | Loss: 0.9787\n",
            "[exp_3] Episode 1600 | Loss: 0.9707\n",
            "[exp_3] Episode 1650 | Loss: 0.9638\n",
            "[exp_3] Episode 1700 | Loss: 0.9560\n",
            "[exp_3] Episode 1750 | Loss: 0.9685\n",
            "[exp_3] Episode 1800 | Loss: 1.0044\n",
            "[exp_3] Episode 1850 | Loss: 0.9644\n",
            "[exp_3] Episode 1900 | Loss: 0.9517\n",
            "[exp_3] Episode 1950 | Loss: 0.8888\n",
            "[exp_3] Episode 2000 | Loss: 0.9392\n",
            "[exp_3] Validation Accuracy: 54.97%\n",
            "[exp_3] Episode 2050 | Loss: 0.9336\n",
            "[exp_3] Episode 2100 | Loss: 0.9301\n",
            "[exp_3] Episode 2150 | Loss: 0.9190\n",
            "[exp_3] Episode 2200 | Loss: 0.9197\n",
            "[exp_3] Episode 2250 | Loss: 0.8794\n",
            "[exp_3] Episode 2300 | Loss: 0.8924\n",
            "[exp_3] Episode 2350 | Loss: 0.9808\n",
            "[exp_3] Episode 2400 | Loss: 0.9572\n",
            "[exp_3] Episode 2450 | Loss: 0.8807\n",
            "[exp_3] Episode 2500 | Loss: 0.9097\n",
            "[exp_3] Validation Accuracy: 50.02%\n",
            "[exp_3] Episode 2550 | Loss: 0.8931\n",
            "[exp_3] Episode 2600 | Loss: 0.9170\n",
            "[exp_3] Episode 2650 | Loss: 0.8840\n",
            "[exp_3] Episode 2700 | Loss: 0.8882\n",
            "[exp_3] Episode 2750 | Loss: 0.8339\n",
            "[exp_3] Episode 2800 | Loss: 0.8775\n",
            "[exp_3] Episode 2850 | Loss: 0.8904\n",
            "[exp_3] Episode 2900 | Loss: 0.8018\n",
            "[exp_3] Episode 2950 | Loss: 0.8976\n",
            "[exp_3] Episode 3000 | Loss: 0.8754\n",
            "[exp_3] Validation Accuracy: 54.40%\n",
            "[exp_3] Episode 3050 | Loss: 0.8624\n",
            "[exp_3] Episode 3100 | Loss: 0.8565\n",
            "[exp_3] Episode 3150 | Loss: 0.8564\n",
            "[exp_3] Episode 3200 | Loss: 0.8418\n",
            "[exp_3] Episode 3250 | Loss: 0.8165\n",
            "[exp_3] Episode 3300 | Loss: 0.8958\n",
            "[exp_3] Episode 3350 | Loss: 0.8438\n",
            "[exp_3] Episode 3400 | Loss: 0.8049\n",
            "[exp_3] Episode 3450 | Loss: 0.8553\n",
            "[exp_3] Episode 3500 | Loss: 0.8442\n",
            "[exp_3] Validation Accuracy: 54.75%\n",
            "[exp_3] Episode 3550 | Loss: 0.9207\n",
            "[exp_3] Episode 3600 | Loss: 0.8545\n",
            "[exp_3] Episode 3650 | Loss: 0.8590\n",
            "[exp_3] Episode 3700 | Loss: 0.7981\n",
            "[exp_3] Episode 3750 | Loss: 0.7857\n",
            "[exp_3] Episode 3800 | Loss: 0.8309\n",
            "[exp_3] Episode 3850 | Loss: 0.8346\n",
            "[exp_3] Episode 3900 | Loss: 0.8862\n",
            "[exp_3] Episode 3950 | Loss: 0.7875\n",
            "[exp_3] Episode 4000 | Loss: 0.7766\n",
            "[exp_3] Validation Accuracy: 61.88%\n",
            "[exp_3] Episode 4050 | Loss: 0.8089\n",
            "[exp_3] Episode 4100 | Loss: 0.8318\n",
            "[exp_3] Episode 4150 | Loss: 0.8287\n",
            "[exp_3] Episode 4200 | Loss: 0.8658\n",
            "[exp_3] Episode 4250 | Loss: 0.7233\n",
            "[exp_3] Episode 4300 | Loss: 0.8490\n",
            "[exp_3] Episode 4350 | Loss: 0.7477\n",
            "[exp_3] Episode 4400 | Loss: 0.8267\n",
            "[exp_3] Episode 4450 | Loss: 0.7868\n",
            "[exp_3] Episode 4500 | Loss: 0.7966\n",
            "[exp_3] Validation Accuracy: 57.17%\n",
            "[exp_3] Episode 4550 | Loss: 0.7890\n",
            "[exp_3] Episode 4600 | Loss: 0.7662\n",
            "[exp_3] Episode 4650 | Loss: 0.7255\n",
            "[exp_3] Episode 4700 | Loss: 0.7511\n",
            "[exp_3] Episode 4750 | Loss: 0.7805\n",
            "[exp_3] Episode 4800 | Loss: 0.7490\n",
            "[exp_3] Episode 4850 | Loss: 0.7830\n",
            "[exp_3] Episode 4900 | Loss: 0.7030\n",
            "[exp_3] Episode 4950 | Loss: 0.7907\n",
            "[exp_3] Episode 5000 | Loss: 0.7484\n",
            "[exp_3] Validation Accuracy: 57.83%\n",
            "[exp_3] Episode 5050 | Loss: 0.7669\n",
            "[exp_3] Episode 5100 | Loss: 0.7511\n",
            "[exp_3] Episode 5150 | Loss: 0.7681\n",
            "[exp_3] Episode 5200 | Loss: 0.7568\n",
            "[exp_3] Episode 5250 | Loss: 0.7813\n",
            "[exp_3] Episode 5300 | Loss: 0.8041\n",
            "[exp_3] Episode 5350 | Loss: 0.7102\n",
            "[exp_3] Episode 5400 | Loss: 0.7651\n",
            "[exp_3] Episode 5450 | Loss: 0.8147\n",
            "[exp_3] Episode 5500 | Loss: 0.7255\n",
            "[exp_3] Validation Accuracy: 57.05%\n",
            "[exp_3] Episode 5550 | Loss: 0.7389\n",
            "[exp_3] Episode 5600 | Loss: 0.7191\n",
            "[exp_3] Episode 5650 | Loss: 0.8108\n",
            "[exp_3] Episode 5700 | Loss: 0.7914\n",
            "[exp_3] Episode 5750 | Loss: 0.7309\n",
            "[exp_3] Episode 5800 | Loss: 0.7636\n",
            "[exp_3] Episode 5850 | Loss: 0.7790\n",
            "[exp_3] Episode 5900 | Loss: 0.6708\n",
            "[exp_3] Episode 5950 | Loss: 0.7300\n",
            "[exp_3] Episode 6000 | Loss: 0.7946\n",
            "[exp_3] Validation Accuracy: 58.95%\n",
            "[exp_3] Episode 6050 | Loss: 0.7534\n",
            "[exp_3] Episode 6100 | Loss: 0.6382\n",
            "[exp_3] Episode 6150 | Loss: 0.6592\n",
            "[exp_3] Episode 6200 | Loss: 0.7125\n",
            "[exp_3] Episode 6250 | Loss: 0.7237\n",
            "[exp_3] Episode 6300 | Loss: 0.6729\n",
            "[exp_3] Episode 6350 | Loss: 0.6580\n",
            "[exp_3] Episode 6400 | Loss: 0.7100\n",
            "[exp_3] Episode 6450 | Loss: 0.7693\n",
            "[exp_3] Episode 6500 | Loss: 0.7391\n",
            "[exp_3] Validation Accuracy: 60.00%\n",
            "[exp_3] Episode 6550 | Loss: 0.7084\n",
            "[exp_3] Episode 6600 | Loss: 0.7466\n",
            "[exp_3] Episode 6650 | Loss: 0.7098\n",
            "[exp_3] Episode 6700 | Loss: 0.6913\n",
            "[exp_3] Episode 6750 | Loss: 0.6549\n",
            "[exp_3] Episode 6800 | Loss: 0.7368\n",
            "[exp_3] Episode 6850 | Loss: 0.7021\n",
            "[exp_3] Episode 6900 | Loss: 0.6604\n",
            "[exp_3] Episode 6950 | Loss: 0.7048\n",
            "[exp_3] Episode 7000 | Loss: 0.7118\n",
            "[exp_3] Validation Accuracy: 58.60%\n",
            "[exp_3] Episode 7050 | Loss: 0.6816\n",
            "[exp_3] Episode 7100 | Loss: 0.6433\n",
            "[exp_3] Episode 7150 | Loss: 0.7006\n",
            "[exp_3] Episode 7200 | Loss: 0.6194\n",
            "[exp_3] Episode 7250 | Loss: 0.6868\n",
            "[exp_3] Episode 7300 | Loss: 0.6654\n",
            "[exp_3] Episode 7350 | Loss: 0.6702\n",
            "[exp_3] Episode 7400 | Loss: 0.7240\n",
            "[exp_3] Episode 7450 | Loss: 0.6157\n",
            "[exp_3] Episode 7500 | Loss: 0.6489\n",
            "[exp_3] Validation Accuracy: 59.05%\n",
            "[exp_3] Episode 7550 | Loss: 0.6234\n",
            "[exp_3] Episode 7600 | Loss: 0.6931\n",
            "[exp_3] Episode 7650 | Loss: 0.6132\n",
            "[exp_3] Episode 7700 | Loss: 0.5898\n",
            "[exp_3] Episode 7750 | Loss: 0.6177\n",
            "[exp_3] Episode 7800 | Loss: 0.6633\n",
            "[exp_3] Episode 7850 | Loss: 0.6353\n",
            "[exp_3] Episode 7900 | Loss: 0.6565\n",
            "[exp_3] Episode 7950 | Loss: 0.6422\n",
            "[exp_3] Episode 8000 | Loss: 0.6435\n",
            "[exp_3] Validation Accuracy: 63.68%\n",
            "[exp_3] Episode 8050 | Loss: 0.6719\n",
            "[exp_3] Episode 8100 | Loss: 0.6411\n",
            "[exp_3] Episode 8150 | Loss: 0.6534\n",
            "[exp_3] Episode 8200 | Loss: 0.6590\n",
            "[exp_3] Episode 8250 | Loss: 0.5768\n",
            "[exp_3] Episode 8300 | Loss: 0.6532\n",
            "[exp_3] Episode 8350 | Loss: 0.6943\n",
            "[exp_3] Episode 8400 | Loss: 0.6925\n",
            "[exp_3] Episode 8450 | Loss: 0.6124\n",
            "[exp_3] Episode 8500 | Loss: 0.6454\n",
            "[exp_3] Validation Accuracy: 60.65%\n",
            "[exp_3] Episode 8550 | Loss: 0.6531\n",
            "[exp_3] Episode 8600 | Loss: 0.6058\n",
            "[exp_3] Episode 8650 | Loss: 0.5952\n",
            "[exp_3] Episode 8700 | Loss: 0.5530\n",
            "[exp_3] Episode 8750 | Loss: 0.6295\n",
            "[exp_3] Episode 8800 | Loss: 0.5811\n",
            "[exp_3] Episode 8850 | Loss: 0.5945\n",
            "[exp_3] Episode 8900 | Loss: 0.5535\n",
            "[exp_3] Episode 8950 | Loss: 0.6192\n",
            "[exp_3] Episode 9000 | Loss: 0.6132\n",
            "[exp_3] Validation Accuracy: 59.40%\n",
            "[exp_3] Episode 9050 | Loss: 0.5937\n",
            "[exp_3] Episode 9100 | Loss: 0.6419\n",
            "[exp_3] Episode 9150 | Loss: 0.6415\n",
            "[exp_3] Episode 9200 | Loss: 0.6242\n",
            "[exp_3] Episode 9250 | Loss: 0.5892\n",
            "[exp_3] Episode 9300 | Loss: 0.5983\n",
            "[exp_3] Episode 9350 | Loss: 0.5878\n",
            "[exp_3] Episode 9400 | Loss: 0.5362\n",
            "[exp_3] Episode 9450 | Loss: 0.5650\n",
            "[exp_3] Episode 9500 | Loss: 0.5220\n",
            "[exp_3] Validation Accuracy: 61.80%\n",
            "[exp_3] Episode 9550 | Loss: 0.6336\n",
            "[exp_3] Episode 9600 | Loss: 0.5961\n",
            "[exp_3] Episode 9650 | Loss: 0.6638\n",
            "[exp_3] Episode 9700 | Loss: 0.6310\n",
            "[exp_3] Episode 9750 | Loss: 0.5455\n",
            "[exp_3] Episode 9800 | Loss: 0.5643\n",
            "[exp_3] Episode 9850 | Loss: 0.5516\n",
            "[exp_3] Episode 9900 | Loss: 0.5675\n",
            "[exp_3] Episode 9950 | Loss: 0.6195\n",
            "[exp_3] Episode 10000 | Loss: 0.6375\n",
            "[exp_3] Validation Accuracy: 64.33%\n",
            "[exp_3] Episode 10050 | Loss: 0.5856\n",
            "[exp_3] Episode 10100 | Loss: 0.5795\n",
            "[exp_3] Episode 10150 | Loss: 0.6413\n",
            "[exp_3] Episode 10200 | Loss: 0.5454\n",
            "[exp_3] Episode 10250 | Loss: 0.5381\n",
            "[exp_3] Episode 10300 | Loss: 0.4812\n",
            "[exp_3] Episode 10350 | Loss: 0.5205\n",
            "[exp_3] Episode 10400 | Loss: 0.5147\n",
            "[exp_3] Episode 10450 | Loss: 0.5954\n",
            "[exp_3] Episode 10500 | Loss: 0.5163\n",
            "[exp_3] Validation Accuracy: 62.52%\n",
            "[exp_3] Episode 10550 | Loss: 0.5629\n",
            "[exp_3] Episode 10600 | Loss: 0.5031\n",
            "[exp_3] Episode 10650 | Loss: 0.4990\n",
            "[exp_3] Episode 10700 | Loss: 0.6190\n",
            "[exp_3] Episode 10750 | Loss: 0.5122\n",
            "[exp_3] Episode 10800 | Loss: 0.5418\n",
            "[exp_3] Episode 10850 | Loss: 0.5588\n",
            "[exp_3] Episode 10900 | Loss: 0.5199\n",
            "[exp_3] Episode 10950 | Loss: 0.4967\n",
            "[exp_3] Episode 11000 | Loss: 0.5800\n",
            "[exp_3] Validation Accuracy: 61.27%\n",
            "[exp_3] Episode 11050 | Loss: 0.5765\n",
            "[exp_3] Episode 11100 | Loss: 0.5086\n",
            "[exp_3] Episode 11150 | Loss: 0.4621\n",
            "[exp_3] Episode 11200 | Loss: 0.5964\n",
            "[exp_3] Episode 11250 | Loss: 0.6652\n",
            "[exp_3] Episode 11300 | Loss: 0.5140\n",
            "[exp_3] Episode 11350 | Loss: 0.5136\n",
            "[exp_3] Episode 11400 | Loss: 0.5569\n",
            "[exp_3] Episode 11450 | Loss: 0.5102\n",
            "[exp_3] Episode 11500 | Loss: 0.5476\n",
            "[exp_3] Validation Accuracy: 62.58%\n",
            "[exp_3] Episode 11550 | Loss: 0.4976\n",
            "[exp_3] Episode 11600 | Loss: 0.5673\n",
            "[exp_3] Episode 11650 | Loss: 0.6118\n",
            "[exp_3] Episode 11700 | Loss: 0.4940\n",
            "[exp_3] Episode 11750 | Loss: 0.5211\n",
            "[exp_3] Episode 11800 | Loss: 0.5379\n",
            "[exp_3] Episode 11850 | Loss: 0.5503\n",
            "[exp_3] Episode 11900 | Loss: 0.5249\n",
            "[exp_3] Episode 11950 | Loss: 0.5524\n",
            "[exp_3] Episode 12000 | Loss: 0.5067\n",
            "[exp_3] Validation Accuracy: 61.10%\n",
            "[exp_3] Episode 12050 | Loss: 0.4999\n",
            "[exp_3] Episode 12100 | Loss: 0.5366\n",
            "[exp_3] Episode 12150 | Loss: 0.5401\n",
            "[exp_3] Episode 12200 | Loss: 0.5393\n",
            "[exp_3] Episode 12250 | Loss: 0.5438\n",
            "[exp_3] Episode 12300 | Loss: 0.5670\n",
            "[exp_3] Episode 12350 | Loss: 0.5113\n",
            "[exp_3] Episode 12400 | Loss: 0.4967\n",
            "[exp_3] Episode 12450 | Loss: 0.4843\n",
            "[exp_3] Episode 12500 | Loss: 0.4808\n",
            "[exp_3] Validation Accuracy: 61.30%\n",
            "[exp_3] Episode 12550 | Loss: 0.5553\n",
            "[exp_3] Episode 12600 | Loss: 0.5821\n",
            "[exp_3] Episode 12650 | Loss: 0.5748\n",
            "[exp_3] Episode 12700 | Loss: 0.5188\n",
            "[exp_3] Episode 12750 | Loss: 0.5171\n",
            "[exp_3] Episode 12800 | Loss: 0.5080\n",
            "[exp_3] Episode 12850 | Loss: 0.5127\n",
            "[exp_3] Episode 12900 | Loss: 0.4920\n",
            "[exp_3] Episode 12950 | Loss: 0.5094\n",
            "[exp_3] Episode 13000 | Loss: 0.5333\n",
            "[exp_3] Validation Accuracy: 61.82%\n",
            "[exp_3] Episode 13050 | Loss: 0.4317\n",
            "[exp_3] Episode 13100 | Loss: 0.5384\n",
            "[exp_3] Episode 13150 | Loss: 0.5283\n",
            "[exp_3] Episode 13200 | Loss: 0.4302\n",
            "[exp_3] Episode 13250 | Loss: 0.5210\n",
            "[exp_3] Episode 13300 | Loss: 0.4410\n",
            "[exp_3] Episode 13350 | Loss: 0.4733\n",
            "[exp_3] Episode 13400 | Loss: 0.4286\n",
            "[exp_3] Episode 13450 | Loss: 0.4702\n",
            "[exp_3] Episode 13500 | Loss: 0.4634\n",
            "[exp_3] Validation Accuracy: 65.38%\n",
            "[exp_3] Episode 13550 | Loss: 0.4483\n",
            "[exp_3] Episode 13600 | Loss: 0.4956\n",
            "[exp_3] Episode 13650 | Loss: 0.5080\n",
            "[exp_3] Episode 13700 | Loss: 0.4310\n",
            "[exp_3] Episode 13750 | Loss: 0.4189\n",
            "[exp_3] Episode 13800 | Loss: 0.4833\n",
            "[exp_3] Episode 13850 | Loss: 0.4828\n",
            "[exp_3] Episode 13900 | Loss: 0.4235\n",
            "[exp_3] Episode 13950 | Loss: 0.3818\n",
            "[exp_3] Episode 14000 | Loss: 0.4910\n",
            "[exp_3] Validation Accuracy: 65.48%\n",
            "[exp_3] Episode 14050 | Loss: 0.4402\n",
            "[exp_3] Episode 14100 | Loss: 0.4623\n",
            "[exp_3] Episode 14150 | Loss: 0.5109\n",
            "[exp_3] Episode 14200 | Loss: 0.4846\n",
            "[exp_3] Episode 14250 | Loss: 0.4855\n",
            "[exp_3] Episode 14300 | Loss: 0.4137\n",
            "[exp_3] Episode 14350 | Loss: 0.4157\n",
            "[exp_3] Episode 14400 | Loss: 0.4593\n",
            "[exp_3] Episode 14450 | Loss: 0.3989\n",
            "[exp_3] Episode 14500 | Loss: 0.4275\n",
            "[exp_3] Validation Accuracy: 62.28%\n",
            "[exp_3] Episode 14550 | Loss: 0.5261\n",
            "[exp_3] Episode 14600 | Loss: 0.4486\n",
            "[exp_3] Episode 14650 | Loss: 0.5232\n",
            "[exp_3] Episode 14700 | Loss: 0.3961\n",
            "[exp_3] Episode 14750 | Loss: 0.3308\n",
            "[exp_3] Episode 14800 | Loss: 0.3383\n",
            "[exp_3] Episode 14850 | Loss: 0.4364\n",
            "[exp_3] Episode 14900 | Loss: 0.4649\n",
            "[exp_3] Episode 14950 | Loss: 0.4152\n",
            "[exp_3] Episode 15000 | Loss: 0.4745\n",
            "[exp_3] Validation Accuracy: 67.55%\n",
            "[exp_3] Episode 15050 | Loss: 0.5174\n",
            "[exp_3] Episode 15100 | Loss: 0.4255\n",
            "[exp_3] Episode 15150 | Loss: 0.4461\n",
            "[exp_3] Episode 15200 | Loss: 0.4543\n",
            "[exp_3] Episode 15250 | Loss: 0.4172\n",
            "[exp_3] Episode 15300 | Loss: 0.4307\n",
            "[exp_3] Episode 15350 | Loss: 0.5305\n",
            "[exp_3] Episode 15400 | Loss: 0.4612\n",
            "[exp_3] Episode 15450 | Loss: 0.4133\n",
            "[exp_3] Episode 15500 | Loss: 0.3736\n",
            "[exp_3] Validation Accuracy: 65.67%\n",
            "[exp_3] Episode 15550 | Loss: 0.3992\n",
            "[exp_3] Episode 15600 | Loss: 0.3836\n",
            "[exp_3] Episode 15650 | Loss: 0.4756\n",
            "[exp_3] Episode 15700 | Loss: 0.4626\n",
            "[exp_3] Episode 15750 | Loss: 0.3952\n",
            "[exp_3] Episode 15800 | Loss: 0.4313\n",
            "[exp_3] Episode 15850 | Loss: 0.4333\n",
            "[exp_3] Episode 15900 | Loss: 0.4225\n",
            "[exp_3] Episode 15950 | Loss: 0.3871\n",
            "[exp_3] Episode 16000 | Loss: 0.4122\n",
            "[exp_3] Validation Accuracy: 63.98%\n",
            "[exp_3] Episode 16050 | Loss: 0.4544\n",
            "[exp_3] Episode 16100 | Loss: 0.3893\n",
            "[exp_3] Episode 16150 | Loss: 0.4205\n",
            "[exp_3] Episode 16200 | Loss: 0.3976\n",
            "[exp_3] Episode 16250 | Loss: 0.4722\n",
            "[exp_3] Episode 16300 | Loss: 0.3514\n",
            "[exp_3] Episode 16350 | Loss: 0.3655\n",
            "[exp_3] Episode 16400 | Loss: 0.4056\n",
            "[exp_3] Episode 16450 | Loss: 0.4095\n",
            "[exp_3] Episode 16500 | Loss: 0.3873\n",
            "[exp_3] Validation Accuracy: 67.65%\n",
            "[exp_3] Episode 16550 | Loss: 0.4068\n",
            "[exp_3] Episode 16600 | Loss: 0.4183\n",
            "[exp_3] Episode 16650 | Loss: 0.3961\n",
            "[exp_3] Episode 16700 | Loss: 0.4393\n",
            "[exp_3] Episode 16750 | Loss: 0.4249\n",
            "[exp_3] Episode 16800 | Loss: 0.3698\n",
            "[exp_3] Episode 16850 | Loss: 0.3346\n",
            "[exp_3] Episode 16900 | Loss: 0.4161\n",
            "[exp_3] Episode 16950 | Loss: 0.3957\n",
            "[exp_3] Episode 17000 | Loss: 0.3881\n",
            "[exp_3] Validation Accuracy: 67.90%\n",
            "[exp_3] Episode 17050 | Loss: 0.3705\n",
            "[exp_3] Episode 17100 | Loss: 0.3946\n",
            "[exp_3] Episode 17150 | Loss: 0.4394\n",
            "[exp_3] Episode 17200 | Loss: 0.4445\n",
            "[exp_3] Episode 17250 | Loss: 0.4590\n",
            "[exp_3] Episode 17300 | Loss: 0.3717\n",
            "[exp_3] Episode 17350 | Loss: 0.3692\n",
            "[exp_3] Episode 17400 | Loss: 0.3971\n",
            "[exp_3] Episode 17450 | Loss: 0.3749\n",
            "[exp_3] Episode 17500 | Loss: 0.4029\n",
            "[exp_3] Validation Accuracy: 66.15%\n",
            "[exp_3] Episode 17550 | Loss: 0.3999\n",
            "[exp_3] Episode 17600 | Loss: 0.4330\n",
            "[exp_3] Episode 17650 | Loss: 0.3793\n",
            "[exp_3] Episode 17700 | Loss: 0.3570\n",
            "[exp_3] Episode 17750 | Loss: 0.3532\n",
            "[exp_3] Episode 17800 | Loss: 0.3668\n",
            "[exp_3] Episode 17850 | Loss: 0.4191\n",
            "[exp_3] Episode 17900 | Loss: 0.3666\n",
            "[exp_3] Episode 17950 | Loss: 0.3908\n",
            "[exp_3] Episode 18000 | Loss: 0.3623\n",
            "[exp_3] Validation Accuracy: 63.78%\n",
            "[exp_3] Episode 18050 | Loss: 0.3520\n",
            "[exp_3] Episode 18100 | Loss: 0.3676\n",
            "[exp_3] Episode 18150 | Loss: 0.3925\n",
            "[exp_3] Episode 18200 | Loss: 0.3472\n",
            "[exp_3] Episode 18250 | Loss: 0.3433\n",
            "[exp_3] Episode 18300 | Loss: 0.3395\n",
            "[exp_3] Episode 18350 | Loss: 0.4125\n",
            "[exp_3] Episode 18400 | Loss: 0.4079\n",
            "[exp_3] Episode 18450 | Loss: 0.3216\n",
            "[exp_3] Episode 18500 | Loss: 0.3513\n",
            "[exp_3] Validation Accuracy: 68.03%\n",
            "[exp_3] Episode 18550 | Loss: 0.3333\n",
            "[exp_3] Episode 18600 | Loss: 0.3413\n",
            "[exp_3] Episode 18650 | Loss: 0.3941\n",
            "[exp_3] Episode 18700 | Loss: 0.3807\n",
            "[exp_3] Episode 18750 | Loss: 0.3435\n",
            "[exp_3] Episode 18800 | Loss: 0.4081\n",
            "[exp_3] Episode 18850 | Loss: 0.4003\n",
            "[exp_3] Episode 18900 | Loss: 0.3524\n",
            "[exp_3] Episode 18950 | Loss: 0.3418\n",
            "[exp_3] Episode 19000 | Loss: 0.3350\n",
            "[exp_3] Validation Accuracy: 63.10%\n",
            "[exp_3] Episode 19050 | Loss: 0.3863\n",
            "[exp_3] Episode 19100 | Loss: 0.3902\n",
            "[exp_3] Episode 19150 | Loss: 0.3187\n",
            "[exp_3] Episode 19200 | Loss: 0.3756\n",
            "[exp_3] Episode 19250 | Loss: 0.3791\n",
            "[exp_3] Episode 19300 | Loss: 0.3489\n",
            "[exp_3] Episode 19350 | Loss: 0.3786\n",
            "[exp_3] Episode 19400 | Loss: 0.4250\n",
            "[exp_3] Episode 19450 | Loss: 0.3572\n",
            "[exp_3] Episode 19500 | Loss: 0.3337\n",
            "[exp_3] Validation Accuracy: 67.75%\n",
            "[exp_3] Episode 19550 | Loss: 0.3045\n",
            "[exp_3] Episode 19600 | Loss: 0.3309\n",
            "[exp_3] Episode 19650 | Loss: 0.3194\n",
            "[exp_3] Episode 19700 | Loss: 0.3458\n",
            "[exp_3] Episode 19750 | Loss: 0.3225\n",
            "[exp_3] Episode 19800 | Loss: 0.3384\n",
            "[exp_3] Episode 19850 | Loss: 0.3724\n",
            "[exp_3] Episode 19900 | Loss: 0.3245\n",
            "[exp_3] Episode 19950 | Loss: 0.3262\n",
            "[exp_3] Episode 20000 | Loss: 0.3372\n",
            "[exp_3] Validation Accuracy: 67.65%\n",
            "[exp_3] Episode 20050 | Loss: 0.3061\n",
            "[exp_3] Episode 20100 | Loss: 0.3959\n",
            "[exp_3] Episode 20150 | Loss: 0.2924\n",
            "[exp_3] Episode 20200 | Loss: 0.3060\n",
            "[exp_3] Episode 20250 | Loss: 0.2990\n",
            "[exp_3] Episode 20300 | Loss: 0.3195\n",
            "[exp_3] Episode 20350 | Loss: 0.2916\n",
            "[exp_3] Episode 20400 | Loss: 0.3205\n",
            "[exp_3] Episode 20450 | Loss: 0.3751\n",
            "[exp_3] Episode 20500 | Loss: 0.3492\n",
            "[exp_3] Validation Accuracy: 62.75%\n",
            "[exp_3] Episode 20550 | Loss: 0.3552\n",
            "[exp_3] Episode 20600 | Loss: 0.3189\n",
            "[exp_3] Episode 20650 | Loss: 0.3107\n",
            "[exp_3] Episode 20700 | Loss: 0.3725\n",
            "[exp_3] Episode 20750 | Loss: 0.2948\n",
            "[exp_3] Episode 20800 | Loss: 0.3129\n",
            "[exp_3] Episode 20850 | Loss: 0.3314\n",
            "[exp_3] Episode 20900 | Loss: 0.3479\n",
            "[exp_3] Episode 20950 | Loss: 0.3284\n",
            "[exp_3] Episode 21000 | Loss: 0.3119\n",
            "[exp_3] Validation Accuracy: 65.22%\n",
            "[exp_3] Episode 21050 | Loss: 0.2786\n",
            "[exp_3] Episode 21100 | Loss: 0.3129\n",
            "[exp_3] Episode 21150 | Loss: 0.3893\n",
            "[exp_3] Episode 21200 | Loss: 0.3542\n",
            "[exp_3] Episode 21250 | Loss: 0.2951\n",
            "[exp_3] Episode 21300 | Loss: 0.3558\n",
            "[exp_3] Episode 21350 | Loss: 0.2902\n",
            "[exp_3] Episode 21400 | Loss: 0.3043\n",
            "[exp_3] Episode 21450 | Loss: 0.2684\n",
            "[exp_3] Episode 21500 | Loss: 0.3251\n",
            "[exp_3] Validation Accuracy: 64.12%\n",
            "[exp_3] Episode 21550 | Loss: 0.2960\n",
            "[exp_3] Episode 21600 | Loss: 0.3538\n",
            "[exp_3] Episode 21650 | Loss: 0.2615\n",
            "[exp_3] Episode 21700 | Loss: 0.3067\n",
            "[exp_3] Episode 21750 | Loss: 0.3182\n",
            "[exp_3] Episode 21800 | Loss: 0.2462\n",
            "[exp_3] Episode 21850 | Loss: 0.2558\n",
            "[exp_3] Episode 21900 | Loss: 0.3145\n",
            "[exp_3] Episode 21950 | Loss: 0.2860\n",
            "[exp_3] Episode 22000 | Loss: 0.3464\n",
            "[exp_3] Validation Accuracy: 64.68%\n",
            "[exp_3] Episode 22050 | Loss: 0.3080\n",
            "[exp_3] Episode 22100 | Loss: 0.3154\n",
            "[exp_3] Episode 22150 | Loss: 0.2643\n",
            "[exp_3] Episode 22200 | Loss: 0.3963\n",
            "[exp_3] Episode 22250 | Loss: 0.3391\n",
            "[exp_3] Episode 22300 | Loss: 0.2937\n",
            "[exp_3] Episode 22350 | Loss: 0.2898\n",
            "[exp_3] Episode 22400 | Loss: 0.3147\n",
            "[exp_3] Episode 22450 | Loss: 0.2761\n",
            "[exp_3] Episode 22500 | Loss: 0.3733\n",
            "[exp_3] Validation Accuracy: 64.33%\n",
            "[exp_3] Episode 22550 | Loss: 0.3870\n",
            "[exp_3] Episode 22600 | Loss: 0.2502\n",
            "[exp_3] Episode 22650 | Loss: 0.2463\n",
            "[exp_3] Episode 22700 | Loss: 0.3320\n",
            "[exp_3] Episode 22750 | Loss: 0.3350\n",
            "[exp_3] Episode 22800 | Loss: 0.2847\n",
            "[exp_3] Episode 22850 | Loss: 0.3383\n",
            "[exp_3] Episode 22900 | Loss: 0.3018\n",
            "[exp_3] Episode 22950 | Loss: 0.2569\n",
            "[exp_3] Episode 23000 | Loss: 0.3269\n",
            "[exp_3] Validation Accuracy: 66.17%\n",
            "[exp_3] Episode 23050 | Loss: 0.2554\n",
            "[exp_3] Episode 23100 | Loss: 0.2909\n",
            "[exp_3] Episode 23150 | Loss: 0.2898\n",
            "[exp_3] Episode 23200 | Loss: 0.3072\n",
            "[exp_3] Episode 23250 | Loss: 0.2560\n",
            "[exp_3] Episode 23300 | Loss: 0.2755\n",
            "[exp_3] Episode 23350 | Loss: 0.2559\n",
            "[exp_3] Episode 23400 | Loss: 0.2784\n",
            "[exp_3] Episode 23450 | Loss: 0.3070\n",
            "[exp_3] Episode 23500 | Loss: 0.2754\n",
            "[exp_3] Validation Accuracy: 65.53%\n",
            "[exp_3] Early stopping triggered at episode 23500\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_4 (shot: 1, meta_batch_size: 4, do_training: True)\n",
            "[exp_4] Episode 0 | Loss: 0.9434\n",
            "[exp_4] Episode 50 | Loss: 1.9939\n",
            "[exp_4] Episode 100 | Loss: 1.2980\n",
            "[exp_4] Episode 150 | Loss: 1.2805\n",
            "[exp_4] Episode 200 | Loss: 1.2092\n",
            "[exp_4] Episode 250 | Loss: 1.2533\n",
            "[exp_4] Episode 300 | Loss: 1.1465\n",
            "[exp_4] Episode 350 | Loss: 1.2012\n",
            "[exp_4] Episode 400 | Loss: 1.1597\n",
            "[exp_4] Episode 450 | Loss: 1.2069\n",
            "[exp_4] Episode 500 | Loss: 1.1568\n",
            "[exp_4] Validation Accuracy: 41.05%\n",
            "[exp_4] Episode 550 | Loss: 1.1177\n",
            "[exp_4] Episode 600 | Loss: 1.1885\n",
            "[exp_4] Episode 650 | Loss: 1.1420\n",
            "[exp_4] Episode 700 | Loss: 1.1209\n",
            "[exp_4] Episode 750 | Loss: 1.1288\n",
            "[exp_4] Episode 800 | Loss: 1.0800\n",
            "[exp_4] Episode 850 | Loss: 1.1240\n",
            "[exp_4] Episode 900 | Loss: 1.1258\n",
            "[exp_4] Episode 950 | Loss: 1.1080\n",
            "[exp_4] Episode 1000 | Loss: 1.0513\n",
            "[exp_4] Validation Accuracy: 46.23%\n",
            "[exp_4] Episode 1050 | Loss: 1.1541\n",
            "[exp_4] Episode 1100 | Loss: 1.0945\n",
            "[exp_4] Episode 1150 | Loss: 1.0809\n",
            "[exp_4] Episode 1200 | Loss: 1.0875\n",
            "[exp_4] Episode 1250 | Loss: 1.0392\n",
            "[exp_4] Episode 1300 | Loss: 0.9942\n",
            "[exp_4] Episode 1350 | Loss: 0.9765\n",
            "[exp_4] Episode 1400 | Loss: 1.0201\n",
            "[exp_4] Episode 1450 | Loss: 1.0244\n",
            "[exp_4] Episode 1500 | Loss: 1.0040\n",
            "[exp_4] Validation Accuracy: 54.20%\n",
            "[exp_4] Episode 1550 | Loss: 0.9981\n",
            "[exp_4] Episode 1600 | Loss: 0.9625\n",
            "[exp_4] Episode 1650 | Loss: 0.9621\n",
            "[exp_4] Episode 1700 | Loss: 0.9551\n",
            "[exp_4] Episode 1750 | Loss: 0.9783\n",
            "[exp_4] Episode 1800 | Loss: 1.0044\n",
            "[exp_4] Episode 1850 | Loss: 0.9674\n",
            "[exp_4] Episode 1900 | Loss: 0.9342\n",
            "[exp_4] Episode 1950 | Loss: 0.8968\n",
            "[exp_4] Episode 2000 | Loss: 0.9379\n",
            "[exp_4] Validation Accuracy: 55.25%\n",
            "[exp_4] Episode 2050 | Loss: 0.9113\n",
            "[exp_4] Episode 2100 | Loss: 0.9582\n",
            "[exp_4] Episode 2150 | Loss: 0.9255\n",
            "[exp_4] Episode 2200 | Loss: 0.9201\n",
            "[exp_4] Episode 2250 | Loss: 0.8943\n",
            "[exp_4] Episode 2300 | Loss: 0.9067\n",
            "[exp_4] Episode 2350 | Loss: 0.9699\n",
            "[exp_4] Episode 2400 | Loss: 0.9758\n",
            "[exp_4] Episode 2450 | Loss: 0.8968\n",
            "[exp_4] Episode 2500 | Loss: 0.9672\n",
            "[exp_4] Validation Accuracy: 50.85%\n",
            "[exp_4] Episode 2550 | Loss: 0.8870\n",
            "[exp_4] Episode 2600 | Loss: 0.9156\n",
            "[exp_4] Episode 2650 | Loss: 0.8636\n",
            "[exp_4] Episode 2700 | Loss: 0.8661\n",
            "[exp_4] Episode 2750 | Loss: 0.8616\n",
            "[exp_4] Episode 2800 | Loss: 0.8963\n",
            "[exp_4] Episode 2850 | Loss: 0.9056\n",
            "[exp_4] Episode 2900 | Loss: 0.8208\n",
            "[exp_4] Episode 2950 | Loss: 0.8988\n",
            "[exp_4] Episode 3000 | Loss: 0.8576\n",
            "[exp_4] Validation Accuracy: 55.35%\n",
            "[exp_4] Episode 3050 | Loss: 0.8874\n",
            "[exp_4] Episode 3100 | Loss: 0.8254\n",
            "[exp_4] Episode 3150 | Loss: 0.8309\n",
            "[exp_4] Episode 3200 | Loss: 0.8316\n",
            "[exp_4] Episode 3250 | Loss: 0.8328\n",
            "[exp_4] Episode 3300 | Loss: 0.8970\n",
            "[exp_4] Episode 3350 | Loss: 0.8547\n",
            "[exp_4] Episode 3400 | Loss: 0.8401\n",
            "[exp_4] Episode 3450 | Loss: 0.8634\n",
            "[exp_4] Episode 3500 | Loss: 0.8323\n",
            "[exp_4] Validation Accuracy: 57.60%\n",
            "[exp_4] Episode 3550 | Loss: 0.9112\n",
            "[exp_4] Episode 3600 | Loss: 0.8826\n",
            "[exp_4] Episode 3650 | Loss: 0.8790\n",
            "[exp_4] Episode 3700 | Loss: 0.7996\n",
            "[exp_4] Episode 3750 | Loss: 0.7977\n",
            "[exp_4] Episode 3800 | Loss: 0.8496\n",
            "[exp_4] Episode 3850 | Loss: 0.8444\n",
            "[exp_4] Episode 3900 | Loss: 0.8509\n",
            "[exp_4] Episode 3950 | Loss: 0.8332\n",
            "[exp_4] Episode 4000 | Loss: 0.7806\n",
            "[exp_4] Validation Accuracy: 60.25%\n",
            "[exp_4] Episode 4050 | Loss: 0.8094\n",
            "[exp_4] Episode 4100 | Loss: 0.8678\n",
            "[exp_4] Episode 4150 | Loss: 0.8427\n",
            "[exp_4] Episode 4200 | Loss: 0.8788\n",
            "[exp_4] Episode 4250 | Loss: 0.7217\n",
            "[exp_4] Episode 4300 | Loss: 0.8535\n",
            "[exp_4] Episode 4350 | Loss: 0.7584\n",
            "[exp_4] Episode 4400 | Loss: 0.8419\n",
            "[exp_4] Episode 4450 | Loss: 0.7767\n",
            "[exp_4] Episode 4500 | Loss: 0.8132\n",
            "[exp_4] Validation Accuracy: 55.77%\n",
            "[exp_4] Episode 4550 | Loss: 0.8188\n",
            "[exp_4] Episode 4600 | Loss: 0.7773\n",
            "[exp_4] Episode 4650 | Loss: 0.7566\n",
            "[exp_4] Episode 4700 | Loss: 0.7608\n",
            "[exp_4] Episode 4750 | Loss: 0.7928\n",
            "[exp_4] Episode 4800 | Loss: 0.7938\n",
            "[exp_4] Episode 4850 | Loss: 0.7501\n",
            "[exp_4] Episode 4900 | Loss: 0.7244\n",
            "[exp_4] Episode 4950 | Loss: 0.7926\n",
            "[exp_4] Episode 5000 | Loss: 0.7793\n",
            "[exp_4] Validation Accuracy: 59.00%\n",
            "[exp_4] Episode 5050 | Loss: 0.7512\n",
            "[exp_4] Episode 5100 | Loss: 0.7386\n",
            "[exp_4] Episode 5150 | Loss: 0.7663\n",
            "[exp_4] Episode 5200 | Loss: 0.7886\n",
            "[exp_4] Episode 5250 | Loss: 0.7868\n",
            "[exp_4] Episode 5300 | Loss: 0.8043\n",
            "[exp_4] Episode 5350 | Loss: 0.7121\n",
            "[exp_4] Episode 5400 | Loss: 0.7759\n",
            "[exp_4] Episode 5450 | Loss: 0.8109\n",
            "[exp_4] Episode 5500 | Loss: 0.7214\n",
            "[exp_4] Validation Accuracy: 56.50%\n",
            "[exp_4] Episode 5550 | Loss: 0.7427\n",
            "[exp_4] Episode 5600 | Loss: 0.7199\n",
            "[exp_4] Episode 5650 | Loss: 0.7796\n",
            "[exp_4] Episode 5700 | Loss: 0.7943\n",
            "[exp_4] Episode 5750 | Loss: 0.7275\n",
            "[exp_4] Episode 5800 | Loss: 0.7930\n",
            "[exp_4] Episode 5850 | Loss: 0.7871\n",
            "[exp_4] Episode 5900 | Loss: 0.7246\n",
            "[exp_4] Episode 5950 | Loss: 0.7625\n",
            "[exp_4] Episode 6000 | Loss: 0.7901\n",
            "[exp_4] Validation Accuracy: 59.23%\n",
            "[exp_4] Episode 6050 | Loss: 0.7910\n",
            "[exp_4] Episode 6100 | Loss: 0.6343\n",
            "[exp_4] Episode 6150 | Loss: 0.6381\n",
            "[exp_4] Episode 6200 | Loss: 0.7107\n",
            "[exp_4] Episode 6250 | Loss: 0.7318\n",
            "[exp_4] Episode 6300 | Loss: 0.6748\n",
            "[exp_4] Episode 6350 | Loss: 0.6735\n",
            "[exp_4] Episode 6400 | Loss: 0.7359\n",
            "[exp_4] Episode 6450 | Loss: 0.7749\n",
            "[exp_4] Episode 6500 | Loss: 0.7585\n",
            "[exp_4] Validation Accuracy: 59.05%\n",
            "[exp_4] Episode 6550 | Loss: 0.7386\n",
            "[exp_4] Episode 6600 | Loss: 0.7409\n",
            "[exp_4] Episode 6650 | Loss: 0.6976\n",
            "[exp_4] Episode 6700 | Loss: 0.6627\n",
            "[exp_4] Episode 6750 | Loss: 0.6824\n",
            "[exp_4] Episode 6800 | Loss: 0.7436\n",
            "[exp_4] Episode 6850 | Loss: 0.7189\n",
            "[exp_4] Episode 6900 | Loss: 0.6355\n",
            "[exp_4] Episode 6950 | Loss: 0.7453\n",
            "[exp_4] Episode 7000 | Loss: 0.7248\n",
            "[exp_4] Validation Accuracy: 57.75%\n",
            "[exp_4] Episode 7050 | Loss: 0.6790\n",
            "[exp_4] Episode 7100 | Loss: 0.6576\n",
            "[exp_4] Episode 7150 | Loss: 0.7349\n",
            "[exp_4] Episode 7200 | Loss: 0.6180\n",
            "[exp_4] Episode 7250 | Loss: 0.6690\n",
            "[exp_4] Episode 7300 | Loss: 0.6969\n",
            "[exp_4] Episode 7350 | Loss: 0.6806\n",
            "[exp_4] Episode 7400 | Loss: 0.7151\n",
            "[exp_4] Episode 7450 | Loss: 0.6285\n",
            "[exp_4] Episode 7500 | Loss: 0.6689\n",
            "[exp_4] Validation Accuracy: 61.27%\n",
            "[exp_4] Episode 7550 | Loss: 0.6352\n",
            "[exp_4] Episode 7600 | Loss: 0.7026\n",
            "[exp_4] Episode 7650 | Loss: 0.6204\n",
            "[exp_4] Episode 7700 | Loss: 0.6211\n",
            "[exp_4] Episode 7750 | Loss: 0.6633\n",
            "[exp_4] Episode 7800 | Loss: 0.6965\n",
            "[exp_4] Episode 7850 | Loss: 0.6473\n",
            "[exp_4] Episode 7900 | Loss: 0.6628\n",
            "[exp_4] Episode 7950 | Loss: 0.6672\n",
            "[exp_4] Episode 8000 | Loss: 0.6612\n",
            "[exp_4] Validation Accuracy: 62.52%\n",
            "[exp_4] Episode 8050 | Loss: 0.6799\n",
            "[exp_4] Episode 8100 | Loss: 0.6387\n",
            "[exp_4] Episode 8150 | Loss: 0.6634\n",
            "[exp_4] Episode 8200 | Loss: 0.6639\n",
            "[exp_4] Episode 8250 | Loss: 0.6104\n",
            "[exp_4] Episode 8300 | Loss: 0.6808\n",
            "[exp_4] Episode 8350 | Loss: 0.6982\n",
            "[exp_4] Episode 8400 | Loss: 0.6963\n",
            "[exp_4] Episode 8450 | Loss: 0.6530\n",
            "[exp_4] Episode 8500 | Loss: 0.6580\n",
            "[exp_4] Validation Accuracy: 58.25%\n",
            "[exp_4] Episode 8550 | Loss: 0.6685\n",
            "[exp_4] Episode 8600 | Loss: 0.6391\n",
            "[exp_4] Episode 8650 | Loss: 0.5946\n",
            "[exp_4] Episode 8700 | Loss: 0.5653\n",
            "[exp_4] Episode 8750 | Loss: 0.6415\n",
            "[exp_4] Episode 8800 | Loss: 0.5712\n",
            "[exp_4] Episode 8850 | Loss: 0.5828\n",
            "[exp_4] Episode 8900 | Loss: 0.5923\n",
            "[exp_4] Episode 8950 | Loss: 0.6137\n",
            "[exp_4] Episode 9000 | Loss: 0.6476\n",
            "[exp_4] Validation Accuracy: 58.88%\n",
            "[exp_4] Episode 9050 | Loss: 0.6027\n",
            "[exp_4] Episode 9100 | Loss: 0.6384\n",
            "[exp_4] Episode 9150 | Loss: 0.6526\n",
            "[exp_4] Episode 9200 | Loss: 0.6343\n",
            "[exp_4] Episode 9250 | Loss: 0.6058\n",
            "[exp_4] Episode 9300 | Loss: 0.6355\n",
            "[exp_4] Episode 9350 | Loss: 0.6095\n",
            "[exp_4] Episode 9400 | Loss: 0.5785\n",
            "[exp_4] Episode 9450 | Loss: 0.5457\n",
            "[exp_4] Episode 9500 | Loss: 0.5327\n",
            "[exp_4] Validation Accuracy: 60.92%\n",
            "[exp_4] Episode 9550 | Loss: 0.6513\n",
            "[exp_4] Episode 9600 | Loss: 0.6188\n",
            "[exp_4] Episode 9650 | Loss: 0.6804\n",
            "[exp_4] Episode 9700 | Loss: 0.6445\n",
            "[exp_4] Episode 9750 | Loss: 0.5610\n",
            "[exp_4] Episode 9800 | Loss: 0.5988\n",
            "[exp_4] Episode 9850 | Loss: 0.5666\n",
            "[exp_4] Episode 9900 | Loss: 0.5917\n",
            "[exp_4] Episode 9950 | Loss: 0.6437\n",
            "[exp_4] Episode 10000 | Loss: 0.6617\n",
            "[exp_4] Validation Accuracy: 62.00%\n",
            "[exp_4] Episode 10050 | Loss: 0.6137\n",
            "[exp_4] Episode 10100 | Loss: 0.6124\n",
            "[exp_4] Episode 10150 | Loss: 0.6698\n",
            "[exp_4] Episode 10200 | Loss: 0.5707\n",
            "[exp_4] Episode 10250 | Loss: 0.5610\n",
            "[exp_4] Episode 10300 | Loss: 0.4922\n",
            "[exp_4] Episode 10350 | Loss: 0.5165\n",
            "[exp_4] Episode 10400 | Loss: 0.5641\n",
            "[exp_4] Episode 10450 | Loss: 0.6006\n",
            "[exp_4] Episode 10500 | Loss: 0.5307\n",
            "[exp_4] Validation Accuracy: 63.08%\n",
            "[exp_4] Episode 10550 | Loss: 0.5509\n",
            "[exp_4] Episode 10600 | Loss: 0.5389\n",
            "[exp_4] Episode 10650 | Loss: 0.5411\n",
            "[exp_4] Episode 10700 | Loss: 0.6290\n",
            "[exp_4] Episode 10750 | Loss: 0.5591\n",
            "[exp_4] Episode 10800 | Loss: 0.5877\n",
            "[exp_4] Episode 10850 | Loss: 0.5579\n",
            "[exp_4] Episode 10900 | Loss: 0.5401\n",
            "[exp_4] Episode 10950 | Loss: 0.5082\n",
            "[exp_4] Episode 11000 | Loss: 0.6034\n",
            "[exp_4] Validation Accuracy: 62.22%\n",
            "[exp_4] Episode 11050 | Loss: 0.5701\n",
            "[exp_4] Episode 11100 | Loss: 0.4998\n",
            "[exp_4] Episode 11150 | Loss: 0.5052\n",
            "[exp_4] Episode 11200 | Loss: 0.6199\n",
            "[exp_4] Episode 11250 | Loss: 0.6363\n",
            "[exp_4] Episode 11300 | Loss: 0.5238\n",
            "[exp_4] Episode 11350 | Loss: 0.5709\n",
            "[exp_4] Episode 11400 | Loss: 0.5565\n",
            "[exp_4] Episode 11450 | Loss: 0.4844\n",
            "[exp_4] Episode 11500 | Loss: 0.5651\n",
            "[exp_4] Validation Accuracy: 60.45%\n",
            "[exp_4] Episode 11550 | Loss: 0.5267\n",
            "[exp_4] Episode 11600 | Loss: 0.5952\n",
            "[exp_4] Episode 11650 | Loss: 0.6606\n",
            "[exp_4] Episode 11700 | Loss: 0.5542\n",
            "[exp_4] Episode 11750 | Loss: 0.5483\n",
            "[exp_4] Episode 11800 | Loss: 0.5438\n",
            "[exp_4] Episode 11850 | Loss: 0.5823\n",
            "[exp_4] Episode 11900 | Loss: 0.5362\n",
            "[exp_4] Episode 11950 | Loss: 0.5400\n",
            "[exp_4] Episode 12000 | Loss: 0.5077\n",
            "[exp_4] Validation Accuracy: 60.88%\n",
            "[exp_4] Episode 12050 | Loss: 0.5045\n",
            "[exp_4] Episode 12100 | Loss: 0.5511\n",
            "[exp_4] Episode 12150 | Loss: 0.5253\n",
            "[exp_4] Episode 12200 | Loss: 0.5459\n",
            "[exp_4] Episode 12250 | Loss: 0.5642\n",
            "[exp_4] Episode 12300 | Loss: 0.5852\n",
            "[exp_4] Episode 12350 | Loss: 0.5372\n",
            "[exp_4] Episode 12400 | Loss: 0.4930\n",
            "[exp_4] Episode 12450 | Loss: 0.4861\n",
            "[exp_4] Episode 12500 | Loss: 0.4823\n",
            "[exp_4] Validation Accuracy: 62.85%\n",
            "[exp_4] Episode 12550 | Loss: 0.5331\n",
            "[exp_4] Episode 12600 | Loss: 0.5933\n",
            "[exp_4] Episode 12650 | Loss: 0.5556\n",
            "[exp_4] Episode 12700 | Loss: 0.5374\n",
            "[exp_4] Episode 12750 | Loss: 0.5301\n",
            "[exp_4] Episode 12800 | Loss: 0.4958\n",
            "[exp_4] Episode 12850 | Loss: 0.5062\n",
            "[exp_4] Episode 12900 | Loss: 0.4713\n",
            "[exp_4] Episode 12950 | Loss: 0.5130\n",
            "[exp_4] Episode 13000 | Loss: 0.5276\n",
            "[exp_4] Validation Accuracy: 62.55%\n",
            "[exp_4] Episode 13050 | Loss: 0.4584\n",
            "[exp_4] Episode 13100 | Loss: 0.5832\n",
            "[exp_4] Episode 13150 | Loss: 0.5639\n",
            "[exp_4] Episode 13200 | Loss: 0.4311\n",
            "[exp_4] Episode 13250 | Loss: 0.5236\n",
            "[exp_4] Episode 13300 | Loss: 0.4488\n",
            "[exp_4] Episode 13350 | Loss: 0.4810\n",
            "[exp_4] Episode 13400 | Loss: 0.4494\n",
            "[exp_4] Episode 13450 | Loss: 0.4674\n",
            "[exp_4] Episode 13500 | Loss: 0.4841\n",
            "[exp_4] Validation Accuracy: 64.55%\n",
            "[exp_4] Episode 13550 | Loss: 0.4590\n",
            "[exp_4] Episode 13600 | Loss: 0.5039\n",
            "[exp_4] Episode 13650 | Loss: 0.4801\n",
            "[exp_4] Episode 13700 | Loss: 0.4528\n",
            "[exp_4] Episode 13750 | Loss: 0.4616\n",
            "[exp_4] Episode 13800 | Loss: 0.5000\n",
            "[exp_4] Episode 13850 | Loss: 0.4901\n",
            "[exp_4] Episode 13900 | Loss: 0.4172\n",
            "[exp_4] Episode 13950 | Loss: 0.3935\n",
            "[exp_4] Episode 14000 | Loss: 0.4941\n",
            "[exp_4] Validation Accuracy: 64.48%\n",
            "[exp_4] Episode 14050 | Loss: 0.4196\n",
            "[exp_4] Episode 14100 | Loss: 0.4863\n",
            "[exp_4] Episode 14150 | Loss: 0.5126\n",
            "[exp_4] Episode 14200 | Loss: 0.4734\n",
            "[exp_4] Episode 14250 | Loss: 0.5146\n",
            "[exp_4] Episode 14300 | Loss: 0.4153\n",
            "[exp_4] Episode 14350 | Loss: 0.4265\n",
            "[exp_4] Episode 14400 | Loss: 0.4634\n",
            "[exp_4] Episode 14450 | Loss: 0.4140\n",
            "[exp_4] Episode 14500 | Loss: 0.4727\n",
            "[exp_4] Validation Accuracy: 62.98%\n",
            "[exp_4] Episode 14550 | Loss: 0.5585\n",
            "[exp_4] Episode 14600 | Loss: 0.4704\n",
            "[exp_4] Episode 14650 | Loss: 0.5791\n",
            "[exp_4] Episode 14700 | Loss: 0.4506\n",
            "[exp_4] Episode 14750 | Loss: 0.3305\n",
            "[exp_4] Episode 14800 | Loss: 0.3492\n",
            "[exp_4] Episode 14850 | Loss: 0.4570\n",
            "[exp_4] Episode 14900 | Loss: 0.4788\n",
            "[exp_4] Episode 14950 | Loss: 0.3916\n",
            "[exp_4] Episode 15000 | Loss: 0.4972\n",
            "[exp_4] Validation Accuracy: 67.85%\n",
            "[exp_4] Episode 15050 | Loss: 0.5358\n",
            "[exp_4] Episode 15100 | Loss: 0.4267\n",
            "[exp_4] Episode 15150 | Loss: 0.4692\n",
            "[exp_4] Episode 15200 | Loss: 0.4635\n",
            "[exp_4] Episode 15250 | Loss: 0.4407\n",
            "[exp_4] Episode 15300 | Loss: 0.4353\n",
            "[exp_4] Episode 15350 | Loss: 0.4864\n",
            "[exp_4] Episode 15400 | Loss: 0.4868\n",
            "[exp_4] Episode 15450 | Loss: 0.4094\n",
            "[exp_4] Episode 15500 | Loss: 0.4006\n",
            "[exp_4] Validation Accuracy: 64.70%\n",
            "[exp_4] Episode 15550 | Loss: 0.3906\n",
            "[exp_4] Episode 15600 | Loss: 0.3541\n",
            "[exp_4] Episode 15650 | Loss: 0.4781\n",
            "[exp_4] Episode 15700 | Loss: 0.5055\n",
            "[exp_4] Episode 15750 | Loss: 0.4181\n",
            "[exp_4] Episode 15800 | Loss: 0.4043\n",
            "[exp_4] Episode 15850 | Loss: 0.4659\n",
            "[exp_4] Episode 15900 | Loss: 0.4337\n",
            "[exp_4] Episode 15950 | Loss: 0.4411\n",
            "[exp_4] Episode 16000 | Loss: 0.4048\n",
            "[exp_4] Validation Accuracy: 64.22%\n",
            "[exp_4] Episode 16050 | Loss: 0.4397\n",
            "[exp_4] Episode 16100 | Loss: 0.3779\n",
            "[exp_4] Episode 16150 | Loss: 0.4361\n",
            "[exp_4] Episode 16200 | Loss: 0.3981\n",
            "[exp_4] Episode 16250 | Loss: 0.4553\n",
            "[exp_4] Episode 16300 | Loss: 0.3445\n",
            "[exp_4] Episode 16350 | Loss: 0.3787\n",
            "[exp_4] Episode 16400 | Loss: 0.3677\n",
            "[exp_4] Episode 16450 | Loss: 0.3690\n",
            "[exp_4] Episode 16500 | Loss: 0.4203\n",
            "[exp_4] Validation Accuracy: 64.92%\n",
            "[exp_4] Episode 16550 | Loss: 0.4057\n",
            "[exp_4] Episode 16600 | Loss: 0.4396\n",
            "[exp_4] Episode 16650 | Loss: 0.3987\n",
            "[exp_4] Episode 16700 | Loss: 0.4557\n",
            "[exp_4] Episode 16750 | Loss: 0.4057\n",
            "[exp_4] Episode 16800 | Loss: 0.3955\n",
            "[exp_4] Episode 16850 | Loss: 0.3651\n",
            "[exp_4] Episode 16900 | Loss: 0.4420\n",
            "[exp_4] Episode 16950 | Loss: 0.4252\n",
            "[exp_4] Episode 17000 | Loss: 0.3961\n",
            "[exp_4] Validation Accuracy: 69.80%\n",
            "[exp_4] Episode 17050 | Loss: 0.3798\n",
            "[exp_4] Episode 17100 | Loss: 0.4169\n",
            "[exp_4] Episode 17150 | Loss: 0.4711\n",
            "[exp_4] Episode 17200 | Loss: 0.4497\n",
            "[exp_4] Episode 17250 | Loss: 0.4483\n",
            "[exp_4] Episode 17300 | Loss: 0.3661\n",
            "[exp_4] Episode 17350 | Loss: 0.3987\n",
            "[exp_4] Episode 17400 | Loss: 0.4219\n",
            "[exp_4] Episode 17450 | Loss: 0.3670\n",
            "[exp_4] Episode 17500 | Loss: 0.4467\n",
            "[exp_4] Validation Accuracy: 66.15%\n",
            "[exp_4] Episode 17550 | Loss: 0.3815\n",
            "[exp_4] Episode 17600 | Loss: 0.4553\n",
            "[exp_4] Episode 17650 | Loss: 0.3918\n",
            "[exp_4] Episode 17700 | Loss: 0.3427\n",
            "[exp_4] Episode 17750 | Loss: 0.3200\n",
            "[exp_4] Episode 17800 | Loss: 0.3736\n",
            "[exp_4] Episode 17850 | Loss: 0.4461\n",
            "[exp_4] Episode 17900 | Loss: 0.3601\n",
            "[exp_4] Episode 17950 | Loss: 0.4141\n",
            "[exp_4] Episode 18000 | Loss: 0.4243\n",
            "[exp_4] Validation Accuracy: 63.22%\n",
            "[exp_4] Episode 18050 | Loss: 0.3374\n",
            "[exp_4] Episode 18100 | Loss: 0.3723\n",
            "[exp_4] Episode 18150 | Loss: 0.4128\n",
            "[exp_4] Episode 18200 | Loss: 0.3380\n",
            "[exp_4] Episode 18250 | Loss: 0.3613\n",
            "[exp_4] Episode 18300 | Loss: 0.3508\n",
            "[exp_4] Episode 18350 | Loss: 0.3998\n",
            "[exp_4] Episode 18400 | Loss: 0.4443\n",
            "[exp_4] Episode 18450 | Loss: 0.3542\n",
            "[exp_4] Episode 18500 | Loss: 0.3742\n",
            "[exp_4] Validation Accuracy: 66.05%\n",
            "[exp_4] Episode 18550 | Loss: 0.3589\n",
            "[exp_4] Episode 18600 | Loss: 0.3878\n",
            "[exp_4] Episode 18650 | Loss: 0.4438\n",
            "[exp_4] Episode 18700 | Loss: 0.3990\n",
            "[exp_4] Episode 18750 | Loss: 0.3727\n",
            "[exp_4] Episode 18800 | Loss: 0.3869\n",
            "[exp_4] Episode 18850 | Loss: 0.3962\n",
            "[exp_4] Episode 18900 | Loss: 0.3669\n",
            "[exp_4] Episode 18950 | Loss: 0.3695\n",
            "[exp_4] Episode 19000 | Loss: 0.3596\n",
            "[exp_4] Validation Accuracy: 64.22%\n",
            "[exp_4] Episode 19050 | Loss: 0.4207\n",
            "[exp_4] Episode 19100 | Loss: 0.3812\n",
            "[exp_4] Episode 19150 | Loss: 0.3582\n",
            "[exp_4] Episode 19200 | Loss: 0.4089\n",
            "[exp_4] Episode 19250 | Loss: 0.3626\n",
            "[exp_4] Episode 19300 | Loss: 0.3516\n",
            "[exp_4] Episode 19350 | Loss: 0.3582\n",
            "[exp_4] Episode 19400 | Loss: 0.4433\n",
            "[exp_4] Episode 19450 | Loss: 0.3240\n",
            "[exp_4] Episode 19500 | Loss: 0.3590\n",
            "[exp_4] Validation Accuracy: 64.40%\n",
            "[exp_4] Episode 19550 | Loss: 0.2879\n",
            "[exp_4] Episode 19600 | Loss: 0.3260\n",
            "[exp_4] Episode 19650 | Loss: 0.3731\n",
            "[exp_4] Episode 19700 | Loss: 0.3511\n",
            "[exp_4] Episode 19750 | Loss: 0.3165\n",
            "[exp_4] Episode 19800 | Loss: 0.3872\n",
            "[exp_4] Episode 19850 | Loss: 0.3925\n",
            "[exp_4] Episode 19900 | Loss: 0.3234\n",
            "[exp_4] Episode 19950 | Loss: 0.3281\n",
            "[exp_4] Episode 20000 | Loss: 0.3649\n",
            "[exp_4] Validation Accuracy: 67.00%\n",
            "[exp_4] Episode 20050 | Loss: 0.3082\n",
            "[exp_4] Episode 20100 | Loss: 0.3812\n",
            "[exp_4] Episode 20150 | Loss: 0.3007\n",
            "[exp_4] Episode 20200 | Loss: 0.3221\n",
            "[exp_4] Episode 20250 | Loss: 0.3109\n",
            "[exp_4] Episode 20300 | Loss: 0.3527\n",
            "[exp_4] Episode 20350 | Loss: 0.2981\n",
            "[exp_4] Episode 20400 | Loss: 0.3043\n",
            "[exp_4] Episode 20450 | Loss: 0.3713\n",
            "[exp_4] Episode 20500 | Loss: 0.3846\n",
            "[exp_4] Validation Accuracy: 64.40%\n",
            "[exp_4] Episode 20550 | Loss: 0.3311\n",
            "[exp_4] Episode 20600 | Loss: 0.3126\n",
            "[exp_4] Episode 20650 | Loss: 0.3230\n",
            "[exp_4] Episode 20700 | Loss: 0.3633\n",
            "[exp_4] Episode 20750 | Loss: 0.3303\n",
            "[exp_4] Episode 20800 | Loss: 0.3117\n",
            "[exp_4] Episode 20850 | Loss: 0.3413\n",
            "[exp_4] Episode 20900 | Loss: 0.3542\n",
            "[exp_4] Episode 20950 | Loss: 0.3462\n",
            "[exp_4] Episode 21000 | Loss: 0.3141\n",
            "[exp_4] Validation Accuracy: 67.60%\n",
            "[exp_4] Episode 21050 | Loss: 0.2968\n",
            "[exp_4] Episode 21100 | Loss: 0.3282\n",
            "[exp_4] Episode 21150 | Loss: 0.3900\n",
            "[exp_4] Episode 21200 | Loss: 0.3373\n",
            "[exp_4] Episode 21250 | Loss: 0.3339\n",
            "[exp_4] Episode 21300 | Loss: 0.3772\n",
            "[exp_4] Episode 21350 | Loss: 0.3332\n",
            "[exp_4] Episode 21400 | Loss: 0.3051\n",
            "[exp_4] Episode 21450 | Loss: 0.2554\n",
            "[exp_4] Episode 21500 | Loss: 0.2826\n",
            "[exp_4] Validation Accuracy: 64.08%\n",
            "[exp_4] Episode 21550 | Loss: 0.2701\n",
            "[exp_4] Episode 21600 | Loss: 0.3340\n",
            "[exp_4] Episode 21650 | Loss: 0.2708\n",
            "[exp_4] Episode 21700 | Loss: 0.3323\n",
            "[exp_4] Episode 21750 | Loss: 0.3303\n",
            "[exp_4] Episode 21800 | Loss: 0.2785\n",
            "[exp_4] Episode 21850 | Loss: 0.2732\n",
            "[exp_4] Episode 21900 | Loss: 0.3349\n",
            "[exp_4] Episode 21950 | Loss: 0.2824\n",
            "[exp_4] Episode 22000 | Loss: 0.3428\n",
            "[exp_4] Validation Accuracy: 65.08%\n",
            "[exp_4] Early stopping triggered at episode 22000\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_5 (shot: 1, meta_batch_size: 8, do_training: True)\n",
            "[exp_5] Episode 0 | Loss: 0.9434\n",
            "[exp_5] Episode 50 | Loss: 2.1088\n",
            "[exp_5] Episode 100 | Loss: 1.3369\n",
            "[exp_5] Episode 150 | Loss: 1.2560\n",
            "[exp_5] Episode 200 | Loss: 1.1931\n",
            "[exp_5] Episode 250 | Loss: 1.2412\n",
            "[exp_5] Episode 300 | Loss: 1.1723\n",
            "[exp_5] Episode 350 | Loss: 1.2055\n",
            "[exp_5] Episode 400 | Loss: 1.1712\n",
            "[exp_5] Episode 450 | Loss: 1.2475\n",
            "[exp_5] Episode 500 | Loss: 1.1750\n",
            "[exp_5] Validation Accuracy: 41.27%\n",
            "[exp_5] Episode 550 | Loss: 1.1552\n",
            "[exp_5] Episode 600 | Loss: 1.2105\n",
            "[exp_5] Episode 650 | Loss: 1.1518\n",
            "[exp_5] Episode 700 | Loss: 1.0935\n",
            "[exp_5] Episode 750 | Loss: 1.1066\n",
            "[exp_5] Episode 800 | Loss: 1.0486\n",
            "[exp_5] Episode 850 | Loss: 1.0840\n",
            "[exp_5] Episode 900 | Loss: 1.1014\n",
            "[exp_5] Episode 950 | Loss: 1.0999\n",
            "[exp_5] Episode 1000 | Loss: 1.0949\n",
            "[exp_5] Validation Accuracy: 45.95%\n",
            "[exp_5] Episode 1050 | Loss: 1.1146\n",
            "[exp_5] Episode 1100 | Loss: 1.0682\n",
            "[exp_5] Episode 1150 | Loss: 1.0442\n",
            "[exp_5] Episode 1200 | Loss: 1.0650\n",
            "[exp_5] Episode 1250 | Loss: 1.0482\n",
            "[exp_5] Episode 1300 | Loss: 1.0119\n",
            "[exp_5] Episode 1350 | Loss: 0.9601\n",
            "[exp_5] Episode 1400 | Loss: 1.0385\n",
            "[exp_5] Episode 1450 | Loss: 1.0312\n",
            "[exp_5] Episode 1500 | Loss: 1.0281\n",
            "[exp_5] Validation Accuracy: 53.77%\n",
            "[exp_5] Episode 1550 | Loss: 0.9928\n",
            "[exp_5] Episode 1600 | Loss: 0.9584\n",
            "[exp_5] Episode 1650 | Loss: 0.9839\n",
            "[exp_5] Episode 1700 | Loss: 0.9429\n",
            "[exp_5] Episode 1750 | Loss: 0.9816\n",
            "[exp_5] Episode 1800 | Loss: 1.0016\n",
            "[exp_5] Episode 1850 | Loss: 0.9641\n",
            "[exp_5] Episode 1900 | Loss: 0.9526\n",
            "[exp_5] Episode 1950 | Loss: 0.9025\n",
            "[exp_5] Episode 2000 | Loss: 0.9370\n",
            "[exp_5] Validation Accuracy: 55.88%\n",
            "[exp_5] Episode 2050 | Loss: 0.9200\n",
            "[exp_5] Episode 2100 | Loss: 0.9462\n",
            "[exp_5] Episode 2150 | Loss: 0.9237\n",
            "[exp_5] Episode 2200 | Loss: 0.8975\n",
            "[exp_5] Episode 2250 | Loss: 0.8887\n",
            "[exp_5] Episode 2300 | Loss: 0.8683\n",
            "[exp_5] Episode 2350 | Loss: 0.9755\n",
            "[exp_5] Episode 2400 | Loss: 0.9542\n",
            "[exp_5] Episode 2450 | Loss: 0.8818\n",
            "[exp_5] Episode 2500 | Loss: 0.9320\n",
            "[exp_5] Validation Accuracy: 52.80%\n",
            "[exp_5] Episode 2550 | Loss: 0.8440\n",
            "[exp_5] Episode 2600 | Loss: 0.9041\n",
            "[exp_5] Episode 2650 | Loss: 0.8634\n",
            "[exp_5] Episode 2700 | Loss: 0.8756\n",
            "[exp_5] Episode 2750 | Loss: 0.8608\n",
            "[exp_5] Episode 2800 | Loss: 0.8837\n",
            "[exp_5] Episode 2850 | Loss: 0.8766\n",
            "[exp_5] Episode 2900 | Loss: 0.8063\n",
            "[exp_5] Episode 2950 | Loss: 0.8960\n",
            "[exp_5] Episode 3000 | Loss: 0.8362\n",
            "[exp_5] Validation Accuracy: 55.10%\n",
            "[exp_5] Episode 3050 | Loss: 0.8621\n",
            "[exp_5] Episode 3100 | Loss: 0.8374\n",
            "[exp_5] Episode 3150 | Loss: 0.8158\n",
            "[exp_5] Episode 3200 | Loss: 0.8360\n",
            "[exp_5] Episode 3250 | Loss: 0.8091\n",
            "[exp_5] Episode 3300 | Loss: 0.8958\n",
            "[exp_5] Episode 3350 | Loss: 0.8288\n",
            "[exp_5] Episode 3400 | Loss: 0.8254\n",
            "[exp_5] Episode 3450 | Loss: 0.8477\n",
            "[exp_5] Episode 3500 | Loss: 0.8256\n",
            "[exp_5] Validation Accuracy: 57.03%\n",
            "[exp_5] Episode 3550 | Loss: 0.8830\n",
            "[exp_5] Episode 3600 | Loss: 0.8537\n",
            "[exp_5] Episode 3650 | Loss: 0.8653\n",
            "[exp_5] Episode 3700 | Loss: 0.7862\n",
            "[exp_5] Episode 3750 | Loss: 0.8082\n",
            "[exp_5] Episode 3800 | Loss: 0.8028\n",
            "[exp_5] Episode 3850 | Loss: 0.8260\n",
            "[exp_5] Episode 3900 | Loss: 0.8478\n",
            "[exp_5] Episode 3950 | Loss: 0.7912\n",
            "[exp_5] Episode 4000 | Loss: 0.7949\n",
            "[exp_5] Validation Accuracy: 58.98%\n",
            "[exp_5] Episode 4050 | Loss: 0.8001\n",
            "[exp_5] Episode 4100 | Loss: 0.8500\n",
            "[exp_5] Episode 4150 | Loss: 0.8151\n",
            "[exp_5] Episode 4200 | Loss: 0.8559\n",
            "[exp_5] Episode 4250 | Loss: 0.7274\n",
            "[exp_5] Episode 4300 | Loss: 0.8633\n",
            "[exp_5] Episode 4350 | Loss: 0.7356\n",
            "[exp_5] Episode 4400 | Loss: 0.8452\n",
            "[exp_5] Episode 4450 | Loss: 0.7939\n",
            "[exp_5] Episode 4500 | Loss: 0.8088\n",
            "[exp_5] Validation Accuracy: 58.90%\n",
            "[exp_5] Episode 4550 | Loss: 0.7557\n",
            "[exp_5] Episode 4600 | Loss: 0.7559\n",
            "[exp_5] Episode 4650 | Loss: 0.7466\n",
            "[exp_5] Episode 4700 | Loss: 0.7563\n",
            "[exp_5] Episode 4750 | Loss: 0.8012\n",
            "[exp_5] Episode 4800 | Loss: 0.7758\n",
            "[exp_5] Episode 4850 | Loss: 0.7720\n",
            "[exp_5] Episode 4900 | Loss: 0.7224\n",
            "[exp_5] Episode 4950 | Loss: 0.7885\n",
            "[exp_5] Episode 5000 | Loss: 0.7525\n",
            "[exp_5] Validation Accuracy: 58.10%\n",
            "[exp_5] Episode 5050 | Loss: 0.7637\n",
            "[exp_5] Episode 5100 | Loss: 0.7466\n",
            "[exp_5] Episode 5150 | Loss: 0.7731\n",
            "[exp_5] Episode 5200 | Loss: 0.7673\n",
            "[exp_5] Episode 5250 | Loss: 0.7327\n",
            "[exp_5] Episode 5300 | Loss: 0.7821\n",
            "[exp_5] Episode 5350 | Loss: 0.7128\n",
            "[exp_5] Episode 5400 | Loss: 0.7777\n",
            "[exp_5] Episode 5450 | Loss: 0.8039\n",
            "[exp_5] Episode 5500 | Loss: 0.7262\n",
            "[exp_5] Validation Accuracy: 57.90%\n",
            "[exp_5] Episode 5550 | Loss: 0.7066\n",
            "[exp_5] Episode 5600 | Loss: 0.7119\n",
            "[exp_5] Episode 5650 | Loss: 0.7953\n",
            "[exp_5] Episode 5700 | Loss: 0.7697\n",
            "[exp_5] Episode 5750 | Loss: 0.7279\n",
            "[exp_5] Episode 5800 | Loss: 0.7495\n",
            "[exp_5] Episode 5850 | Loss: 0.7718\n",
            "[exp_5] Episode 5900 | Loss: 0.6993\n",
            "[exp_5] Episode 5950 | Loss: 0.7158\n",
            "[exp_5] Episode 6000 | Loss: 0.7282\n",
            "[exp_5] Validation Accuracy: 59.38%\n",
            "[exp_5] Episode 6050 | Loss: 0.7969\n",
            "[exp_5] Episode 6100 | Loss: 0.6325\n",
            "[exp_5] Episode 6150 | Loss: 0.6330\n",
            "[exp_5] Episode 6200 | Loss: 0.7091\n",
            "[exp_5] Episode 6250 | Loss: 0.7355\n",
            "[exp_5] Episode 6300 | Loss: 0.6903\n",
            "[exp_5] Episode 6350 | Loss: 0.6523\n",
            "[exp_5] Episode 6400 | Loss: 0.7320\n",
            "[exp_5] Episode 6450 | Loss: 0.7546\n",
            "[exp_5] Episode 6500 | Loss: 0.7601\n",
            "[exp_5] Validation Accuracy: 59.55%\n",
            "[exp_5] Episode 6550 | Loss: 0.6954\n",
            "[exp_5] Episode 6600 | Loss: 0.7520\n",
            "[exp_5] Episode 6650 | Loss: 0.6959\n",
            "[exp_5] Episode 6700 | Loss: 0.6466\n",
            "[exp_5] Episode 6750 | Loss: 0.6953\n",
            "[exp_5] Episode 6800 | Loss: 0.7323\n",
            "[exp_5] Episode 6850 | Loss: 0.6881\n",
            "[exp_5] Episode 6900 | Loss: 0.6461\n",
            "[exp_5] Episode 6950 | Loss: 0.6973\n",
            "[exp_5] Episode 7000 | Loss: 0.7065\n",
            "[exp_5] Validation Accuracy: 58.45%\n",
            "[exp_5] Episode 7050 | Loss: 0.6733\n",
            "[exp_5] Episode 7100 | Loss: 0.6162\n",
            "[exp_5] Episode 7150 | Loss: 0.7164\n",
            "[exp_5] Episode 7200 | Loss: 0.6067\n",
            "[exp_5] Episode 7250 | Loss: 0.6628\n",
            "[exp_5] Episode 7300 | Loss: 0.6888\n",
            "[exp_5] Episode 7350 | Loss: 0.6759\n",
            "[exp_5] Episode 7400 | Loss: 0.6865\n",
            "[exp_5] Episode 7450 | Loss: 0.6359\n",
            "[exp_5] Episode 7500 | Loss: 0.6738\n",
            "[exp_5] Validation Accuracy: 62.48%\n",
            "[exp_5] Episode 7550 | Loss: 0.6218\n",
            "[exp_5] Episode 7600 | Loss: 0.6929\n",
            "[exp_5] Episode 7650 | Loss: 0.6334\n",
            "[exp_5] Episode 7700 | Loss: 0.5971\n",
            "[exp_5] Episode 7750 | Loss: 0.6334\n",
            "[exp_5] Episode 7800 | Loss: 0.6441\n",
            "[exp_5] Episode 7850 | Loss: 0.6363\n",
            "[exp_5] Episode 7900 | Loss: 0.6853\n",
            "[exp_5] Episode 7950 | Loss: 0.6331\n",
            "[exp_5] Episode 8000 | Loss: 0.6321\n",
            "[exp_5] Validation Accuracy: 62.40%\n",
            "[exp_5] Episode 8050 | Loss: 0.6525\n",
            "[exp_5] Episode 8100 | Loss: 0.6389\n",
            "[exp_5] Episode 8150 | Loss: 0.6587\n",
            "[exp_5] Episode 8200 | Loss: 0.6436\n",
            "[exp_5] Episode 8250 | Loss: 0.5900\n",
            "[exp_5] Episode 8300 | Loss: 0.6930\n",
            "[exp_5] Episode 8350 | Loss: 0.6898\n",
            "[exp_5] Episode 8400 | Loss: 0.6658\n",
            "[exp_5] Episode 8450 | Loss: 0.6223\n",
            "[exp_5] Episode 8500 | Loss: 0.6560\n",
            "[exp_5] Validation Accuracy: 60.92%\n",
            "[exp_5] Episode 8550 | Loss: 0.6263\n",
            "[exp_5] Episode 8600 | Loss: 0.6551\n",
            "[exp_5] Episode 8650 | Loss: 0.5634\n",
            "[exp_5] Episode 8700 | Loss: 0.5713\n",
            "[exp_5] Episode 8750 | Loss: 0.6218\n",
            "[exp_5] Episode 8800 | Loss: 0.5596\n",
            "[exp_5] Episode 8850 | Loss: 0.5771\n",
            "[exp_5] Episode 8900 | Loss: 0.5663\n",
            "[exp_5] Episode 8950 | Loss: 0.6050\n",
            "[exp_5] Episode 9000 | Loss: 0.6338\n",
            "[exp_5] Validation Accuracy: 59.95%\n",
            "[exp_5] Episode 9050 | Loss: 0.6065\n",
            "[exp_5] Episode 9100 | Loss: 0.6344\n",
            "[exp_5] Episode 9150 | Loss: 0.6174\n",
            "[exp_5] Episode 9200 | Loss: 0.5921\n",
            "[exp_5] Episode 9250 | Loss: 0.6061\n",
            "[exp_5] Episode 9300 | Loss: 0.5831\n",
            "[exp_5] Episode 9350 | Loss: 0.5827\n",
            "[exp_5] Episode 9400 | Loss: 0.5784\n",
            "[exp_5] Episode 9450 | Loss: 0.5351\n",
            "[exp_5] Episode 9500 | Loss: 0.5067\n",
            "[exp_5] Validation Accuracy: 59.67%\n",
            "[exp_5] Episode 9550 | Loss: 0.6137\n",
            "[exp_5] Episode 9600 | Loss: 0.5936\n",
            "[exp_5] Episode 9650 | Loss: 0.6578\n",
            "[exp_5] Episode 9700 | Loss: 0.6510\n",
            "[exp_5] Episode 9750 | Loss: 0.5415\n",
            "[exp_5] Episode 9800 | Loss: 0.5781\n",
            "[exp_5] Episode 9850 | Loss: 0.5560\n",
            "[exp_5] Episode 9900 | Loss: 0.5733\n",
            "[exp_5] Episode 9950 | Loss: 0.6395\n",
            "[exp_5] Episode 10000 | Loss: 0.6265\n",
            "[exp_5] Validation Accuracy: 63.52%\n",
            "[exp_5] Episode 10050 | Loss: 0.5982\n",
            "[exp_5] Episode 10100 | Loss: 0.5741\n",
            "[exp_5] Episode 10150 | Loss: 0.6432\n",
            "[exp_5] Episode 10200 | Loss: 0.5560\n",
            "[exp_5] Episode 10250 | Loss: 0.5350\n",
            "[exp_5] Episode 10300 | Loss: 0.4718\n",
            "[exp_5] Episode 10350 | Loss: 0.4849\n",
            "[exp_5] Episode 10400 | Loss: 0.5027\n",
            "[exp_5] Episode 10450 | Loss: 0.5736\n",
            "[exp_5] Episode 10500 | Loss: 0.5340\n",
            "[exp_5] Validation Accuracy: 61.05%\n",
            "[exp_5] Episode 10550 | Loss: 0.5305\n",
            "[exp_5] Episode 10600 | Loss: 0.4980\n",
            "[exp_5] Episode 10650 | Loss: 0.5116\n",
            "[exp_5] Episode 10700 | Loss: 0.5906\n",
            "[exp_5] Episode 10750 | Loss: 0.5284\n",
            "[exp_5] Episode 10800 | Loss: 0.5843\n",
            "[exp_5] Episode 10850 | Loss: 0.5456\n",
            "[exp_5] Episode 10900 | Loss: 0.5389\n",
            "[exp_5] Episode 10950 | Loss: 0.5257\n",
            "[exp_5] Episode 11000 | Loss: 0.5853\n",
            "[exp_5] Validation Accuracy: 62.80%\n",
            "[exp_5] Episode 11050 | Loss: 0.5467\n",
            "[exp_5] Episode 11100 | Loss: 0.4989\n",
            "[exp_5] Episode 11150 | Loss: 0.4629\n",
            "[exp_5] Episode 11200 | Loss: 0.6227\n",
            "[exp_5] Episode 11250 | Loss: 0.6356\n",
            "[exp_5] Episode 11300 | Loss: 0.5283\n",
            "[exp_5] Episode 11350 | Loss: 0.5556\n",
            "[exp_5] Episode 11400 | Loss: 0.5121\n",
            "[exp_5] Episode 11450 | Loss: 0.4746\n",
            "[exp_5] Episode 11500 | Loss: 0.5419\n",
            "[exp_5] Validation Accuracy: 61.88%\n",
            "[exp_5] Episode 11550 | Loss: 0.4928\n",
            "[exp_5] Episode 11600 | Loss: 0.5848\n",
            "[exp_5] Episode 11650 | Loss: 0.6167\n",
            "[exp_5] Episode 11700 | Loss: 0.4978\n",
            "[exp_5] Episode 11750 | Loss: 0.5244\n",
            "[exp_5] Episode 11800 | Loss: 0.4957\n",
            "[exp_5] Episode 11850 | Loss: 0.5286\n",
            "[exp_5] Episode 11900 | Loss: 0.5236\n",
            "[exp_5] Episode 11950 | Loss: 0.5282\n",
            "[exp_5] Episode 12000 | Loss: 0.4934\n",
            "[exp_5] Validation Accuracy: 62.90%\n",
            "[exp_5] Episode 12050 | Loss: 0.5240\n",
            "[exp_5] Episode 12100 | Loss: 0.5520\n",
            "[exp_5] Episode 12150 | Loss: 0.5166\n",
            "[exp_5] Episode 12200 | Loss: 0.5303\n",
            "[exp_5] Episode 12250 | Loss: 0.5559\n",
            "[exp_5] Episode 12300 | Loss: 0.5218\n",
            "[exp_5] Episode 12350 | Loss: 0.5272\n",
            "[exp_5] Episode 12400 | Loss: 0.4632\n",
            "[exp_5] Episode 12450 | Loss: 0.4650\n",
            "[exp_5] Episode 12500 | Loss: 0.4649\n",
            "[exp_5] Validation Accuracy: 63.73%\n",
            "[exp_5] Episode 12550 | Loss: 0.5429\n",
            "[exp_5] Episode 12600 | Loss: 0.5833\n",
            "[exp_5] Episode 12650 | Loss: 0.5434\n",
            "[exp_5] Episode 12700 | Loss: 0.5111\n",
            "[exp_5] Episode 12750 | Loss: 0.5501\n",
            "[exp_5] Episode 12800 | Loss: 0.4978\n",
            "[exp_5] Episode 12850 | Loss: 0.4931\n",
            "[exp_5] Episode 12900 | Loss: 0.4904\n",
            "[exp_5] Episode 12950 | Loss: 0.5033\n",
            "[exp_5] Episode 13000 | Loss: 0.5300\n",
            "[exp_5] Validation Accuracy: 63.20%\n",
            "[exp_5] Episode 13050 | Loss: 0.4403\n",
            "[exp_5] Episode 13100 | Loss: 0.5185\n",
            "[exp_5] Episode 13150 | Loss: 0.5351\n",
            "[exp_5] Episode 13200 | Loss: 0.4125\n",
            "[exp_5] Episode 13250 | Loss: 0.5103\n",
            "[exp_5] Episode 13300 | Loss: 0.4274\n",
            "[exp_5] Episode 13350 | Loss: 0.4722\n",
            "[exp_5] Episode 13400 | Loss: 0.4381\n",
            "[exp_5] Episode 13450 | Loss: 0.4559\n",
            "[exp_5] Episode 13500 | Loss: 0.4871\n",
            "[exp_5] Validation Accuracy: 63.52%\n",
            "[exp_5] Episode 13550 | Loss: 0.4659\n",
            "[exp_5] Episode 13600 | Loss: 0.4676\n",
            "[exp_5] Episode 13650 | Loss: 0.4661\n",
            "[exp_5] Episode 13700 | Loss: 0.4381\n",
            "[exp_5] Episode 13750 | Loss: 0.4430\n",
            "[exp_5] Episode 13800 | Loss: 0.4601\n",
            "[exp_5] Episode 13850 | Loss: 0.4839\n",
            "[exp_5] Episode 13900 | Loss: 0.4199\n",
            "[exp_5] Episode 13950 | Loss: 0.3777\n",
            "[exp_5] Episode 14000 | Loss: 0.4874\n",
            "[exp_5] Validation Accuracy: 65.50%\n",
            "[exp_5] Episode 14050 | Loss: 0.4120\n",
            "[exp_5] Episode 14100 | Loss: 0.4840\n",
            "[exp_5] Episode 14150 | Loss: 0.5292\n",
            "[exp_5] Episode 14200 | Loss: 0.4591\n",
            "[exp_5] Episode 14250 | Loss: 0.4886\n",
            "[exp_5] Episode 14300 | Loss: 0.4076\n",
            "[exp_5] Episode 14350 | Loss: 0.4108\n",
            "[exp_5] Episode 14400 | Loss: 0.4501\n",
            "[exp_5] Episode 14450 | Loss: 0.4251\n",
            "[exp_5] Episode 14500 | Loss: 0.4403\n",
            "[exp_5] Validation Accuracy: 63.50%\n",
            "[exp_5] Episode 14550 | Loss: 0.5233\n",
            "[exp_5] Episode 14600 | Loss: 0.4082\n",
            "[exp_5] Episode 14650 | Loss: 0.5397\n",
            "[exp_5] Episode 14700 | Loss: 0.4034\n",
            "[exp_5] Episode 14750 | Loss: 0.3006\n",
            "[exp_5] Episode 14800 | Loss: 0.3288\n",
            "[exp_5] Episode 14850 | Loss: 0.4281\n",
            "[exp_5] Episode 14900 | Loss: 0.4594\n",
            "[exp_5] Episode 14950 | Loss: 0.3809\n",
            "[exp_5] Episode 15000 | Loss: 0.4485\n",
            "[exp_5] Validation Accuracy: 67.12%\n",
            "[exp_5] Episode 15050 | Loss: 0.5079\n",
            "[exp_5] Episode 15100 | Loss: 0.4247\n",
            "[exp_5] Episode 15150 | Loss: 0.4783\n",
            "[exp_5] Episode 15200 | Loss: 0.4370\n",
            "[exp_5] Episode 15250 | Loss: 0.4007\n",
            "[exp_5] Episode 15300 | Loss: 0.4212\n",
            "[exp_5] Episode 15350 | Loss: 0.4962\n",
            "[exp_5] Episode 15400 | Loss: 0.4475\n",
            "[exp_5] Episode 15450 | Loss: 0.3584\n",
            "[exp_5] Episode 15500 | Loss: 0.3717\n",
            "[exp_5] Validation Accuracy: 64.38%\n",
            "[exp_5] Episode 15550 | Loss: 0.3762\n",
            "[exp_5] Episode 15600 | Loss: 0.3634\n",
            "[exp_5] Episode 15650 | Loss: 0.4526\n",
            "[exp_5] Episode 15700 | Loss: 0.4709\n",
            "[exp_5] Episode 15750 | Loss: 0.3966\n",
            "[exp_5] Episode 15800 | Loss: 0.4307\n",
            "[exp_5] Episode 15850 | Loss: 0.4345\n",
            "[exp_5] Episode 15900 | Loss: 0.4042\n",
            "[exp_5] Episode 15950 | Loss: 0.4262\n",
            "[exp_5] Episode 16000 | Loss: 0.3883\n",
            "[exp_5] Validation Accuracy: 65.18%\n",
            "[exp_5] Episode 16050 | Loss: 0.4258\n",
            "[exp_5] Episode 16100 | Loss: 0.3641\n",
            "[exp_5] Episode 16150 | Loss: 0.3938\n",
            "[exp_5] Episode 16200 | Loss: 0.3634\n",
            "[exp_5] Episode 16250 | Loss: 0.4237\n",
            "[exp_5] Episode 16300 | Loss: 0.3332\n",
            "[exp_5] Episode 16350 | Loss: 0.3824\n",
            "[exp_5] Episode 16400 | Loss: 0.3672\n",
            "[exp_5] Episode 16450 | Loss: 0.3626\n",
            "[exp_5] Episode 16500 | Loss: 0.3976\n",
            "[exp_5] Validation Accuracy: 66.42%\n",
            "[exp_5] Episode 16550 | Loss: 0.4029\n",
            "[exp_5] Episode 16600 | Loss: 0.4175\n",
            "[exp_5] Episode 16650 | Loss: 0.4117\n",
            "[exp_5] Episode 16700 | Loss: 0.4450\n",
            "[exp_5] Episode 16750 | Loss: 0.4013\n",
            "[exp_5] Episode 16800 | Loss: 0.3499\n",
            "[exp_5] Episode 16850 | Loss: 0.3162\n",
            "[exp_5] Episode 16900 | Loss: 0.4200\n",
            "[exp_5] Episode 16950 | Loss: 0.4069\n",
            "[exp_5] Episode 17000 | Loss: 0.3762\n",
            "[exp_5] Validation Accuracy: 69.10%\n",
            "[exp_5] Episode 17050 | Loss: 0.3419\n",
            "[exp_5] Episode 17100 | Loss: 0.3729\n",
            "[exp_5] Episode 17150 | Loss: 0.4790\n",
            "[exp_5] Episode 17200 | Loss: 0.4029\n",
            "[exp_5] Episode 17250 | Loss: 0.4712\n",
            "[exp_5] Episode 17300 | Loss: 0.3311\n",
            "[exp_5] Episode 17350 | Loss: 0.3698\n",
            "[exp_5] Episode 17400 | Loss: 0.3742\n",
            "[exp_5] Episode 17450 | Loss: 0.3642\n",
            "[exp_5] Episode 17500 | Loss: 0.4289\n",
            "[exp_5] Validation Accuracy: 65.45%\n",
            "[exp_5] Episode 17550 | Loss: 0.4319\n",
            "[exp_5] Episode 17600 | Loss: 0.4119\n",
            "[exp_5] Episode 17650 | Loss: 0.3170\n",
            "[exp_5] Episode 17700 | Loss: 0.3347\n",
            "[exp_5] Episode 17750 | Loss: 0.3090\n",
            "[exp_5] Episode 17800 | Loss: 0.3585\n",
            "[exp_5] Episode 17850 | Loss: 0.4544\n",
            "[exp_5] Episode 17900 | Loss: 0.3500\n",
            "[exp_5] Episode 17950 | Loss: 0.3843\n",
            "[exp_5] Episode 18000 | Loss: 0.3693\n",
            "[exp_5] Validation Accuracy: 61.80%\n",
            "[exp_5] Episode 18050 | Loss: 0.3140\n",
            "[exp_5] Episode 18100 | Loss: 0.3597\n",
            "[exp_5] Episode 18150 | Loss: 0.3992\n",
            "[exp_5] Episode 18200 | Loss: 0.3421\n",
            "[exp_5] Episode 18250 | Loss: 0.3194\n",
            "[exp_5] Episode 18300 | Loss: 0.3084\n",
            "[exp_5] Episode 18350 | Loss: 0.3834\n",
            "[exp_5] Episode 18400 | Loss: 0.4007\n",
            "[exp_5] Episode 18450 | Loss: 0.3496\n",
            "[exp_5] Episode 18500 | Loss: 0.3889\n",
            "[exp_5] Validation Accuracy: 68.42%\n",
            "[exp_5] Episode 18550 | Loss: 0.3428\n",
            "[exp_5] Episode 18600 | Loss: 0.3354\n",
            "[exp_5] Episode 18650 | Loss: 0.4111\n",
            "[exp_5] Episode 18700 | Loss: 0.4074\n",
            "[exp_5] Episode 18750 | Loss: 0.3248\n",
            "[exp_5] Episode 18800 | Loss: 0.3962\n",
            "[exp_5] Episode 18850 | Loss: 0.3740\n",
            "[exp_5] Episode 18900 | Loss: 0.3626\n",
            "[exp_5] Episode 18950 | Loss: 0.3365\n",
            "[exp_5] Episode 19000 | Loss: 0.3153\n",
            "[exp_5] Validation Accuracy: 64.80%\n",
            "[exp_5] Episode 19050 | Loss: 0.3968\n",
            "[exp_5] Episode 19100 | Loss: 0.3863\n",
            "[exp_5] Episode 19150 | Loss: 0.3183\n",
            "[exp_5] Episode 19200 | Loss: 0.3303\n",
            "[exp_5] Episode 19250 | Loss: 0.3418\n",
            "[exp_5] Episode 19300 | Loss: 0.3380\n",
            "[exp_5] Episode 19350 | Loss: 0.3808\n",
            "[exp_5] Episode 19400 | Loss: 0.4089\n",
            "[exp_5] Episode 19450 | Loss: 0.3182\n",
            "[exp_5] Episode 19500 | Loss: 0.3321\n",
            "[exp_5] Validation Accuracy: 65.48%\n",
            "[exp_5] Episode 19550 | Loss: 0.2853\n",
            "[exp_5] Episode 19600 | Loss: 0.3187\n",
            "[exp_5] Episode 19650 | Loss: 0.3774\n",
            "[exp_5] Episode 19700 | Loss: 0.3819\n",
            "[exp_5] Episode 19750 | Loss: 0.3422\n",
            "[exp_5] Episode 19800 | Loss: 0.3544\n",
            "[exp_5] Episode 19850 | Loss: 0.3736\n",
            "[exp_5] Episode 19900 | Loss: 0.3299\n",
            "[exp_5] Episode 19950 | Loss: 0.3128\n",
            "[exp_5] Episode 20000 | Loss: 0.3412\n",
            "[exp_5] Validation Accuracy: 66.83%\n",
            "[exp_5] Episode 20050 | Loss: 0.2860\n",
            "[exp_5] Episode 20100 | Loss: 0.3695\n",
            "[exp_5] Episode 20150 | Loss: 0.3170\n",
            "[exp_5] Episode 20200 | Loss: 0.3031\n",
            "[exp_5] Episode 20250 | Loss: 0.2882\n",
            "[exp_5] Episode 20300 | Loss: 0.3383\n",
            "[exp_5] Episode 20350 | Loss: 0.3074\n",
            "[exp_5] Episode 20400 | Loss: 0.3186\n",
            "[exp_5] Episode 20450 | Loss: 0.3628\n",
            "[exp_5] Episode 20500 | Loss: 0.3383\n",
            "[exp_5] Validation Accuracy: 64.58%\n",
            "[exp_5] Episode 20550 | Loss: 0.3183\n",
            "[exp_5] Episode 20600 | Loss: 0.2877\n",
            "[exp_5] Episode 20650 | Loss: 0.3109\n",
            "[exp_5] Episode 20700 | Loss: 0.3374\n",
            "[exp_5] Episode 20750 | Loss: 0.3083\n",
            "[exp_5] Episode 20800 | Loss: 0.2846\n",
            "[exp_5] Episode 20850 | Loss: 0.3241\n",
            "[exp_5] Episode 20900 | Loss: 0.3675\n",
            "[exp_5] Episode 20950 | Loss: 0.3152\n",
            "[exp_5] Episode 21000 | Loss: 0.3168\n",
            "[exp_5] Validation Accuracy: 66.17%\n",
            "[exp_5] Episode 21050 | Loss: 0.2936\n",
            "[exp_5] Episode 21100 | Loss: 0.3287\n",
            "[exp_5] Episode 21150 | Loss: 0.3766\n",
            "[exp_5] Episode 21200 | Loss: 0.3096\n",
            "[exp_5] Episode 21250 | Loss: 0.3337\n",
            "[exp_5] Episode 21300 | Loss: 0.3464\n",
            "[exp_5] Episode 21350 | Loss: 0.2680\n",
            "[exp_5] Episode 21400 | Loss: 0.3146\n",
            "[exp_5] Episode 21450 | Loss: 0.2522\n",
            "[exp_5] Episode 21500 | Loss: 0.2969\n",
            "[exp_5] Validation Accuracy: 66.22%\n",
            "[exp_5] Episode 21550 | Loss: 0.2737\n",
            "[exp_5] Episode 21600 | Loss: 0.3258\n",
            "[exp_5] Episode 21650 | Loss: 0.3017\n",
            "[exp_5] Episode 21700 | Loss: 0.3356\n",
            "[exp_5] Episode 21750 | Loss: 0.3135\n",
            "[exp_5] Episode 21800 | Loss: 0.2399\n",
            "[exp_5] Episode 21850 | Loss: 0.2604\n",
            "[exp_5] Episode 21900 | Loss: 0.2860\n",
            "[exp_5] Episode 21950 | Loss: 0.2942\n",
            "[exp_5] Episode 22000 | Loss: 0.3177\n",
            "[exp_5] Validation Accuracy: 64.18%\n",
            "[exp_5] Early stopping triggered at episode 22000\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_6 (shot: 5, meta_batch_size: 1, do_training: True)\n",
            "[exp_6] Episode 0 | Loss: 0.5654\n",
            "[exp_6] Episode 50 | Loss: 1.4045\n",
            "[exp_6] Episode 100 | Loss: 1.0765\n",
            "[exp_6] Episode 150 | Loss: 0.9379\n",
            "[exp_6] Episode 200 | Loss: 0.8768\n",
            "[exp_6] Episode 250 | Loss: 0.8431\n",
            "[exp_6] Episode 300 | Loss: 0.7955\n",
            "[exp_6] Episode 350 | Loss: 0.7848\n",
            "[exp_6] Episode 400 | Loss: 0.8419\n",
            "[exp_6] Episode 450 | Loss: 0.6874\n",
            "[exp_6] Episode 500 | Loss: 0.6962\n",
            "[exp_6] Validation Accuracy: 65.72%\n",
            "[exp_6] Episode 550 | Loss: 0.7039\n",
            "[exp_6] Episode 600 | Loss: 0.6382\n",
            "[exp_6] Episode 650 | Loss: 0.7024\n",
            "[exp_6] Episode 700 | Loss: 0.6693\n",
            "[exp_6] Episode 750 | Loss: 0.6247\n",
            "[exp_6] Episode 800 | Loss: 0.5415\n",
            "[exp_6] Episode 850 | Loss: 0.5676\n",
            "[exp_6] Episode 900 | Loss: 0.5821\n",
            "[exp_6] Episode 950 | Loss: 0.5258\n",
            "[exp_6] Episode 1000 | Loss: 0.5642\n",
            "[exp_6] Validation Accuracy: 69.80%\n",
            "[exp_6] Episode 1050 | Loss: 0.5660\n",
            "[exp_6] Episode 1100 | Loss: 0.6002\n",
            "[exp_6] Episode 1150 | Loss: 0.5905\n",
            "[exp_6] Episode 1200 | Loss: 0.5457\n",
            "[exp_6] Episode 1250 | Loss: 0.4894\n",
            "[exp_6] Episode 1300 | Loss: 0.4979\n",
            "[exp_6] Episode 1350 | Loss: 0.5315\n",
            "[exp_6] Episode 1400 | Loss: 0.5438\n",
            "[exp_6] Episode 1450 | Loss: 0.5223\n",
            "[exp_6] Episode 1500 | Loss: 0.4912\n",
            "[exp_6] Validation Accuracy: 74.98%\n",
            "[exp_6] Episode 1550 | Loss: 0.5304\n",
            "[exp_6] Episode 1600 | Loss: 0.4734\n",
            "[exp_6] Episode 1650 | Loss: 0.4686\n",
            "[exp_6] Episode 1700 | Loss: 0.4833\n",
            "[exp_6] Episode 1750 | Loss: 0.5222\n",
            "[exp_6] Episode 1800 | Loss: 0.5039\n",
            "[exp_6] Episode 1850 | Loss: 0.4555\n",
            "[exp_6] Episode 1900 | Loss: 0.4713\n",
            "[exp_6] Episode 1950 | Loss: 0.4514\n",
            "[exp_6] Episode 2000 | Loss: 0.4776\n",
            "[exp_6] Validation Accuracy: 73.20%\n",
            "[exp_6] Episode 2050 | Loss: 0.4567\n",
            "[exp_6] Episode 2100 | Loss: 0.5022\n",
            "[exp_6] Episode 2150 | Loss: 0.4544\n",
            "[exp_6] Episode 2200 | Loss: 0.4417\n",
            "[exp_6] Episode 2250 | Loss: 0.4338\n",
            "[exp_6] Episode 2300 | Loss: 0.3832\n",
            "[exp_6] Episode 2350 | Loss: 0.5041\n",
            "[exp_6] Episode 2400 | Loss: 0.3681\n",
            "[exp_6] Episode 2450 | Loss: 0.3999\n",
            "[exp_6] Episode 2500 | Loss: 0.4345\n",
            "[exp_6] Validation Accuracy: 74.88%\n",
            "[exp_6] Episode 2550 | Loss: 0.4050\n",
            "[exp_6] Episode 2600 | Loss: 0.4215\n",
            "[exp_6] Episode 2650 | Loss: 0.3805\n",
            "[exp_6] Episode 2700 | Loss: 0.4444\n",
            "[exp_6] Episode 2750 | Loss: 0.4150\n",
            "[exp_6] Episode 2800 | Loss: 0.4232\n",
            "[exp_6] Episode 2850 | Loss: 0.4442\n",
            "[exp_6] Episode 2900 | Loss: 0.4067\n",
            "[exp_6] Episode 2950 | Loss: 0.3757\n",
            "[exp_6] Episode 3000 | Loss: 0.3991\n",
            "[exp_6] Validation Accuracy: 76.40%\n",
            "[exp_6] Episode 3050 | Loss: 0.3697\n",
            "[exp_6] Episode 3100 | Loss: 0.3811\n",
            "[exp_6] Episode 3150 | Loss: 0.4477\n",
            "[exp_6] Episode 3200 | Loss: 0.3520\n",
            "[exp_6] Episode 3250 | Loss: 0.3940\n",
            "[exp_6] Episode 3300 | Loss: 0.4199\n",
            "[exp_6] Episode 3350 | Loss: 0.3715\n",
            "[exp_6] Episode 3400 | Loss: 0.3919\n",
            "[exp_6] Episode 3450 | Loss: 0.4410\n",
            "[exp_6] Episode 3500 | Loss: 0.3634\n",
            "[exp_6] Validation Accuracy: 75.95%\n",
            "[exp_6] Episode 3550 | Loss: 0.3760\n",
            "[exp_6] Episode 3600 | Loss: 0.3828\n",
            "[exp_6] Episode 3650 | Loss: 0.3441\n",
            "[exp_6] Episode 3700 | Loss: 0.3004\n",
            "[exp_6] Episode 3750 | Loss: 0.3680\n",
            "[exp_6] Episode 3800 | Loss: 0.3527\n",
            "[exp_6] Episode 3850 | Loss: 0.3421\n",
            "[exp_6] Episode 3900 | Loss: 0.3739\n",
            "[exp_6] Episode 3950 | Loss: 0.3598\n",
            "[exp_6] Episode 4000 | Loss: 0.4008\n",
            "[exp_6] Validation Accuracy: 75.20%\n",
            "[exp_6] Episode 4050 | Loss: 0.3886\n",
            "[exp_6] Episode 4100 | Loss: 0.3340\n",
            "[exp_6] Episode 4150 | Loss: 0.3663\n",
            "[exp_6] Episode 4200 | Loss: 0.3617\n",
            "[exp_6] Episode 4250 | Loss: 0.3575\n",
            "[exp_6] Episode 4300 | Loss: 0.3795\n",
            "[exp_6] Episode 4350 | Loss: 0.3125\n",
            "[exp_6] Episode 4400 | Loss: 0.3808\n",
            "[exp_6] Episode 4450 | Loss: 0.3199\n",
            "[exp_6] Episode 4500 | Loss: 0.3273\n",
            "[exp_6] Validation Accuracy: 77.58%\n",
            "[exp_6] Episode 4550 | Loss: 0.3083\n",
            "[exp_6] Episode 4600 | Loss: 0.3474\n",
            "[exp_6] Episode 4650 | Loss: 0.3336\n",
            "[exp_6] Episode 4700 | Loss: 0.3131\n",
            "[exp_6] Episode 4750 | Loss: 0.3839\n",
            "[exp_6] Episode 4800 | Loss: 0.3504\n",
            "[exp_6] Episode 4850 | Loss: 0.3269\n",
            "[exp_6] Episode 4900 | Loss: 0.2736\n",
            "[exp_6] Episode 4950 | Loss: 0.2652\n",
            "[exp_6] Episode 5000 | Loss: 0.3439\n",
            "[exp_6] Validation Accuracy: 79.85%\n",
            "[exp_6] Episode 5050 | Loss: 0.3596\n",
            "[exp_6] Episode 5100 | Loss: 0.3154\n",
            "[exp_6] Episode 5150 | Loss: 0.3133\n",
            "[exp_6] Episode 5200 | Loss: 0.3489\n",
            "[exp_6] Episode 5250 | Loss: 0.2966\n",
            "[exp_6] Episode 5300 | Loss: 0.3029\n",
            "[exp_6] Episode 5350 | Loss: 0.3022\n",
            "[exp_6] Episode 5400 | Loss: 0.2913\n",
            "[exp_6] Episode 5450 | Loss: 0.3266\n",
            "[exp_6] Episode 5500 | Loss: 0.3418\n",
            "[exp_6] Validation Accuracy: 76.65%\n",
            "[exp_6] Episode 5550 | Loss: 0.3097\n",
            "[exp_6] Episode 5600 | Loss: 0.2948\n",
            "[exp_6] Episode 5650 | Loss: 0.3087\n",
            "[exp_6] Episode 5700 | Loss: 0.3099\n",
            "[exp_6] Episode 5750 | Loss: 0.2839\n",
            "[exp_6] Episode 5800 | Loss: 0.3307\n",
            "[exp_6] Episode 5850 | Loss: 0.2366\n",
            "[exp_6] Episode 5900 | Loss: 0.2824\n",
            "[exp_6] Episode 5950 | Loss: 0.2720\n",
            "[exp_6] Episode 6000 | Loss: 0.2714\n",
            "[exp_6] Validation Accuracy: 76.38%\n",
            "[exp_6] Episode 6050 | Loss: 0.2346\n",
            "[exp_6] Episode 6100 | Loss: 0.2840\n",
            "[exp_6] Episode 6150 | Loss: 0.2996\n",
            "[exp_6] Episode 6200 | Loss: 0.2718\n",
            "[exp_6] Episode 6250 | Loss: 0.2469\n",
            "[exp_6] Episode 6300 | Loss: 0.2707\n",
            "[exp_6] Episode 6350 | Loss: 0.3197\n",
            "[exp_6] Episode 6400 | Loss: 0.2679\n",
            "[exp_6] Episode 6450 | Loss: 0.2623\n",
            "[exp_6] Episode 6500 | Loss: 0.2712\n",
            "[exp_6] Validation Accuracy: 79.92%\n",
            "[exp_6] Episode 6550 | Loss: 0.2617\n",
            "[exp_6] Episode 6600 | Loss: 0.2614\n",
            "[exp_6] Episode 6650 | Loss: 0.2715\n",
            "[exp_6] Episode 6700 | Loss: 0.2803\n",
            "[exp_6] Episode 6750 | Loss: 0.2374\n",
            "[exp_6] Episode 6800 | Loss: 0.2827\n",
            "[exp_6] Episode 6850 | Loss: 0.2853\n",
            "[exp_6] Episode 6900 | Loss: 0.2775\n",
            "[exp_6] Episode 6950 | Loss: 0.2281\n",
            "[exp_6] Episode 7000 | Loss: 0.2853\n",
            "[exp_6] Validation Accuracy: 79.47%\n",
            "[exp_6] Episode 7050 | Loss: 0.2080\n",
            "[exp_6] Episode 7100 | Loss: 0.2076\n",
            "[exp_6] Episode 7150 | Loss: 0.2570\n",
            "[exp_6] Episode 7200 | Loss: 0.1810\n",
            "[exp_6] Episode 7250 | Loss: 0.2677\n",
            "[exp_6] Episode 7300 | Loss: 0.2555\n",
            "[exp_6] Episode 7350 | Loss: 0.2847\n",
            "[exp_6] Episode 7400 | Loss: 0.2457\n",
            "[exp_6] Episode 7450 | Loss: 0.2849\n",
            "[exp_6] Episode 7500 | Loss: 0.2395\n",
            "[exp_6] Validation Accuracy: 80.92%\n",
            "[exp_6] Episode 7550 | Loss: 0.2461\n",
            "[exp_6] Episode 7600 | Loss: 0.2427\n",
            "[exp_6] Episode 7650 | Loss: 0.1881\n",
            "[exp_6] Episode 7700 | Loss: 0.2550\n",
            "[exp_6] Episode 7750 | Loss: 0.2476\n",
            "[exp_6] Episode 7800 | Loss: 0.2034\n",
            "[exp_6] Episode 7850 | Loss: 0.2299\n",
            "[exp_6] Episode 7900 | Loss: 0.2259\n",
            "[exp_6] Episode 7950 | Loss: 0.2231\n",
            "[exp_6] Episode 8000 | Loss: 0.2704\n",
            "[exp_6] Validation Accuracy: 79.40%\n",
            "[exp_6] Episode 8050 | Loss: 0.2303\n",
            "[exp_6] Episode 8100 | Loss: 0.2207\n",
            "[exp_6] Episode 8150 | Loss: 0.1959\n",
            "[exp_6] Episode 8200 | Loss: 0.2129\n",
            "[exp_6] Episode 8250 | Loss: 0.2123\n",
            "[exp_6] Episode 8300 | Loss: 0.2130\n",
            "[exp_6] Episode 8350 | Loss: 0.2783\n",
            "[exp_6] Episode 8400 | Loss: 0.2252\n",
            "[exp_6] Episode 8450 | Loss: 0.1806\n",
            "[exp_6] Episode 8500 | Loss: 0.2184\n",
            "[exp_6] Validation Accuracy: 79.30%\n",
            "[exp_6] Episode 8550 | Loss: 0.1900\n",
            "[exp_6] Episode 8600 | Loss: 0.2464\n",
            "[exp_6] Episode 8650 | Loss: 0.1792\n",
            "[exp_6] Episode 8700 | Loss: 0.2517\n",
            "[exp_6] Episode 8750 | Loss: 0.2334\n",
            "[exp_6] Episode 8800 | Loss: 0.2127\n",
            "[exp_6] Episode 8850 | Loss: 0.1895\n",
            "[exp_6] Episode 8900 | Loss: 0.2204\n",
            "[exp_6] Episode 8950 | Loss: 0.2374\n",
            "[exp_6] Episode 9000 | Loss: 0.2015\n",
            "[exp_6] Validation Accuracy: 79.22%\n",
            "[exp_6] Episode 9050 | Loss: 0.2263\n",
            "[exp_6] Episode 9100 | Loss: 0.2000\n",
            "[exp_6] Episode 9150 | Loss: 0.1749\n",
            "[exp_6] Episode 9200 | Loss: 0.2249\n",
            "[exp_6] Episode 9250 | Loss: 0.2142\n",
            "[exp_6] Episode 9300 | Loss: 0.1613\n",
            "[exp_6] Episode 9350 | Loss: 0.1950\n",
            "[exp_6] Episode 9400 | Loss: 0.2194\n",
            "[exp_6] Episode 9450 | Loss: 0.1746\n",
            "[exp_6] Episode 9500 | Loss: 0.2077\n",
            "[exp_6] Validation Accuracy: 79.12%\n",
            "[exp_6] Episode 9550 | Loss: 0.2014\n",
            "[exp_6] Episode 9600 | Loss: 0.1743\n",
            "[exp_6] Episode 9650 | Loss: 0.1982\n",
            "[exp_6] Episode 9700 | Loss: 0.2241\n",
            "[exp_6] Episode 9750 | Loss: 0.1869\n",
            "[exp_6] Episode 9800 | Loss: 0.1825\n",
            "[exp_6] Episode 9850 | Loss: 0.1863\n",
            "[exp_6] Episode 9900 | Loss: 0.1594\n",
            "[exp_6] Episode 9950 | Loss: 0.1587\n",
            "[exp_6] Episode 10000 | Loss: 0.2001\n",
            "[exp_6] Validation Accuracy: 78.50%\n",
            "[exp_6] Episode 10050 | Loss: 0.2154\n",
            "[exp_6] Episode 10100 | Loss: 0.1776\n",
            "[exp_6] Episode 10150 | Loss: 0.2242\n",
            "[exp_6] Episode 10200 | Loss: 0.1583\n",
            "[exp_6] Episode 10250 | Loss: 0.1659\n",
            "[exp_6] Episode 10300 | Loss: 0.1723\n",
            "[exp_6] Episode 10350 | Loss: 0.1690\n",
            "[exp_6] Episode 10400 | Loss: 0.1731\n",
            "[exp_6] Episode 10450 | Loss: 0.1658\n",
            "[exp_6] Episode 10500 | Loss: 0.1892\n",
            "[exp_6] Validation Accuracy: 79.42%\n",
            "[exp_6] Episode 10550 | Loss: 0.1713\n",
            "[exp_6] Episode 10600 | Loss: 0.1162\n",
            "[exp_6] Episode 10650 | Loss: 0.1285\n",
            "[exp_6] Episode 10700 | Loss: 0.1510\n",
            "[exp_6] Episode 10750 | Loss: 0.2088\n",
            "[exp_6] Episode 10800 | Loss: 0.2121\n",
            "[exp_6] Episode 10850 | Loss: 0.1808\n",
            "[exp_6] Episode 10900 | Loss: 0.1853\n",
            "[exp_6] Episode 10950 | Loss: 0.1583\n",
            "[exp_6] Episode 11000 | Loss: 0.1844\n",
            "[exp_6] Validation Accuracy: 80.62%\n",
            "[exp_6] Episode 11050 | Loss: 0.1786\n",
            "[exp_6] Episode 11100 | Loss: 0.1519\n",
            "[exp_6] Episode 11150 | Loss: 0.1992\n",
            "[exp_6] Episode 11200 | Loss: 0.1837\n",
            "[exp_6] Episode 11250 | Loss: 0.1600\n",
            "[exp_6] Episode 11300 | Loss: 0.1632\n",
            "[exp_6] Episode 11350 | Loss: 0.1792\n",
            "[exp_6] Episode 11400 | Loss: 0.1571\n",
            "[exp_6] Episode 11450 | Loss: 0.1660\n",
            "[exp_6] Episode 11500 | Loss: 0.2023\n",
            "[exp_6] Validation Accuracy: 80.30%\n",
            "[exp_6] Episode 11550 | Loss: 0.1703\n",
            "[exp_6] Episode 11600 | Loss: 0.1289\n",
            "[exp_6] Episode 11650 | Loss: 0.1418\n",
            "[exp_6] Episode 11700 | Loss: 0.1478\n",
            "[exp_6] Episode 11750 | Loss: 0.1702\n",
            "[exp_6] Episode 11800 | Loss: 0.1270\n",
            "[exp_6] Episode 11850 | Loss: 0.1580\n",
            "[exp_6] Episode 11900 | Loss: 0.1627\n",
            "[exp_6] Episode 11950 | Loss: 0.1727\n",
            "[exp_6] Episode 12000 | Loss: 0.1634\n",
            "[exp_6] Validation Accuracy: 80.12%\n",
            "[exp_6] Episode 12050 | Loss: 0.1808\n",
            "[exp_6] Episode 12100 | Loss: 0.1458\n",
            "[exp_6] Episode 12150 | Loss: 0.1377\n",
            "[exp_6] Episode 12200 | Loss: 0.1702\n",
            "[exp_6] Episode 12250 | Loss: 0.1539\n",
            "[exp_6] Episode 12300 | Loss: 0.1940\n",
            "[exp_6] Episode 12350 | Loss: 0.1884\n",
            "[exp_6] Episode 12400 | Loss: 0.1512\n",
            "[exp_6] Episode 12450 | Loss: 0.1338\n",
            "[exp_6] Episode 12500 | Loss: 0.1107\n",
            "[exp_6] Validation Accuracy: 80.95%\n",
            "[exp_6] Episode 12550 | Loss: 0.1444\n",
            "[exp_6] Episode 12600 | Loss: 0.1431\n",
            "[exp_6] Episode 12650 | Loss: 0.1315\n",
            "[exp_6] Episode 12700 | Loss: 0.1733\n",
            "[exp_6] Episode 12750 | Loss: 0.1708\n",
            "[exp_6] Episode 12800 | Loss: 0.1409\n",
            "[exp_6] Episode 12850 | Loss: 0.1429\n",
            "[exp_6] Episode 12900 | Loss: 0.1257\n",
            "[exp_6] Episode 12950 | Loss: 0.1846\n",
            "[exp_6] Episode 13000 | Loss: 0.1523\n",
            "[exp_6] Validation Accuracy: 80.45%\n",
            "[exp_6] Episode 13050 | Loss: 0.1374\n",
            "[exp_6] Episode 13100 | Loss: 0.1331\n",
            "[exp_6] Episode 13150 | Loss: 0.1478\n",
            "[exp_6] Episode 13200 | Loss: 0.1676\n",
            "[exp_6] Episode 13250 | Loss: 0.1502\n",
            "[exp_6] Episode 13300 | Loss: 0.1441\n",
            "[exp_6] Episode 13350 | Loss: 0.1401\n",
            "[exp_6] Episode 13400 | Loss: 0.1545\n",
            "[exp_6] Episode 13450 | Loss: 0.1361\n",
            "[exp_6] Episode 13500 | Loss: 0.1468\n",
            "[exp_6] Validation Accuracy: 79.92%\n",
            "[exp_6] Episode 13550 | Loss: 0.1741\n",
            "[exp_6] Episode 13600 | Loss: 0.1629\n",
            "[exp_6] Episode 13650 | Loss: 0.1300\n",
            "[exp_6] Episode 13700 | Loss: 0.1711\n",
            "[exp_6] Episode 13750 | Loss: 0.1073\n",
            "[exp_6] Episode 13800 | Loss: 0.1446\n",
            "[exp_6] Episode 13850 | Loss: 0.1285\n",
            "[exp_6] Episode 13900 | Loss: 0.1589\n",
            "[exp_6] Episode 13950 | Loss: 0.1361\n",
            "[exp_6] Episode 14000 | Loss: 0.1227\n",
            "[exp_6] Validation Accuracy: 78.25%\n",
            "[exp_6] Episode 14050 | Loss: 0.1222\n",
            "[exp_6] Episode 14100 | Loss: 0.1358\n",
            "[exp_6] Episode 14150 | Loss: 0.1483\n",
            "[exp_6] Episode 14200 | Loss: 0.1284\n",
            "[exp_6] Episode 14250 | Loss: 0.1603\n",
            "[exp_6] Episode 14300 | Loss: 0.1179\n",
            "[exp_6] Episode 14350 | Loss: 0.1292\n",
            "[exp_6] Episode 14400 | Loss: 0.1339\n",
            "[exp_6] Episode 14450 | Loss: 0.1582\n",
            "[exp_6] Episode 14500 | Loss: 0.1049\n",
            "[exp_6] Validation Accuracy: 80.25%\n",
            "[exp_6] Episode 14550 | Loss: 0.1413\n",
            "[exp_6] Episode 14600 | Loss: 0.1017\n",
            "[exp_6] Episode 14650 | Loss: 0.1326\n",
            "[exp_6] Episode 14700 | Loss: 0.1209\n",
            "[exp_6] Episode 14750 | Loss: 0.1032\n",
            "[exp_6] Episode 14800 | Loss: 0.1285\n",
            "[exp_6] Episode 14850 | Loss: 0.1413\n",
            "[exp_6] Episode 14900 | Loss: 0.1338\n",
            "[exp_6] Episode 14950 | Loss: 0.0917\n",
            "[exp_6] Episode 15000 | Loss: 0.1249\n",
            "[exp_6] Validation Accuracy: 78.57%\n",
            "[exp_6] Episode 15050 | Loss: 0.1143\n",
            "[exp_6] Episode 15100 | Loss: 0.1321\n",
            "[exp_6] Episode 15150 | Loss: 0.1292\n",
            "[exp_6] Episode 15200 | Loss: 0.1034\n",
            "[exp_6] Episode 15250 | Loss: 0.1075\n",
            "[exp_6] Episode 15300 | Loss: 0.1081\n",
            "[exp_6] Episode 15350 | Loss: 0.1049\n",
            "[exp_6] Episode 15400 | Loss: 0.0930\n",
            "[exp_6] Episode 15450 | Loss: 0.1279\n",
            "[exp_6] Episode 15500 | Loss: 0.1102\n",
            "[exp_6] Validation Accuracy: 80.10%\n",
            "[exp_6] Episode 15550 | Loss: 0.0835\n",
            "[exp_6] Episode 15600 | Loss: 0.1123\n",
            "[exp_6] Episode 15650 | Loss: 0.1093\n",
            "[exp_6] Episode 15700 | Loss: 0.0930\n",
            "[exp_6] Episode 15750 | Loss: 0.1010\n",
            "[exp_6] Episode 15800 | Loss: 0.1177\n",
            "[exp_6] Episode 15850 | Loss: 0.1176\n",
            "[exp_6] Episode 15900 | Loss: 0.0978\n",
            "[exp_6] Episode 15950 | Loss: 0.0976\n",
            "[exp_6] Episode 16000 | Loss: 0.1376\n",
            "[exp_6] Validation Accuracy: 79.12%\n",
            "[exp_6] Episode 16050 | Loss: 0.1143\n",
            "[exp_6] Episode 16100 | Loss: 0.1406\n",
            "[exp_6] Episode 16150 | Loss: 0.0945\n",
            "[exp_6] Episode 16200 | Loss: 0.1162\n",
            "[exp_6] Episode 16250 | Loss: 0.1316\n",
            "[exp_6] Episode 16300 | Loss: 0.1242\n",
            "[exp_6] Episode 16350 | Loss: 0.0952\n",
            "[exp_6] Episode 16400 | Loss: 0.1369\n",
            "[exp_6] Episode 16450 | Loss: 0.0749\n",
            "[exp_6] Episode 16500 | Loss: 0.1037\n",
            "[exp_6] Validation Accuracy: 80.03%\n",
            "[exp_6] Episode 16550 | Loss: 0.1045\n",
            "[exp_6] Episode 16600 | Loss: 0.1122\n",
            "[exp_6] Episode 16650 | Loss: 0.0815\n",
            "[exp_6] Episode 16700 | Loss: 0.1090\n",
            "[exp_6] Episode 16750 | Loss: 0.1184\n",
            "[exp_6] Episode 16800 | Loss: 0.1191\n",
            "[exp_6] Episode 16850 | Loss: 0.0987\n",
            "[exp_6] Episode 16900 | Loss: 0.1125\n",
            "[exp_6] Episode 16950 | Loss: 0.1089\n",
            "[exp_6] Episode 17000 | Loss: 0.1047\n",
            "[exp_6] Validation Accuracy: 77.68%\n",
            "[exp_6] Episode 17050 | Loss: 0.1242\n",
            "[exp_6] Episode 17100 | Loss: 0.0964\n",
            "[exp_6] Episode 17150 | Loss: 0.1436\n",
            "[exp_6] Episode 17200 | Loss: 0.1139\n",
            "[exp_6] Episode 17250 | Loss: 0.1063\n",
            "[exp_6] Episode 17300 | Loss: 0.0802\n",
            "[exp_6] Episode 17350 | Loss: 0.0880\n",
            "[exp_6] Episode 17400 | Loss: 0.1155\n",
            "[exp_6] Episode 17450 | Loss: 0.0895\n",
            "[exp_6] Episode 17500 | Loss: 0.0983\n",
            "[exp_6] Validation Accuracy: 81.00%\n",
            "[exp_6] Episode 17550 | Loss: 0.0961\n",
            "[exp_6] Episode 17600 | Loss: 0.0988\n",
            "[exp_6] Episode 17650 | Loss: 0.1277\n",
            "[exp_6] Episode 17700 | Loss: 0.0969\n",
            "[exp_6] Episode 17750 | Loss: 0.1288\n",
            "[exp_6] Episode 17800 | Loss: 0.1095\n",
            "[exp_6] Episode 17850 | Loss: 0.1038\n",
            "[exp_6] Episode 17900 | Loss: 0.1458\n",
            "[exp_6] Episode 17950 | Loss: 0.1224\n",
            "[exp_6] Episode 18000 | Loss: 0.0964\n",
            "[exp_6] Validation Accuracy: 80.10%\n",
            "[exp_6] Episode 18050 | Loss: 0.0833\n",
            "[exp_6] Episode 18100 | Loss: 0.0811\n",
            "[exp_6] Episode 18150 | Loss: 0.1195\n",
            "[exp_6] Episode 18200 | Loss: 0.0947\n",
            "[exp_6] Episode 18250 | Loss: 0.1152\n",
            "[exp_6] Episode 18300 | Loss: 0.0876\n",
            "[exp_6] Episode 18350 | Loss: 0.1021\n",
            "[exp_6] Episode 18400 | Loss: 0.1027\n",
            "[exp_6] Episode 18450 | Loss: 0.1249\n",
            "[exp_6] Episode 18500 | Loss: 0.0880\n",
            "[exp_6] Validation Accuracy: 78.38%\n",
            "[exp_6] Episode 18550 | Loss: 0.0793\n",
            "[exp_6] Episode 18600 | Loss: 0.1188\n",
            "[exp_6] Episode 18650 | Loss: 0.0924\n",
            "[exp_6] Episode 18700 | Loss: 0.0901\n",
            "[exp_6] Episode 18750 | Loss: 0.0960\n",
            "[exp_6] Episode 18800 | Loss: 0.1083\n",
            "[exp_6] Episode 18850 | Loss: 0.1100\n",
            "[exp_6] Episode 18900 | Loss: 0.0915\n",
            "[exp_6] Episode 18950 | Loss: 0.1149\n",
            "[exp_6] Episode 19000 | Loss: 0.0711\n",
            "[exp_6] Validation Accuracy: 82.88%\n",
            "[exp_6] Episode 19050 | Loss: 0.0844\n",
            "[exp_6] Episode 19100 | Loss: 0.0827\n",
            "[exp_6] Episode 19150 | Loss: 0.0874\n",
            "[exp_6] Episode 19200 | Loss: 0.0986\n",
            "[exp_6] Episode 19250 | Loss: 0.0730\n",
            "[exp_6] Episode 19300 | Loss: 0.0951\n",
            "[exp_6] Episode 19350 | Loss: 0.0883\n",
            "[exp_6] Episode 19400 | Loss: 0.0607\n",
            "[exp_6] Episode 19450 | Loss: 0.0634\n",
            "[exp_6] Episode 19500 | Loss: 0.0808\n",
            "[exp_6] Validation Accuracy: 79.97%\n",
            "[exp_6] Episode 19550 | Loss: 0.0963\n",
            "[exp_6] Episode 19600 | Loss: 0.0976\n",
            "[exp_6] Episode 19650 | Loss: 0.1295\n",
            "[exp_6] Episode 19700 | Loss: 0.1076\n",
            "[exp_6] Episode 19750 | Loss: 0.0982\n",
            "[exp_6] Episode 19800 | Loss: 0.1262\n",
            "[exp_6] Episode 19850 | Loss: 0.1088\n",
            "[exp_6] Episode 19900 | Loss: 0.0907\n",
            "[exp_6] Episode 19950 | Loss: 0.1064\n",
            "[exp_6] Episode 20000 | Loss: 0.0845\n",
            "[exp_6] Validation Accuracy: 79.20%\n",
            "[exp_6] Episode 20050 | Loss: 0.0478\n",
            "[exp_6] Episode 20100 | Loss: 0.0809\n",
            "[exp_6] Episode 20150 | Loss: 0.1068\n",
            "[exp_6] Episode 20200 | Loss: 0.0907\n",
            "[exp_6] Episode 20250 | Loss: 0.1153\n",
            "[exp_6] Episode 20300 | Loss: 0.0955\n",
            "[exp_6] Episode 20350 | Loss: 0.0760\n",
            "[exp_6] Episode 20400 | Loss: 0.0981\n",
            "[exp_6] Episode 20450 | Loss: 0.1153\n",
            "[exp_6] Episode 20500 | Loss: 0.0887\n",
            "[exp_6] Validation Accuracy: 78.92%\n",
            "[exp_6] Episode 20550 | Loss: 0.0541\n",
            "[exp_6] Episode 20600 | Loss: 0.0743\n",
            "[exp_6] Episode 20650 | Loss: 0.0832\n",
            "[exp_6] Episode 20700 | Loss: 0.0661\n",
            "[exp_6] Episode 20750 | Loss: 0.0797\n",
            "[exp_6] Episode 20800 | Loss: 0.0803\n",
            "[exp_6] Episode 20850 | Loss: 0.0911\n",
            "[exp_6] Episode 20900 | Loss: 0.1234\n",
            "[exp_6] Episode 20950 | Loss: 0.1437\n",
            "[exp_6] Episode 21000 | Loss: 0.1060\n",
            "[exp_6] Validation Accuracy: 80.27%\n",
            "[exp_6] Episode 21050 | Loss: 0.1001\n",
            "[exp_6] Episode 21100 | Loss: 0.1117\n",
            "[exp_6] Episode 21150 | Loss: 0.0650\n",
            "[exp_6] Episode 21200 | Loss: 0.0643\n",
            "[exp_6] Episode 21250 | Loss: 0.0832\n",
            "[exp_6] Episode 21300 | Loss: 0.0641\n",
            "[exp_6] Episode 21350 | Loss: 0.0765\n",
            "[exp_6] Episode 21400 | Loss: 0.0798\n",
            "[exp_6] Episode 21450 | Loss: 0.0756\n",
            "[exp_6] Episode 21500 | Loss: 0.0861\n",
            "[exp_6] Validation Accuracy: 80.23%\n",
            "[exp_6] Episode 21550 | Loss: 0.1036\n",
            "[exp_6] Episode 21600 | Loss: 0.0755\n",
            "[exp_6] Episode 21650 | Loss: 0.0574\n",
            "[exp_6] Episode 21700 | Loss: 0.0623\n",
            "[exp_6] Episode 21750 | Loss: 0.0623\n",
            "[exp_6] Episode 21800 | Loss: 0.0911\n",
            "[exp_6] Episode 21850 | Loss: 0.0926\n",
            "[exp_6] Episode 21900 | Loss: 0.0719\n",
            "[exp_6] Episode 21950 | Loss: 0.0567\n",
            "[exp_6] Episode 22000 | Loss: 0.0848\n",
            "[exp_6] Validation Accuracy: 78.85%\n",
            "[exp_6] Episode 22050 | Loss: 0.0948\n",
            "[exp_6] Episode 22100 | Loss: 0.0977\n",
            "[exp_6] Episode 22150 | Loss: 0.0946\n",
            "[exp_6] Episode 22200 | Loss: 0.1080\n",
            "[exp_6] Episode 22250 | Loss: 0.0610\n",
            "[exp_6] Episode 22300 | Loss: 0.0989\n",
            "[exp_6] Episode 22350 | Loss: 0.0864\n",
            "[exp_6] Episode 22400 | Loss: 0.0741\n",
            "[exp_6] Episode 22450 | Loss: 0.0790\n",
            "[exp_6] Episode 22500 | Loss: 0.0851\n",
            "[exp_6] Validation Accuracy: 79.77%\n",
            "[exp_6] Episode 22550 | Loss: 0.0945\n",
            "[exp_6] Episode 22600 | Loss: 0.0880\n",
            "[exp_6] Episode 22650 | Loss: 0.0688\n",
            "[exp_6] Episode 22700 | Loss: 0.0721\n",
            "[exp_6] Episode 22750 | Loss: 0.0767\n",
            "[exp_6] Episode 22800 | Loss: 0.0607\n",
            "[exp_6] Episode 22850 | Loss: 0.0773\n",
            "[exp_6] Episode 22900 | Loss: 0.0900\n",
            "[exp_6] Episode 22950 | Loss: 0.0874\n",
            "[exp_6] Episode 23000 | Loss: 0.0768\n",
            "[exp_6] Validation Accuracy: 78.45%\n",
            "[exp_6] Episode 23050 | Loss: 0.0723\n",
            "[exp_6] Episode 23100 | Loss: 0.0797\n",
            "[exp_6] Episode 23150 | Loss: 0.0703\n",
            "[exp_6] Episode 23200 | Loss: 0.1114\n",
            "[exp_6] Episode 23250 | Loss: 0.0556\n",
            "[exp_6] Episode 23300 | Loss: 0.0658\n",
            "[exp_6] Episode 23350 | Loss: 0.0570\n",
            "[exp_6] Episode 23400 | Loss: 0.0780\n",
            "[exp_6] Episode 23450 | Loss: 0.0766\n",
            "[exp_6] Episode 23500 | Loss: 0.0738\n",
            "[exp_6] Validation Accuracy: 79.60%\n",
            "[exp_6] Episode 23550 | Loss: 0.0614\n",
            "[exp_6] Episode 23600 | Loss: 0.0827\n",
            "[exp_6] Episode 23650 | Loss: 0.0935\n",
            "[exp_6] Episode 23700 | Loss: 0.0664\n",
            "[exp_6] Episode 23750 | Loss: 0.0910\n",
            "[exp_6] Episode 23800 | Loss: 0.0711\n",
            "[exp_6] Episode 23850 | Loss: 0.0586\n",
            "[exp_6] Episode 23900 | Loss: 0.0690\n",
            "[exp_6] Episode 23950 | Loss: 0.0746\n",
            "[exp_6] Episode 24000 | Loss: 0.1005\n",
            "[exp_6] Validation Accuracy: 80.88%\n",
            "[exp_6] Early stopping triggered at episode 24000\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_7 (shot: 5, meta_batch_size: 4, do_training: True)\n",
            "[exp_7] Episode 0 | Loss: 0.5654\n",
            "[exp_7] Episode 50 | Loss: 1.3948\n",
            "[exp_7] Episode 100 | Loss: 1.1490\n",
            "[exp_7] Episode 150 | Loss: 0.9280\n",
            "[exp_7] Episode 200 | Loss: 0.9631\n",
            "[exp_7] Episode 250 | Loss: 0.9008\n",
            "[exp_7] Episode 300 | Loss: 0.7955\n",
            "[exp_7] Episode 350 | Loss: 0.7555\n",
            "[exp_7] Episode 400 | Loss: 0.8102\n",
            "[exp_7] Episode 450 | Loss: 0.6781\n",
            "[exp_7] Episode 500 | Loss: 0.6988\n",
            "[exp_7] Validation Accuracy: 64.20%\n",
            "[exp_7] Episode 550 | Loss: 0.6814\n",
            "[exp_7] Episode 600 | Loss: 0.6505\n",
            "[exp_7] Episode 650 | Loss: 0.7345\n",
            "[exp_7] Episode 700 | Loss: 0.6612\n",
            "[exp_7] Episode 750 | Loss: 0.5965\n",
            "[exp_7] Episode 800 | Loss: 0.5562\n",
            "[exp_7] Episode 850 | Loss: 0.5947\n",
            "[exp_7] Episode 900 | Loss: 0.5841\n",
            "[exp_7] Episode 950 | Loss: 0.5788\n",
            "[exp_7] Episode 1000 | Loss: 0.5823\n",
            "[exp_7] Validation Accuracy: 70.28%\n",
            "[exp_7] Episode 1050 | Loss: 0.5704\n",
            "[exp_7] Episode 1100 | Loss: 0.6214\n",
            "[exp_7] Episode 1150 | Loss: 0.6418\n",
            "[exp_7] Episode 1200 | Loss: 0.5442\n",
            "[exp_7] Episode 1250 | Loss: 0.5290\n",
            "[exp_7] Episode 1300 | Loss: 0.5244\n",
            "[exp_7] Episode 1350 | Loss: 0.5365\n",
            "[exp_7] Episode 1400 | Loss: 0.5605\n",
            "[exp_7] Episode 1450 | Loss: 0.5392\n",
            "[exp_7] Episode 1500 | Loss: 0.5147\n",
            "[exp_7] Validation Accuracy: 75.12%\n",
            "[exp_7] Episode 1550 | Loss: 0.5439\n",
            "[exp_7] Episode 1600 | Loss: 0.4863\n",
            "[exp_7] Episode 1650 | Loss: 0.4641\n",
            "[exp_7] Episode 1700 | Loss: 0.4757\n",
            "[exp_7] Episode 1750 | Loss: 0.5485\n",
            "[exp_7] Episode 1800 | Loss: 0.5118\n",
            "[exp_7] Episode 1850 | Loss: 0.4403\n",
            "[exp_7] Episode 1900 | Loss: 0.4611\n",
            "[exp_7] Episode 1950 | Loss: 0.4591\n",
            "[exp_7] Episode 2000 | Loss: 0.5086\n",
            "[exp_7] Validation Accuracy: 72.28%\n",
            "[exp_7] Episode 2050 | Loss: 0.4687\n",
            "[exp_7] Episode 2100 | Loss: 0.5042\n",
            "[exp_7] Episode 2150 | Loss: 0.4604\n",
            "[exp_7] Episode 2200 | Loss: 0.4452\n",
            "[exp_7] Episode 2250 | Loss: 0.4525\n",
            "[exp_7] Episode 2300 | Loss: 0.4277\n",
            "[exp_7] Episode 2350 | Loss: 0.4955\n",
            "[exp_7] Episode 2400 | Loss: 0.3625\n",
            "[exp_7] Episode 2450 | Loss: 0.4117\n",
            "[exp_7] Episode 2500 | Loss: 0.4570\n",
            "[exp_7] Validation Accuracy: 74.83%\n",
            "[exp_7] Episode 2550 | Loss: 0.4113\n",
            "[exp_7] Episode 2600 | Loss: 0.4581\n",
            "[exp_7] Episode 2650 | Loss: 0.3789\n",
            "[exp_7] Episode 2700 | Loss: 0.4485\n",
            "[exp_7] Episode 2750 | Loss: 0.4127\n",
            "[exp_7] Episode 2800 | Loss: 0.4243\n",
            "[exp_7] Episode 2850 | Loss: 0.4901\n",
            "[exp_7] Episode 2900 | Loss: 0.4249\n",
            "[exp_7] Episode 2950 | Loss: 0.3828\n",
            "[exp_7] Episode 3000 | Loss: 0.4005\n",
            "[exp_7] Validation Accuracy: 75.55%\n",
            "[exp_7] Episode 3050 | Loss: 0.3956\n",
            "[exp_7] Episode 3100 | Loss: 0.3952\n",
            "[exp_7] Episode 3150 | Loss: 0.4180\n",
            "[exp_7] Episode 3200 | Loss: 0.3760\n",
            "[exp_7] Episode 3250 | Loss: 0.4239\n",
            "[exp_7] Episode 3300 | Loss: 0.4321\n",
            "[exp_7] Episode 3350 | Loss: 0.3710\n",
            "[exp_7] Episode 3400 | Loss: 0.3866\n",
            "[exp_7] Episode 3450 | Loss: 0.4517\n",
            "[exp_7] Episode 3500 | Loss: 0.3678\n",
            "[exp_7] Validation Accuracy: 75.42%\n",
            "[exp_7] Episode 3550 | Loss: 0.3648\n",
            "[exp_7] Episode 3600 | Loss: 0.3721\n",
            "[exp_7] Episode 3650 | Loss: 0.3692\n",
            "[exp_7] Episode 3700 | Loss: 0.3280\n",
            "[exp_7] Episode 3750 | Loss: 0.3888\n",
            "[exp_7] Episode 3800 | Loss: 0.3455\n",
            "[exp_7] Episode 3850 | Loss: 0.3503\n",
            "[exp_7] Episode 3900 | Loss: 0.3867\n",
            "[exp_7] Episode 3950 | Loss: 0.3815\n",
            "[exp_7] Episode 4000 | Loss: 0.3971\n",
            "[exp_7] Validation Accuracy: 75.75%\n",
            "[exp_7] Episode 4050 | Loss: 0.4060\n",
            "[exp_7] Episode 4100 | Loss: 0.3505\n",
            "[exp_7] Episode 4150 | Loss: 0.3639\n",
            "[exp_7] Episode 4200 | Loss: 0.3799\n",
            "[exp_7] Episode 4250 | Loss: 0.3642\n",
            "[exp_7] Episode 4300 | Loss: 0.3825\n",
            "[exp_7] Episode 4350 | Loss: 0.3555\n",
            "[exp_7] Episode 4400 | Loss: 0.3837\n",
            "[exp_7] Episode 4450 | Loss: 0.3296\n",
            "[exp_7] Episode 4500 | Loss: 0.3094\n",
            "[exp_7] Validation Accuracy: 77.80%\n",
            "[exp_7] Episode 4550 | Loss: 0.3266\n",
            "[exp_7] Episode 4600 | Loss: 0.3390\n",
            "[exp_7] Episode 4650 | Loss: 0.3648\n",
            "[exp_7] Episode 4700 | Loss: 0.3471\n",
            "[exp_7] Episode 4750 | Loss: 0.3856\n",
            "[exp_7] Episode 4800 | Loss: 0.3458\n",
            "[exp_7] Episode 4850 | Loss: 0.3427\n",
            "[exp_7] Episode 4900 | Loss: 0.2834\n",
            "[exp_7] Episode 4950 | Loss: 0.2782\n",
            "[exp_7] Episode 5000 | Loss: 0.3564\n",
            "[exp_7] Validation Accuracy: 79.42%\n",
            "[exp_7] Episode 5050 | Loss: 0.3450\n",
            "[exp_7] Episode 5100 | Loss: 0.3337\n",
            "[exp_7] Episode 5150 | Loss: 0.3416\n",
            "[exp_7] Episode 5200 | Loss: 0.3554\n",
            "[exp_7] Episode 5250 | Loss: 0.2952\n",
            "[exp_7] Episode 5300 | Loss: 0.3103\n",
            "[exp_7] Episode 5350 | Loss: 0.2834\n",
            "[exp_7] Episode 5400 | Loss: 0.2884\n",
            "[exp_7] Episode 5450 | Loss: 0.3560\n",
            "[exp_7] Episode 5500 | Loss: 0.3584\n",
            "[exp_7] Validation Accuracy: 75.90%\n",
            "[exp_7] Episode 5550 | Loss: 0.3398\n",
            "[exp_7] Episode 5600 | Loss: 0.3077\n",
            "[exp_7] Episode 5650 | Loss: 0.3204\n",
            "[exp_7] Episode 5700 | Loss: 0.2964\n",
            "[exp_7] Episode 5750 | Loss: 0.3060\n",
            "[exp_7] Episode 5800 | Loss: 0.3443\n",
            "[exp_7] Episode 5850 | Loss: 0.2536\n",
            "[exp_7] Episode 5900 | Loss: 0.2947\n",
            "[exp_7] Episode 5950 | Loss: 0.2846\n",
            "[exp_7] Episode 6000 | Loss: 0.2708\n",
            "[exp_7] Validation Accuracy: 77.03%\n",
            "[exp_7] Episode 6050 | Loss: 0.2391\n",
            "[exp_7] Episode 6100 | Loss: 0.3004\n",
            "[exp_7] Episode 6150 | Loss: 0.2936\n",
            "[exp_7] Episode 6200 | Loss: 0.2932\n",
            "[exp_7] Episode 6250 | Loss: 0.2722\n",
            "[exp_7] Episode 6300 | Loss: 0.2653\n",
            "[exp_7] Episode 6350 | Loss: 0.3059\n",
            "[exp_7] Episode 6400 | Loss: 0.2862\n",
            "[exp_7] Episode 6450 | Loss: 0.2654\n",
            "[exp_7] Episode 6500 | Loss: 0.2697\n",
            "[exp_7] Validation Accuracy: 79.53%\n",
            "[exp_7] Episode 6550 | Loss: 0.2696\n",
            "[exp_7] Episode 6600 | Loss: 0.2683\n",
            "[exp_7] Episode 6650 | Loss: 0.2723\n",
            "[exp_7] Episode 6700 | Loss: 0.2996\n",
            "[exp_7] Episode 6750 | Loss: 0.2674\n",
            "[exp_7] Episode 6800 | Loss: 0.2858\n",
            "[exp_7] Episode 6850 | Loss: 0.2950\n",
            "[exp_7] Episode 6900 | Loss: 0.2969\n",
            "[exp_7] Episode 6950 | Loss: 0.2353\n",
            "[exp_7] Episode 7000 | Loss: 0.2714\n",
            "[exp_7] Validation Accuracy: 79.77%\n",
            "[exp_7] Episode 7050 | Loss: 0.2336\n",
            "[exp_7] Episode 7100 | Loss: 0.2198\n",
            "[exp_7] Episode 7150 | Loss: 0.2884\n",
            "[exp_7] Episode 7200 | Loss: 0.2250\n",
            "[exp_7] Episode 7250 | Loss: 0.2902\n",
            "[exp_7] Episode 7300 | Loss: 0.2554\n",
            "[exp_7] Episode 7350 | Loss: 0.3038\n",
            "[exp_7] Episode 7400 | Loss: 0.2372\n",
            "[exp_7] Episode 7450 | Loss: 0.2905\n",
            "[exp_7] Episode 7500 | Loss: 0.2446\n",
            "[exp_7] Validation Accuracy: 80.25%\n",
            "[exp_7] Episode 7550 | Loss: 0.2694\n",
            "[exp_7] Episode 7600 | Loss: 0.2655\n",
            "[exp_7] Episode 7650 | Loss: 0.2119\n",
            "[exp_7] Episode 7700 | Loss: 0.2681\n",
            "[exp_7] Episode 7750 | Loss: 0.2716\n",
            "[exp_7] Episode 7800 | Loss: 0.2183\n",
            "[exp_7] Episode 7850 | Loss: 0.2269\n",
            "[exp_7] Episode 7900 | Loss: 0.2241\n",
            "[exp_7] Episode 7950 | Loss: 0.2371\n",
            "[exp_7] Episode 8000 | Loss: 0.2612\n",
            "[exp_7] Validation Accuracy: 79.72%\n",
            "[exp_7] Episode 8050 | Loss: 0.2431\n",
            "[exp_7] Episode 8100 | Loss: 0.2190\n",
            "[exp_7] Episode 8150 | Loss: 0.1888\n",
            "[exp_7] Episode 8200 | Loss: 0.2116\n",
            "[exp_7] Episode 8250 | Loss: 0.2180\n",
            "[exp_7] Episode 8300 | Loss: 0.2128\n",
            "[exp_7] Episode 8350 | Loss: 0.2807\n",
            "[exp_7] Episode 8400 | Loss: 0.2440\n",
            "[exp_7] Episode 8450 | Loss: 0.1945\n",
            "[exp_7] Episode 8500 | Loss: 0.2742\n",
            "[exp_7] Validation Accuracy: 79.00%\n",
            "[exp_7] Episode 8550 | Loss: 0.2363\n",
            "[exp_7] Episode 8600 | Loss: 0.2509\n",
            "[exp_7] Episode 8650 | Loss: 0.1807\n",
            "[exp_7] Episode 8700 | Loss: 0.2606\n",
            "[exp_7] Episode 8750 | Loss: 0.2693\n",
            "[exp_7] Episode 8800 | Loss: 0.2301\n",
            "[exp_7] Episode 8850 | Loss: 0.2041\n",
            "[exp_7] Episode 8900 | Loss: 0.2315\n",
            "[exp_7] Episode 8950 | Loss: 0.2333\n",
            "[exp_7] Episode 9000 | Loss: 0.2057\n",
            "[exp_7] Validation Accuracy: 78.55%\n",
            "[exp_7] Episode 9050 | Loss: 0.2476\n",
            "[exp_7] Episode 9100 | Loss: 0.2354\n",
            "[exp_7] Episode 9150 | Loss: 0.1815\n",
            "[exp_7] Episode 9200 | Loss: 0.2361\n",
            "[exp_7] Episode 9250 | Loss: 0.2222\n",
            "[exp_7] Episode 9300 | Loss: 0.1654\n",
            "[exp_7] Episode 9350 | Loss: 0.1917\n",
            "[exp_7] Episode 9400 | Loss: 0.2268\n",
            "[exp_7] Episode 9450 | Loss: 0.1670\n",
            "[exp_7] Episode 9500 | Loss: 0.2128\n",
            "[exp_7] Validation Accuracy: 77.58%\n",
            "[exp_7] Episode 9550 | Loss: 0.2211\n",
            "[exp_7] Episode 9600 | Loss: 0.1873\n",
            "[exp_7] Episode 9650 | Loss: 0.2009\n",
            "[exp_7] Episode 9700 | Loss: 0.2365\n",
            "[exp_7] Episode 9750 | Loss: 0.1984\n",
            "[exp_7] Episode 9800 | Loss: 0.2023\n",
            "[exp_7] Episode 9850 | Loss: 0.2089\n",
            "[exp_7] Episode 9900 | Loss: 0.1637\n",
            "[exp_7] Episode 9950 | Loss: 0.1632\n",
            "[exp_7] Episode 10000 | Loss: 0.2053\n",
            "[exp_7] Validation Accuracy: 78.10%\n",
            "[exp_7] Episode 10050 | Loss: 0.2186\n",
            "[exp_7] Episode 10100 | Loss: 0.1750\n",
            "[exp_7] Episode 10150 | Loss: 0.2187\n",
            "[exp_7] Episode 10200 | Loss: 0.1607\n",
            "[exp_7] Episode 10250 | Loss: 0.1865\n",
            "[exp_7] Episode 10300 | Loss: 0.1744\n",
            "[exp_7] Episode 10350 | Loss: 0.1474\n",
            "[exp_7] Episode 10400 | Loss: 0.1784\n",
            "[exp_7] Episode 10450 | Loss: 0.1829\n",
            "[exp_7] Episode 10500 | Loss: 0.1858\n",
            "[exp_7] Validation Accuracy: 79.17%\n",
            "[exp_7] Episode 10550 | Loss: 0.1664\n",
            "[exp_7] Episode 10600 | Loss: 0.1296\n",
            "[exp_7] Episode 10650 | Loss: 0.1404\n",
            "[exp_7] Episode 10700 | Loss: 0.1449\n",
            "[exp_7] Episode 10750 | Loss: 0.2335\n",
            "[exp_7] Episode 10800 | Loss: 0.2246\n",
            "[exp_7] Episode 10850 | Loss: 0.1944\n",
            "[exp_7] Episode 10900 | Loss: 0.1952\n",
            "[exp_7] Episode 10950 | Loss: 0.1837\n",
            "[exp_7] Episode 11000 | Loss: 0.2080\n",
            "[exp_7] Validation Accuracy: 78.65%\n",
            "[exp_7] Episode 11050 | Loss: 0.1849\n",
            "[exp_7] Episode 11100 | Loss: 0.1677\n",
            "[exp_7] Episode 11150 | Loss: 0.1942\n",
            "[exp_7] Episode 11200 | Loss: 0.1934\n",
            "[exp_7] Episode 11250 | Loss: 0.1744\n",
            "[exp_7] Episode 11300 | Loss: 0.1652\n",
            "[exp_7] Episode 11350 | Loss: 0.1577\n",
            "[exp_7] Episode 11400 | Loss: 0.1860\n",
            "[exp_7] Episode 11450 | Loss: 0.1729\n",
            "[exp_7] Episode 11500 | Loss: 0.2013\n",
            "[exp_7] Validation Accuracy: 80.60%\n",
            "[exp_7] Episode 11550 | Loss: 0.1880\n",
            "[exp_7] Episode 11600 | Loss: 0.1442\n",
            "[exp_7] Episode 11650 | Loss: 0.1383\n",
            "[exp_7] Episode 11700 | Loss: 0.1501\n",
            "[exp_7] Episode 11750 | Loss: 0.1897\n",
            "[exp_7] Episode 11800 | Loss: 0.1338\n",
            "[exp_7] Episode 11850 | Loss: 0.1505\n",
            "[exp_7] Episode 11900 | Loss: 0.1837\n",
            "[exp_7] Episode 11950 | Loss: 0.1744\n",
            "[exp_7] Episode 12000 | Loss: 0.1715\n",
            "[exp_7] Validation Accuracy: 80.73%\n",
            "[exp_7] Episode 12050 | Loss: 0.1948\n",
            "[exp_7] Episode 12100 | Loss: 0.1477\n",
            "[exp_7] Episode 12150 | Loss: 0.1524\n",
            "[exp_7] Episode 12200 | Loss: 0.1686\n",
            "[exp_7] Episode 12250 | Loss: 0.1400\n",
            "[exp_7] Episode 12300 | Loss: 0.1883\n",
            "[exp_7] Episode 12350 | Loss: 0.2052\n",
            "[exp_7] Episode 12400 | Loss: 0.1486\n",
            "[exp_7] Episode 12450 | Loss: 0.1329\n",
            "[exp_7] Episode 12500 | Loss: 0.1187\n",
            "[exp_7] Validation Accuracy: 80.50%\n",
            "[exp_7] Episode 12550 | Loss: 0.1326\n",
            "[exp_7] Episode 12600 | Loss: 0.1435\n",
            "[exp_7] Episode 12650 | Loss: 0.1286\n",
            "[exp_7] Episode 12700 | Loss: 0.1803\n",
            "[exp_7] Episode 12750 | Loss: 0.1833\n",
            "[exp_7] Episode 12800 | Loss: 0.1527\n",
            "[exp_7] Episode 12850 | Loss: 0.1610\n",
            "[exp_7] Episode 12900 | Loss: 0.1356\n",
            "[exp_7] Episode 12950 | Loss: 0.1628\n",
            "[exp_7] Episode 13000 | Loss: 0.1459\n",
            "[exp_7] Validation Accuracy: 79.85%\n",
            "[exp_7] Episode 13050 | Loss: 0.1359\n",
            "[exp_7] Episode 13100 | Loss: 0.1453\n",
            "[exp_7] Episode 13150 | Loss: 0.1538\n",
            "[exp_7] Episode 13200 | Loss: 0.1627\n",
            "[exp_7] Episode 13250 | Loss: 0.1499\n",
            "[exp_7] Episode 13300 | Loss: 0.1287\n",
            "[exp_7] Episode 13350 | Loss: 0.1497\n",
            "[exp_7] Episode 13400 | Loss: 0.1576\n",
            "[exp_7] Episode 13450 | Loss: 0.1539\n",
            "[exp_7] Episode 13500 | Loss: 0.1502\n",
            "[exp_7] Validation Accuracy: 81.05%\n",
            "[exp_7] Episode 13550 | Loss: 0.1796\n",
            "[exp_7] Episode 13600 | Loss: 0.1732\n",
            "[exp_7] Episode 13650 | Loss: 0.1409\n",
            "[exp_7] Episode 13700 | Loss: 0.1955\n",
            "[exp_7] Episode 13750 | Loss: 0.0939\n",
            "[exp_7] Episode 13800 | Loss: 0.1711\n",
            "[exp_7] Episode 13850 | Loss: 0.1489\n",
            "[exp_7] Episode 13900 | Loss: 0.1802\n",
            "[exp_7] Episode 13950 | Loss: 0.1221\n",
            "[exp_7] Episode 14000 | Loss: 0.1533\n",
            "[exp_7] Validation Accuracy: 78.33%\n",
            "[exp_7] Episode 14050 | Loss: 0.1445\n",
            "[exp_7] Episode 14100 | Loss: 0.1532\n",
            "[exp_7] Episode 14150 | Loss: 0.1656\n",
            "[exp_7] Episode 14200 | Loss: 0.1391\n",
            "[exp_7] Episode 14250 | Loss: 0.1561\n",
            "[exp_7] Episode 14300 | Loss: 0.1405\n",
            "[exp_7] Episode 14350 | Loss: 0.1334\n",
            "[exp_7] Episode 14400 | Loss: 0.1398\n",
            "[exp_7] Episode 14450 | Loss: 0.1287\n",
            "[exp_7] Episode 14500 | Loss: 0.1093\n",
            "[exp_7] Validation Accuracy: 81.12%\n",
            "[exp_7] Episode 14550 | Loss: 0.1356\n",
            "[exp_7] Episode 14600 | Loss: 0.1052\n",
            "[exp_7] Episode 14650 | Loss: 0.1306\n",
            "[exp_7] Episode 14700 | Loss: 0.1119\n",
            "[exp_7] Episode 14750 | Loss: 0.1019\n",
            "[exp_7] Episode 14800 | Loss: 0.1213\n",
            "[exp_7] Episode 14850 | Loss: 0.1479\n",
            "[exp_7] Episode 14900 | Loss: 0.1424\n",
            "[exp_7] Episode 14950 | Loss: 0.0938\n",
            "[exp_7] Episode 15000 | Loss: 0.1390\n",
            "[exp_7] Validation Accuracy: 77.30%\n",
            "[exp_7] Episode 15050 | Loss: 0.0989\n",
            "[exp_7] Episode 15100 | Loss: 0.1396\n",
            "[exp_7] Episode 15150 | Loss: 0.1243\n",
            "[exp_7] Episode 15200 | Loss: 0.1145\n",
            "[exp_7] Episode 15250 | Loss: 0.1188\n",
            "[exp_7] Episode 15300 | Loss: 0.1075\n",
            "[exp_7] Episode 15350 | Loss: 0.1229\n",
            "[exp_7] Episode 15400 | Loss: 0.0872\n",
            "[exp_7] Episode 15450 | Loss: 0.1527\n",
            "[exp_7] Episode 15500 | Loss: 0.1250\n",
            "[exp_7] Validation Accuracy: 79.17%\n",
            "[exp_7] Episode 15550 | Loss: 0.1072\n",
            "[exp_7] Episode 15600 | Loss: 0.1176\n",
            "[exp_7] Episode 15650 | Loss: 0.1110\n",
            "[exp_7] Episode 15700 | Loss: 0.1030\n",
            "[exp_7] Episode 15750 | Loss: 0.1171\n",
            "[exp_7] Episode 15800 | Loss: 0.1336\n",
            "[exp_7] Episode 15850 | Loss: 0.1318\n",
            "[exp_7] Episode 15900 | Loss: 0.1036\n",
            "[exp_7] Episode 15950 | Loss: 0.1075\n",
            "[exp_7] Episode 16000 | Loss: 0.1379\n",
            "[exp_7] Validation Accuracy: 79.80%\n",
            "[exp_7] Episode 16050 | Loss: 0.1166\n",
            "[exp_7] Episode 16100 | Loss: 0.1481\n",
            "[exp_7] Episode 16150 | Loss: 0.1175\n",
            "[exp_7] Episode 16200 | Loss: 0.1257\n",
            "[exp_7] Episode 16250 | Loss: 0.1382\n",
            "[exp_7] Episode 16300 | Loss: 0.1319\n",
            "[exp_7] Episode 16350 | Loss: 0.1076\n",
            "[exp_7] Episode 16400 | Loss: 0.1444\n",
            "[exp_7] Episode 16450 | Loss: 0.0850\n",
            "[exp_7] Episode 16500 | Loss: 0.0972\n",
            "[exp_7] Validation Accuracy: 80.55%\n",
            "[exp_7] Episode 16550 | Loss: 0.0844\n",
            "[exp_7] Episode 16600 | Loss: 0.1146\n",
            "[exp_7] Episode 16650 | Loss: 0.0910\n",
            "[exp_7] Episode 16700 | Loss: 0.1233\n",
            "[exp_7] Episode 16750 | Loss: 0.1358\n",
            "[exp_7] Episode 16800 | Loss: 0.1420\n",
            "[exp_7] Episode 16850 | Loss: 0.1095\n",
            "[exp_7] Episode 16900 | Loss: 0.1312\n",
            "[exp_7] Episode 16950 | Loss: 0.1165\n",
            "[exp_7] Episode 17000 | Loss: 0.1091\n",
            "[exp_7] Validation Accuracy: 77.92%\n",
            "[exp_7] Episode 17050 | Loss: 0.1154\n",
            "[exp_7] Episode 17100 | Loss: 0.0933\n",
            "[exp_7] Episode 17150 | Loss: 0.1361\n",
            "[exp_7] Episode 17200 | Loss: 0.1065\n",
            "[exp_7] Episode 17250 | Loss: 0.1004\n",
            "[exp_7] Episode 17300 | Loss: 0.0955\n",
            "[exp_7] Episode 17350 | Loss: 0.0910\n",
            "[exp_7] Episode 17400 | Loss: 0.1088\n",
            "[exp_7] Episode 17450 | Loss: 0.1026\n",
            "[exp_7] Episode 17500 | Loss: 0.0972\n",
            "[exp_7] Validation Accuracy: 80.50%\n",
            "[exp_7] Episode 17550 | Loss: 0.0948\n",
            "[exp_7] Episode 17600 | Loss: 0.1045\n",
            "[exp_7] Episode 17650 | Loss: 0.1384\n",
            "[exp_7] Episode 17700 | Loss: 0.1035\n",
            "[exp_7] Episode 17750 | Loss: 0.1151\n",
            "[exp_7] Episode 17800 | Loss: 0.1101\n",
            "[exp_7] Episode 17850 | Loss: 0.1017\n",
            "[exp_7] Episode 17900 | Loss: 0.1506\n",
            "[exp_7] Episode 17950 | Loss: 0.1153\n",
            "[exp_7] Episode 18000 | Loss: 0.1164\n",
            "[exp_7] Validation Accuracy: 80.17%\n",
            "[exp_7] Episode 18050 | Loss: 0.0927\n",
            "[exp_7] Episode 18100 | Loss: 0.0749\n",
            "[exp_7] Episode 18150 | Loss: 0.1047\n",
            "[exp_7] Episode 18200 | Loss: 0.0950\n",
            "[exp_7] Episode 18250 | Loss: 0.1202\n",
            "[exp_7] Episode 18300 | Loss: 0.0864\n",
            "[exp_7] Episode 18350 | Loss: 0.1103\n",
            "[exp_7] Episode 18400 | Loss: 0.1060\n",
            "[exp_7] Episode 18450 | Loss: 0.1402\n",
            "[exp_7] Episode 18500 | Loss: 0.1066\n",
            "[exp_7] Validation Accuracy: 78.38%\n",
            "[exp_7] Episode 18550 | Loss: 0.1029\n",
            "[exp_7] Episode 18600 | Loss: 0.1335\n",
            "[exp_7] Episode 18650 | Loss: 0.0981\n",
            "[exp_7] Episode 18700 | Loss: 0.0875\n",
            "[exp_7] Episode 18750 | Loss: 0.0982\n",
            "[exp_7] Episode 18800 | Loss: 0.1064\n",
            "[exp_7] Episode 18850 | Loss: 0.1067\n",
            "[exp_7] Episode 18900 | Loss: 0.0924\n",
            "[exp_7] Episode 18950 | Loss: 0.1069\n",
            "[exp_7] Episode 19000 | Loss: 0.0793\n",
            "[exp_7] Validation Accuracy: 81.17%\n",
            "[exp_7] Episode 19050 | Loss: 0.0814\n",
            "[exp_7] Episode 19100 | Loss: 0.1074\n",
            "[exp_7] Episode 19150 | Loss: 0.0825\n",
            "[exp_7] Episode 19200 | Loss: 0.1185\n",
            "[exp_7] Episode 19250 | Loss: 0.0893\n",
            "[exp_7] Episode 19300 | Loss: 0.0981\n",
            "[exp_7] Episode 19350 | Loss: 0.0818\n",
            "[exp_7] Episode 19400 | Loss: 0.0697\n",
            "[exp_7] Episode 19450 | Loss: 0.0588\n",
            "[exp_7] Episode 19500 | Loss: 0.0876\n",
            "[exp_7] Validation Accuracy: 80.38%\n",
            "[exp_7] Episode 19550 | Loss: 0.0828\n",
            "[exp_7] Episode 19600 | Loss: 0.0939\n",
            "[exp_7] Episode 19650 | Loss: 0.1246\n",
            "[exp_7] Episode 19700 | Loss: 0.1064\n",
            "[exp_7] Episode 19750 | Loss: 0.1239\n",
            "[exp_7] Episode 19800 | Loss: 0.1193\n",
            "[exp_7] Episode 19850 | Loss: 0.0889\n",
            "[exp_7] Episode 19900 | Loss: 0.1037\n",
            "[exp_7] Episode 19950 | Loss: 0.0927\n",
            "[exp_7] Episode 20000 | Loss: 0.0899\n",
            "[exp_7] Validation Accuracy: 79.22%\n",
            "[exp_7] Episode 20050 | Loss: 0.0558\n",
            "[exp_7] Episode 20100 | Loss: 0.0851\n",
            "[exp_7] Episode 20150 | Loss: 0.1006\n",
            "[exp_7] Episode 20200 | Loss: 0.0946\n",
            "[exp_7] Episode 20250 | Loss: 0.1125\n",
            "[exp_7] Episode 20300 | Loss: 0.0933\n",
            "[exp_7] Episode 20350 | Loss: 0.0862\n",
            "[exp_7] Episode 20400 | Loss: 0.1156\n",
            "[exp_7] Episode 20450 | Loss: 0.1129\n",
            "[exp_7] Episode 20500 | Loss: 0.1190\n",
            "[exp_7] Validation Accuracy: 78.90%\n",
            "[exp_7] Episode 20550 | Loss: 0.0572\n",
            "[exp_7] Episode 20600 | Loss: 0.0939\n",
            "[exp_7] Episode 20650 | Loss: 0.0895\n",
            "[exp_7] Episode 20700 | Loss: 0.0970\n",
            "[exp_7] Episode 20750 | Loss: 0.1002\n",
            "[exp_7] Episode 20800 | Loss: 0.1023\n",
            "[exp_7] Episode 20850 | Loss: 0.1038\n",
            "[exp_7] Episode 20900 | Loss: 0.1241\n",
            "[exp_7] Episode 20950 | Loss: 0.1269\n",
            "[exp_7] Episode 21000 | Loss: 0.0956\n",
            "[exp_7] Validation Accuracy: 79.15%\n",
            "[exp_7] Episode 21050 | Loss: 0.0988\n",
            "[exp_7] Episode 21100 | Loss: 0.1002\n",
            "[exp_7] Episode 21150 | Loss: 0.0852\n",
            "[exp_7] Episode 21200 | Loss: 0.0778\n",
            "[exp_7] Episode 21250 | Loss: 0.0797\n",
            "[exp_7] Episode 21300 | Loss: 0.0530\n",
            "[exp_7] Episode 21350 | Loss: 0.0785\n",
            "[exp_7] Episode 21400 | Loss: 0.0850\n",
            "[exp_7] Episode 21450 | Loss: 0.0808\n",
            "[exp_7] Episode 21500 | Loss: 0.0779\n",
            "[exp_7] Validation Accuracy: 80.30%\n",
            "[exp_7] Episode 21550 | Loss: 0.0961\n",
            "[exp_7] Episode 21600 | Loss: 0.0706\n",
            "[exp_7] Episode 21650 | Loss: 0.0539\n",
            "[exp_7] Episode 21700 | Loss: 0.0670\n",
            "[exp_7] Episode 21750 | Loss: 0.0544\n",
            "[exp_7] Episode 21800 | Loss: 0.1036\n",
            "[exp_7] Episode 21850 | Loss: 0.0908\n",
            "[exp_7] Episode 21900 | Loss: 0.0803\n",
            "[exp_7] Episode 21950 | Loss: 0.0711\n",
            "[exp_7] Episode 22000 | Loss: 0.0697\n",
            "[exp_7] Validation Accuracy: 78.40%\n",
            "[exp_7] Episode 22050 | Loss: 0.0922\n",
            "[exp_7] Episode 22100 | Loss: 0.1113\n",
            "[exp_7] Episode 22150 | Loss: 0.1049\n",
            "[exp_7] Episode 22200 | Loss: 0.1142\n",
            "[exp_7] Episode 22250 | Loss: 0.0776\n",
            "[exp_7] Episode 22300 | Loss: 0.1010\n",
            "[exp_7] Episode 22350 | Loss: 0.0869\n",
            "[exp_7] Episode 22400 | Loss: 0.0691\n",
            "[exp_7] Episode 22450 | Loss: 0.0892\n",
            "[exp_7] Episode 22500 | Loss: 0.0814\n",
            "[exp_7] Validation Accuracy: 79.80%\n",
            "[exp_7] Episode 22550 | Loss: 0.1000\n",
            "[exp_7] Episode 22600 | Loss: 0.1132\n",
            "[exp_7] Episode 22650 | Loss: 0.0924\n",
            "[exp_7] Episode 22700 | Loss: 0.0756\n",
            "[exp_7] Episode 22750 | Loss: 0.0749\n",
            "[exp_7] Episode 22800 | Loss: 0.0741\n",
            "[exp_7] Episode 22850 | Loss: 0.0745\n",
            "[exp_7] Episode 22900 | Loss: 0.0828\n",
            "[exp_7] Episode 22950 | Loss: 0.0837\n",
            "[exp_7] Episode 23000 | Loss: 0.0895\n",
            "[exp_7] Validation Accuracy: 79.40%\n",
            "[exp_7] Episode 23050 | Loss: 0.0650\n",
            "[exp_7] Episode 23100 | Loss: 0.0884\n",
            "[exp_7] Episode 23150 | Loss: 0.0674\n",
            "[exp_7] Episode 23200 | Loss: 0.0943\n",
            "[exp_7] Episode 23250 | Loss: 0.0532\n",
            "[exp_7] Episode 23300 | Loss: 0.0723\n",
            "[exp_7] Episode 23350 | Loss: 0.0750\n",
            "[exp_7] Episode 23400 | Loss: 0.0729\n",
            "[exp_7] Episode 23450 | Loss: 0.0842\n",
            "[exp_7] Episode 23500 | Loss: 0.0843\n",
            "[exp_7] Validation Accuracy: 79.47%\n",
            "[exp_7] Episode 23550 | Loss: 0.0780\n",
            "[exp_7] Episode 23600 | Loss: 0.0924\n",
            "[exp_7] Episode 23650 | Loss: 0.1155\n",
            "[exp_7] Episode 23700 | Loss: 0.1073\n",
            "[exp_7] Episode 23750 | Loss: 0.0997\n",
            "[exp_7] Episode 23800 | Loss: 0.0641\n",
            "[exp_7] Episode 23850 | Loss: 0.0623\n",
            "[exp_7] Episode 23900 | Loss: 0.0768\n",
            "[exp_7] Episode 23950 | Loss: 0.0772\n",
            "[exp_7] Episode 24000 | Loss: 0.1080\n",
            "[exp_7] Validation Accuracy: 80.03%\n",
            "[exp_7] Early stopping triggered at episode 24000\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "==============================\n",
            "실험 시작: exp_8 (shot: 5, meta_batch_size: 8, do_training: True)\n",
            "[exp_8] Episode 0 | Loss: 0.5654\n",
            "[exp_8] Episode 50 | Loss: 1.4579\n",
            "[exp_8] Episode 100 | Loss: 1.1381\n",
            "[exp_8] Episode 150 | Loss: 1.0443\n",
            "[exp_8] Episode 200 | Loss: 0.9988\n",
            "[exp_8] Episode 250 | Loss: 1.0081\n",
            "[exp_8] Episode 300 | Loss: 0.9525\n",
            "[exp_8] Episode 350 | Loss: 0.8461\n",
            "[exp_8] Episode 400 | Loss: 0.9067\n",
            "[exp_8] Episode 450 | Loss: 0.7866\n",
            "[exp_8] Episode 500 | Loss: 0.8016\n",
            "[exp_8] Validation Accuracy: 58.38%\n",
            "[exp_8] Episode 550 | Loss: 0.7940\n",
            "[exp_8] Episode 600 | Loss: 0.7499\n",
            "[exp_8] Episode 650 | Loss: 0.7599\n",
            "[exp_8] Episode 700 | Loss: 0.7344\n",
            "[exp_8] Episode 750 | Loss: 0.6670\n",
            "[exp_8] Episode 800 | Loss: 0.5969\n",
            "[exp_8] Episode 850 | Loss: 0.6461\n",
            "[exp_8] Episode 900 | Loss: 0.6155\n",
            "[exp_8] Episode 950 | Loss: 0.6177\n",
            "[exp_8] Episode 1000 | Loss: 0.6399\n",
            "[exp_8] Validation Accuracy: 67.05%\n",
            "[exp_8] Episode 1050 | Loss: 0.5888\n",
            "[exp_8] Episode 1100 | Loss: 0.6613\n",
            "[exp_8] Episode 1150 | Loss: 0.6788\n",
            "[exp_8] Episode 1200 | Loss: 0.5780\n",
            "[exp_8] Episode 1250 | Loss: 0.5624\n",
            "[exp_8] Episode 1300 | Loss: 0.5536\n",
            "[exp_8] Episode 1350 | Loss: 0.5996\n",
            "[exp_8] Episode 1400 | Loss: 0.5815\n",
            "[exp_8] Episode 1450 | Loss: 0.5586\n",
            "[exp_8] Episode 1500 | Loss: 0.5588\n",
            "[exp_8] Validation Accuracy: 72.15%\n",
            "[exp_8] Episode 1550 | Loss: 0.5589\n",
            "[exp_8] Episode 1600 | Loss: 0.5226\n",
            "[exp_8] Episode 1650 | Loss: 0.5244\n",
            "[exp_8] Episode 1700 | Loss: 0.4848\n",
            "[exp_8] Episode 1750 | Loss: 0.5551\n",
            "[exp_8] Episode 1800 | Loss: 0.5456\n",
            "[exp_8] Episode 1850 | Loss: 0.4864\n",
            "[exp_8] Episode 1900 | Loss: 0.5009\n",
            "[exp_8] Episode 1950 | Loss: 0.4763\n",
            "[exp_8] Episode 2000 | Loss: 0.5185\n",
            "[exp_8] Validation Accuracy: 72.88%\n",
            "[exp_8] Episode 2050 | Loss: 0.4709\n",
            "[exp_8] Episode 2100 | Loss: 0.5286\n",
            "[exp_8] Episode 2150 | Loss: 0.4731\n",
            "[exp_8] Episode 2200 | Loss: 0.4715\n",
            "[exp_8] Episode 2250 | Loss: 0.4837\n",
            "[exp_8] Episode 2300 | Loss: 0.4314\n",
            "[exp_8] Episode 2350 | Loss: 0.5268\n",
            "[exp_8] Episode 2400 | Loss: 0.4087\n",
            "[exp_8] Episode 2450 | Loss: 0.4260\n",
            "[exp_8] Episode 2500 | Loss: 0.4779\n",
            "[exp_8] Validation Accuracy: 73.58%\n",
            "[exp_8] Episode 2550 | Loss: 0.4654\n",
            "[exp_8] Episode 2600 | Loss: 0.4639\n",
            "[exp_8] Episode 2650 | Loss: 0.4092\n",
            "[exp_8] Episode 2700 | Loss: 0.4778\n",
            "[exp_8] Episode 2750 | Loss: 0.4292\n",
            "[exp_8] Episode 2800 | Loss: 0.4264\n",
            "[exp_8] Episode 2850 | Loss: 0.4845\n",
            "[exp_8] Episode 2900 | Loss: 0.4476\n",
            "[exp_8] Episode 2950 | Loss: 0.4026\n",
            "[exp_8] Episode 3000 | Loss: 0.4519\n",
            "[exp_8] Validation Accuracy: 75.55%\n",
            "[exp_8] Episode 3050 | Loss: 0.4197\n",
            "[exp_8] Episode 3100 | Loss: 0.4153\n",
            "[exp_8] Episode 3150 | Loss: 0.4689\n",
            "[exp_8] Episode 3200 | Loss: 0.3645\n",
            "[exp_8] Episode 3250 | Loss: 0.4216\n",
            "[exp_8] Episode 3300 | Loss: 0.4305\n",
            "[exp_8] Episode 3350 | Loss: 0.3982\n",
            "[exp_8] Episode 3400 | Loss: 0.4114\n",
            "[exp_8] Episode 3450 | Loss: 0.4951\n",
            "[exp_8] Episode 3500 | Loss: 0.4075\n",
            "[exp_8] Validation Accuracy: 76.53%\n",
            "[exp_8] Episode 3550 | Loss: 0.3712\n",
            "[exp_8] Episode 3600 | Loss: 0.4194\n",
            "[exp_8] Episode 3650 | Loss: 0.3826\n",
            "[exp_8] Episode 3700 | Loss: 0.3538\n",
            "[exp_8] Episode 3750 | Loss: 0.3811\n",
            "[exp_8] Episode 3800 | Loss: 0.3801\n",
            "[exp_8] Episode 3850 | Loss: 0.3709\n",
            "[exp_8] Episode 3900 | Loss: 0.3839\n",
            "[exp_8] Episode 3950 | Loss: 0.3636\n",
            "[exp_8] Episode 4000 | Loss: 0.3938\n",
            "[exp_8] Validation Accuracy: 73.50%\n",
            "[exp_8] Episode 4050 | Loss: 0.4211\n",
            "[exp_8] Episode 4100 | Loss: 0.3916\n",
            "[exp_8] Episode 4150 | Loss: 0.3787\n",
            "[exp_8] Episode 4200 | Loss: 0.3953\n",
            "[exp_8] Episode 4250 | Loss: 0.3684\n",
            "[exp_8] Episode 4300 | Loss: 0.4370\n",
            "[exp_8] Episode 4350 | Loss: 0.3604\n",
            "[exp_8] Episode 4400 | Loss: 0.3739\n",
            "[exp_8] Episode 4450 | Loss: 0.3406\n",
            "[exp_8] Episode 4500 | Loss: 0.3529\n",
            "[exp_8] Validation Accuracy: 76.17%\n",
            "[exp_8] Episode 4550 | Loss: 0.3523\n",
            "[exp_8] Episode 4600 | Loss: 0.3620\n",
            "[exp_8] Episode 4650 | Loss: 0.3694\n",
            "[exp_8] Episode 4700 | Loss: 0.3601\n",
            "[exp_8] Episode 4750 | Loss: 0.4170\n",
            "[exp_8] Episode 4800 | Loss: 0.3678\n",
            "[exp_8] Episode 4850 | Loss: 0.3469\n",
            "[exp_8] Episode 4900 | Loss: 0.2941\n",
            "[exp_8] Episode 4950 | Loss: 0.2837\n",
            "[exp_8] Episode 5000 | Loss: 0.3670\n",
            "[exp_8] Validation Accuracy: 77.85%\n",
            "[exp_8] Episode 5050 | Loss: 0.3692\n",
            "[exp_8] Episode 5100 | Loss: 0.3256\n",
            "[exp_8] Episode 5150 | Loss: 0.3534\n",
            "[exp_8] Episode 5200 | Loss: 0.3507\n",
            "[exp_8] Episode 5250 | Loss: 0.3038\n",
            "[exp_8] Episode 5300 | Loss: 0.3095\n",
            "[exp_8] Episode 5350 | Loss: 0.3065\n",
            "[exp_8] Episode 5400 | Loss: 0.3088\n",
            "[exp_8] Episode 5450 | Loss: 0.3575\n",
            "[exp_8] Episode 5500 | Loss: 0.3723\n",
            "[exp_8] Validation Accuracy: 75.35%\n",
            "[exp_8] Episode 5550 | Loss: 0.3333\n",
            "[exp_8] Episode 5600 | Loss: 0.3185\n",
            "[exp_8] Episode 5650 | Loss: 0.3294\n",
            "[exp_8] Episode 5700 | Loss: 0.3262\n",
            "[exp_8] Episode 5750 | Loss: 0.3119\n",
            "[exp_8] Episode 5800 | Loss: 0.3381\n",
            "[exp_8] Episode 5850 | Loss: 0.2517\n",
            "[exp_8] Episode 5900 | Loss: 0.3006\n",
            "[exp_8] Episode 5950 | Loss: 0.2975\n",
            "[exp_8] Episode 6000 | Loss: 0.2787\n",
            "[exp_8] Validation Accuracy: 76.12%\n",
            "[exp_8] Episode 6050 | Loss: 0.2873\n",
            "[exp_8] Episode 6100 | Loss: 0.3036\n",
            "[exp_8] Episode 6150 | Loss: 0.3086\n",
            "[exp_8] Episode 6200 | Loss: 0.2789\n",
            "[exp_8] Episode 6250 | Loss: 0.2663\n",
            "[exp_8] Episode 6300 | Loss: 0.2692\n",
            "[exp_8] Episode 6350 | Loss: 0.3233\n",
            "[exp_8] Episode 6400 | Loss: 0.3015\n",
            "[exp_8] Episode 6450 | Loss: 0.2744\n",
            "[exp_8] Episode 6500 | Loss: 0.2754\n",
            "[exp_8] Validation Accuracy: 80.15%\n",
            "[exp_8] Episode 6550 | Loss: 0.2714\n",
            "[exp_8] Episode 6600 | Loss: 0.2695\n",
            "[exp_8] Episode 6650 | Loss: 0.3001\n",
            "[exp_8] Episode 6700 | Loss: 0.2896\n",
            "[exp_8] Episode 6750 | Loss: 0.2539\n",
            "[exp_8] Episode 6800 | Loss: 0.2878\n",
            "[exp_8] Episode 6850 | Loss: 0.2914\n",
            "[exp_8] Episode 6900 | Loss: 0.3096\n",
            "[exp_8] Episode 6950 | Loss: 0.2711\n",
            "[exp_8] Episode 7000 | Loss: 0.3048\n",
            "[exp_8] Validation Accuracy: 79.57%\n",
            "[exp_8] Episode 7050 | Loss: 0.2314\n",
            "[exp_8] Episode 7100 | Loss: 0.2368\n",
            "[exp_8] Episode 7150 | Loss: 0.2820\n",
            "[exp_8] Episode 7200 | Loss: 0.2129\n",
            "[exp_8] Episode 7250 | Loss: 0.2862\n",
            "[exp_8] Episode 7300 | Loss: 0.2560\n",
            "[exp_8] Episode 7350 | Loss: 0.3198\n",
            "[exp_8] Episode 7400 | Loss: 0.2689\n",
            "[exp_8] Episode 7450 | Loss: 0.2970\n",
            "[exp_8] Episode 7500 | Loss: 0.2504\n",
            "[exp_8] Validation Accuracy: 80.90%\n",
            "[exp_8] Episode 7550 | Loss: 0.2746\n",
            "[exp_8] Episode 7600 | Loss: 0.2523\n",
            "[exp_8] Episode 7650 | Loss: 0.2200\n",
            "[exp_8] Episode 7700 | Loss: 0.2645\n",
            "[exp_8] Episode 7750 | Loss: 0.2800\n",
            "[exp_8] Episode 7800 | Loss: 0.2208\n",
            "[exp_8] Episode 7850 | Loss: 0.2267\n",
            "[exp_8] Episode 7900 | Loss: 0.2303\n",
            "[exp_8] Episode 7950 | Loss: 0.2373\n",
            "[exp_8] Episode 8000 | Loss: 0.2785\n",
            "[exp_8] Validation Accuracy: 78.75%\n",
            "[exp_8] Episode 8050 | Loss: 0.2574\n",
            "[exp_8] Episode 8100 | Loss: 0.2328\n",
            "[exp_8] Episode 8150 | Loss: 0.2049\n",
            "[exp_8] Episode 8200 | Loss: 0.2160\n",
            "[exp_8] Episode 8250 | Loss: 0.2257\n",
            "[exp_8] Episode 8300 | Loss: 0.2148\n",
            "[exp_8] Episode 8350 | Loss: 0.2777\n",
            "[exp_8] Episode 8400 | Loss: 0.2439\n",
            "[exp_8] Episode 8450 | Loss: 0.1861\n",
            "[exp_8] Episode 8500 | Loss: 0.2512\n",
            "[exp_8] Validation Accuracy: 77.92%\n",
            "[exp_8] Episode 8550 | Loss: 0.2259\n",
            "[exp_8] Episode 8600 | Loss: 0.2671\n",
            "[exp_8] Episode 8650 | Loss: 0.1818\n",
            "[exp_8] Episode 8700 | Loss: 0.2523\n",
            "[exp_8] Episode 8750 | Loss: 0.2423\n",
            "[exp_8] Episode 8800 | Loss: 0.2289\n",
            "[exp_8] Episode 8850 | Loss: 0.2218\n",
            "[exp_8] Episode 8900 | Loss: 0.2276\n",
            "[exp_8] Episode 8950 | Loss: 0.2545\n",
            "[exp_8] Episode 9000 | Loss: 0.2190\n",
            "[exp_8] Validation Accuracy: 79.17%\n",
            "[exp_8] Episode 9050 | Loss: 0.2207\n",
            "[exp_8] Episode 9100 | Loss: 0.2185\n",
            "[exp_8] Episode 9150 | Loss: 0.1799\n",
            "[exp_8] Episode 9200 | Loss: 0.2312\n",
            "[exp_8] Episode 9250 | Loss: 0.2360\n",
            "[exp_8] Episode 9300 | Loss: 0.1697\n",
            "[exp_8] Episode 9350 | Loss: 0.2018\n",
            "[exp_8] Episode 9400 | Loss: 0.2280\n",
            "[exp_8] Episode 9450 | Loss: 0.1789\n",
            "[exp_8] Episode 9500 | Loss: 0.2013\n",
            "[exp_8] Validation Accuracy: 79.00%\n",
            "[exp_8] Episode 9550 | Loss: 0.2309\n",
            "[exp_8] Episode 9600 | Loss: 0.2107\n",
            "[exp_8] Episode 9650 | Loss: 0.2046\n",
            "[exp_8] Episode 9700 | Loss: 0.2354\n",
            "[exp_8] Episode 9750 | Loss: 0.1997\n",
            "[exp_8] Episode 9800 | Loss: 0.2084\n",
            "[exp_8] Episode 9850 | Loss: 0.1960\n",
            "[exp_8] Episode 9900 | Loss: 0.1889\n",
            "[exp_8] Episode 9950 | Loss: 0.1678\n",
            "[exp_8] Episode 10000 | Loss: 0.2201\n",
            "[exp_8] Validation Accuracy: 76.83%\n",
            "[exp_8] Episode 10050 | Loss: 0.2146\n",
            "[exp_8] Episode 10100 | Loss: 0.1901\n",
            "[exp_8] Episode 10150 | Loss: 0.2149\n",
            "[exp_8] Episode 10200 | Loss: 0.1660\n",
            "[exp_8] Episode 10250 | Loss: 0.2011\n",
            "[exp_8] Episode 10300 | Loss: 0.1735\n",
            "[exp_8] Episode 10350 | Loss: 0.1578\n",
            "[exp_8] Episode 10400 | Loss: 0.1965\n",
            "[exp_8] Episode 10450 | Loss: 0.1906\n",
            "[exp_8] Episode 10500 | Loss: 0.2023\n",
            "[exp_8] Validation Accuracy: 79.95%\n",
            "[exp_8] Episode 10550 | Loss: 0.1530\n",
            "[exp_8] Episode 10600 | Loss: 0.1291\n",
            "[exp_8] Episode 10650 | Loss: 0.1479\n",
            "[exp_8] Episode 10700 | Loss: 0.1652\n",
            "[exp_8] Episode 10750 | Loss: 0.2110\n",
            "[exp_8] Episode 10800 | Loss: 0.2299\n",
            "[exp_8] Episode 10850 | Loss: 0.2019\n",
            "[exp_8] Episode 10900 | Loss: 0.2072\n",
            "[exp_8] Episode 10950 | Loss: 0.1808\n",
            "[exp_8] Episode 11000 | Loss: 0.1977\n",
            "[exp_8] Validation Accuracy: 80.05%\n",
            "[exp_8] Episode 11050 | Loss: 0.2078\n",
            "[exp_8] Episode 11100 | Loss: 0.1576\n",
            "[exp_8] Episode 11150 | Loss: 0.2030\n",
            "[exp_8] Episode 11200 | Loss: 0.1850\n",
            "[exp_8] Episode 11250 | Loss: 0.1795\n",
            "[exp_8] Episode 11300 | Loss: 0.1871\n",
            "[exp_8] Episode 11350 | Loss: 0.1722\n",
            "[exp_8] Episode 11400 | Loss: 0.1885\n",
            "[exp_8] Episode 11450 | Loss: 0.1738\n",
            "[exp_8] Episode 11500 | Loss: 0.2059\n",
            "[exp_8] Validation Accuracy: 80.25%\n",
            "[exp_8] Episode 11550 | Loss: 0.1597\n",
            "[exp_8] Episode 11600 | Loss: 0.1343\n",
            "[exp_8] Episode 11650 | Loss: 0.1370\n",
            "[exp_8] Episode 11700 | Loss: 0.1607\n",
            "[exp_8] Episode 11750 | Loss: 0.1964\n",
            "[exp_8] Episode 11800 | Loss: 0.1442\n",
            "[exp_8] Episode 11850 | Loss: 0.1653\n",
            "[exp_8] Episode 11900 | Loss: 0.1776\n",
            "[exp_8] Episode 11950 | Loss: 0.1843\n",
            "[exp_8] Episode 12000 | Loss: 0.1666\n",
            "[exp_8] Validation Accuracy: 80.23%\n",
            "[exp_8] Episode 12050 | Loss: 0.1806\n",
            "[exp_8] Episode 12100 | Loss: 0.1634\n",
            "[exp_8] Episode 12150 | Loss: 0.1571\n",
            "[exp_8] Episode 12200 | Loss: 0.1733\n",
            "[exp_8] Episode 12250 | Loss: 0.1541\n",
            "[exp_8] Episode 12300 | Loss: 0.1772\n",
            "[exp_8] Episode 12350 | Loss: 0.2016\n",
            "[exp_8] Episode 12400 | Loss: 0.1669\n",
            "[exp_8] Episode 12450 | Loss: 0.1399\n",
            "[exp_8] Episode 12500 | Loss: 0.1126\n",
            "[exp_8] Validation Accuracy: 80.30%\n",
            "[exp_8] Early stopping triggered at episode 12500\n",
            "결과가 저장되었습니다: /content/drive/MyDrive/experiment_results/experiment_summary.csv\n",
            "\n",
            "최종 실험 결과:\n",
            "  experiment_id  shot  meta_batch_size  best_val_acc     status  \\\n",
            "0         exp_1     1              NaN        52.475  Evaluated   \n",
            "1         exp_2     5              NaN        71.375  Evaluated   \n",
            "2         exp_3     1              1.0        68.025   Finished   \n",
            "3         exp_4     1              4.0        69.800   Finished   \n",
            "4         exp_5     1              8.0        69.100   Finished   \n",
            "5         exp_6     5              1.0        82.875   Finished   \n",
            "6         exp_7     5              4.0        81.175   Finished   \n",
            "7         exp_8     5              8.0        80.900   Finished   \n",
            "\n",
            "                        _id  \n",
            "0  67e90de1a30c26eb29b14ade  \n",
            "1  67e90df6a30c26eb29b14adf  \n",
            "2  67e91fc8a30c26eb29b14ae0  \n",
            "3  67e93076a30c26eb29b14ae1  \n",
            "4  67e9412ca30c26eb29b14ae2  \n",
            "5  67e95799a30c26eb29b14ae3  \n",
            "6  67e96dfba30c26eb29b14ae4  \n",
            "7  67e97a10a30c26eb29b14ae5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화"
      ],
      "metadata": {
        "id": "v0R86s0rA_vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_tsne(model, test_loader, save_path, class_names=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        support_images, support_labels, query_images, query_labels, _ = next(iter(test_loader))\n",
        "\n",
        "        support_images = support_images.cuda()\n",
        "        query_images = query_images.cuda()\n",
        "        support_labels = support_labels.cuda()\n",
        "        query_labels = query_labels.cuda()\n",
        "\n",
        "        z_support = model.backbone(support_images).cpu()\n",
        "        z_query = model.backbone(query_images).cpu()\n",
        "\n",
        "        unique_classes = torch.unique(support_labels)\n",
        "        z_proto = torch.stack([\n",
        "            z_support[support_labels.cpu() == cls.cpu()].mean(0)\n",
        "            for cls in unique_classes\n",
        "        ])\n",
        "\n",
        "        all_embeddings = torch.cat([z_support, z_query, z_proto], dim=0).numpy()\n",
        "        tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
        "        embeddings_2d = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "        n_support = len(z_support)\n",
        "        n_query = len(z_query)\n",
        "        z_support_2d = embeddings_2d[:n_support]\n",
        "        z_query_2d = embeddings_2d[n_support:n_support + n_query]\n",
        "        z_proto_2d = embeddings_2d[n_support + n_query:]\n",
        "\n",
        "        # 색상\n",
        "        n_way = len(unique_classes)\n",
        "        palette = sns.color_palette(\"Set2\", n_colors=n_way)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        for i, cls in enumerate(unique_classes.cpu().numpy()):\n",
        "            idx = (support_labels.cpu().numpy() == cls)\n",
        "            sns.kdeplot(\n",
        "                x=z_support_2d[idx, 0], y=z_support_2d[idx, 1],\n",
        "                fill=True,\n",
        "                cmap=sns.light_palette(palette[i], as_cmap=True),\n",
        "                alpha=0.3, levels=10,\n",
        "                label=f\"Support KDE - {class_names[cls] if class_names else cls}\"\n",
        "            )\n",
        "\n",
        "        for i, cls in enumerate(unique_classes.cpu().numpy()):\n",
        "            idx = (query_labels.cpu().numpy() == cls)\n",
        "            plt.scatter(z_query_2d[idx, 0], z_query_2d[idx, 1],\n",
        "                        color=palette[i], label=f\"Query - {class_names[cls] if class_names else cls}\",\n",
        "                        alpha=0.7)\n",
        "\n",
        "        for i, cls in enumerate(unique_classes.cpu().numpy()):\n",
        "            plt.scatter(z_proto_2d[i, 0], z_proto_2d[i, 1],\n",
        "                        marker='*', s=200, edgecolors='k', linewidths=1.5,\n",
        "                        color=palette[i], label=f\"Prototype - {class_names[cls] if class_names else cls}\")\n",
        "\n",
        "        plt.title(\"t-SNE Visualization\")\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{save_path}/tsne_plot.png\")\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "Wqqj5sKxA2-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def visualize_confusion_matrix(model, test_loader, save_path, class_names=None):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for support_images, support_labels, query_images, query_labels, _ in test_loader:\n",
        "            support_images, support_labels = support_images.cuda(), support_labels.cuda()\n",
        "            query_images = query_images.cuda()\n",
        "\n",
        "            scores = model(support_images, support_labels, query_images)\n",
        "            preds = scores.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(query_labels.numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    disp.plot(cmap=\"Blues\", ax=ax)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(f\"{save_path}/confusion_matrix.png\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "0cDwfy_3A5aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_visualizations_for_all_experiments(results_root_dir, test_loader, class_names=None):\n",
        "    experiment_dirs = sorted([\n",
        "        d for d in os.listdir(results_root_dir)\n",
        "        if os.path.isdir(os.path.join(results_root_dir, d))\n",
        "    ])\n",
        "\n",
        "    for exp_name in tqdm(experiment_dirs, desc=\"Experiments\"):\n",
        "        exp_dir = os.path.join(results_root_dir, exp_name)\n",
        "        model_path = os.path.join(exp_dir, \"best_model.pt\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"[{exp_name}] 모델 파일이 없습니다. 스킵합니다.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[{exp_name}] 모델 불러오는 중...\")\n",
        "\n",
        "        # 모델 불러오기\n",
        "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        backbone.fc = nn.Flatten()\n",
        "        model = PrototypicalNetworks(backbone).cuda()\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        # t-SNE 시각화\n",
        "        try:\n",
        "            visualize_tsne(model, test_loader, save_path=exp_dir, class_names=class_names)\n",
        "            print(f\"[{exp_name}] t-SNE 저장 완료\")\n",
        "        except Exception as e:\n",
        "            print(f\"[{exp_name}] t-SNE 실패: {e}\")\n",
        "\n",
        "        # Confusion Matrix 시각화\n",
        "        try:\n",
        "            visualize_confusion_matrix(model, test_loader, save_path=exp_dir, class_names=class_names)\n",
        "            print(f\"[{exp_name}] Confusion Matrix 저장 완료\")\n",
        "        except Exception as e:\n",
        "            print(f\"[{exp_name}] Confusion Matrix 실패: {e}\")\n"
      ],
      "metadata": {
        "id": "koGJZn2FA7RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dir = \"/mnt/data/experiment_results\"\n",
        "class_names = test_dataset.classes  # ex: ['AK', 'KAPADOKYA', 'NURLU', 'SIRA']\n",
        "\n",
        "run_visualizations_for_all_experiments(results_dir, test_loader=test_loader, class_names=class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "NeuW7GT2A9vd",
        "outputId": "fe45164f-e21f-4fb3-894f-5ea081a330e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0efe011268a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/data/experiment_results\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m  \u001b[0;31m# ex: ['AK', 'KAPADOKYA', 'NURLU', 'SIRA']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrun_visualizations_for_all_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    }
  ]
}